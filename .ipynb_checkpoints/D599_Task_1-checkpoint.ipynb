{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8c7788-b956-486f-98c1-417e11b074a1",
   "metadata": {},
   "source": [
    "### D599 Data Preparation and Exploration Task 1\n",
    "#### John D. Pickering\n",
    "#### Environment: Jupyter Notebook\n",
    "#### Language: Python with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3569a042-bf0e-4856-9907-ffa1fe3de205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import plotly\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961fb3c1-d7d0-4eaa-adb0-031a9cb94cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataseet into pandas\n",
    "df = pd.read_csv('Employee Turnover Dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b823c70-f32d-4af9-a521-7c76e13e0665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up column names: strip spaces, lowercase, replace internal spaces\n",
    "df.columns = (\n",
    "    df.columns.str.strip()   # remove leading/trailing whitespace\n",
    "              .str.replace(\" \", \"_\")  # replace spaces with underscores\n",
    "              .str.lower()   # optional: standardize casing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "179d06f6-1fec-4641-b0a5-1313da937798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10199 entries, 0 to 10198\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   employeenumber                10199 non-null  int64  \n",
      " 1   age                           10199 non-null  int64  \n",
      " 2   tenure                        10199 non-null  int64  \n",
      " 3   turnover                      10199 non-null  object \n",
      " 4   hourlyrate                    10199 non-null  object \n",
      " 5   hoursweekly                   10199 non-null  int64  \n",
      " 6   compensationtype              10199 non-null  object \n",
      " 7   annualsalary                  10199 non-null  float64\n",
      " 8   drivingcommuterdistance       10199 non-null  int64  \n",
      " 9   jobrolearea                   10199 non-null  object \n",
      " 10  gender                        10199 non-null  object \n",
      " 11  maritalstatus                 10199 non-null  object \n",
      " 12  numcompaniespreviouslyworked  9534 non-null   float64\n",
      " 13  annualprofessionaldevhrs      8230 non-null   float64\n",
      " 14  paycheckmethod                10199 non-null  object \n",
      " 15  textmessageoptin              7933 non-null   object \n",
      "dtypes: float64(3), int64(5), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# A1 - Identify the number of records and variables (columns) + ensure dataset has been read into Pandas\n",
    "# Rows: 10199\n",
    "# Columns: 16\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd21c21-d079-4792-9ddf-04291691f8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(99)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B1 - Explain how you inspected the dataset to detect the following data quality issues: \n",
    "# Get total rows of duplicated data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb0ecbd-8012-4e7b-ab47-e1dd5c17112f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>employeenumber</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turnover</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hourlyrate</th>\n",
       "      <td>$24.37</td>\n",
       "      <td>$24.37</td>\n",
       "      <td>$22.52</td>\n",
       "      <td>$22.52</td>\n",
       "      <td>$88.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoursweekly</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compensationtype</th>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annualsalary</th>\n",
       "      <td>50689.6</td>\n",
       "      <td>50689.6</td>\n",
       "      <td>46841.6</td>\n",
       "      <td>46841.6</td>\n",
       "      <td>284641.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drivingcommuterdistance</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobrolearea</th>\n",
       "      <td>Research</td>\n",
       "      <td>Research</td>\n",
       "      <td>Information_Technology</td>\n",
       "      <td>Information_Technology</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Prefer Not to Answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maritalstatus</th>\n",
       "      <td>Married</td>\n",
       "      <td>Married</td>\n",
       "      <td>Single</td>\n",
       "      <td>Single</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numcompaniespreviouslyworked</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annualprofessionaldevhrs</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paycheckmethod</th>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Mailed Check</td>\n",
       "      <td>Mailed Check</td>\n",
       "      <td>Mail Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textmessageoptin</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0           1                       2  \\\n",
       "employeenumber                         1           2                       3   \n",
       "age                                   28          33                      22   \n",
       "tenure                                 6           2                       1   \n",
       "turnover                             Yes         Yes                      No   \n",
       "hourlyrate                       $24.37      $24.37                  $22.52    \n",
       "hoursweekly                           40          40                      40   \n",
       "compensationtype                  Salary      Salary                  Salary   \n",
       "annualsalary                     50689.6     50689.6                 46841.6   \n",
       "drivingcommuterdistance               89          89                      35   \n",
       "jobrolearea                     Research    Research  Information_Technology   \n",
       "gender                            Female      Female                  Female   \n",
       "maritalstatus                    Married     Married                  Single   \n",
       "numcompaniespreviouslyworked         3.0         6.0                     1.0   \n",
       "annualprofessionaldevhrs             7.0         7.0                     8.0   \n",
       "paycheckmethod                Mail Check  Mail Check            Mailed Check   \n",
       "textmessageoptin                     Yes         Yes                     Yes   \n",
       "\n",
       "                                                   3                     4  \n",
       "employeenumber                                     4                     5  \n",
       "age                                               23                    40  \n",
       "tenure                                             1                     6  \n",
       "turnover                                          No                    No  \n",
       "hourlyrate                                   $22.52                $88.77   \n",
       "hoursweekly                                       40                    40  \n",
       "compensationtype                              Salary                Salary  \n",
       "annualsalary                                 46841.6              284641.6  \n",
       "drivingcommuterdistance                           35                    12  \n",
       "jobrolearea                   Information_Technology                 Sales  \n",
       "gender                                        Female  Prefer Not to Answer  \n",
       "maritalstatus                                 Single                Single  \n",
       "numcompaniespreviouslyworked                     3.0                   7.0  \n",
       "annualprofessionaldevhrs                         NaN                   NaN  \n",
       "paycheckmethod                          Mailed Check            Mail Check  \n",
       "textmessageoptin                                 Yes                   Yes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A1 - Show variable data for review\n",
    "df.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564ec0c3-10d5-4fd8-99c9-a05849dc0d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employeenumber</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>hoursweekly</th>\n",
       "      <th>annualsalary</th>\n",
       "      <th>drivingcommuterdistance</th>\n",
       "      <th>numcompaniespreviouslyworked</th>\n",
       "      <th>annualprofessionaldevhrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10199.000000</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>10199.0</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>9534.000000</td>\n",
       "      <td>8230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5001.960977</td>\n",
       "      <td>44.028826</td>\n",
       "      <td>8.992744</td>\n",
       "      <td>40.0</td>\n",
       "      <td>120947.568526</td>\n",
       "      <td>45.411903</td>\n",
       "      <td>4.214810</td>\n",
       "      <td>14.938518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2942.709195</td>\n",
       "      <td>10.217864</td>\n",
       "      <td>5.511985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77566.715759</td>\n",
       "      <td>54.011750</td>\n",
       "      <td>2.481994</td>\n",
       "      <td>6.087415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-33326.400000</td>\n",
       "      <td>-275.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2451.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>63252.800000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5001.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>101566.400000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7550.500000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>153878.400000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10100.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>339950.400000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       employeenumber           age        tenure  hoursweekly   annualsalary  \\\n",
       "count    10199.000000  10199.000000  10199.000000      10199.0   10199.000000   \n",
       "mean      5001.960977     44.028826      8.992744         40.0  120947.568526   \n",
       "std       2942.709195     10.217864      5.511985          0.0   77566.715759   \n",
       "min          1.000000     21.000000      1.000000         40.0  -33326.400000   \n",
       "25%       2451.500000     37.000000      5.000000         40.0   63252.800000   \n",
       "50%       5001.000000     44.000000      8.000000         40.0  101566.400000   \n",
       "75%       7550.500000     53.000000     13.000000         40.0  153878.400000   \n",
       "max      10100.000000     61.000000     20.000000         40.0  339950.400000   \n",
       "\n",
       "       drivingcommuterdistance  numcompaniespreviouslyworked  \\\n",
       "count             10199.000000                   9534.000000   \n",
       "mean                 45.411903                      4.214810   \n",
       "std                  54.011750                      2.481994   \n",
       "min                -275.000000                      1.000000   \n",
       "25%                  13.000000                      2.000000   \n",
       "50%                  42.000000                      4.000000   \n",
       "75%                  71.000000                      6.000000   \n",
       "max                 950.000000                      9.000000   \n",
       "\n",
       "       annualprofessionaldevhrs  \n",
       "count               8230.000000  \n",
       "mean                  14.938518  \n",
       "std                    6.087415  \n",
       "min                    5.000000  \n",
       "25%                   10.000000  \n",
       "50%                   15.000000  \n",
       "75%                   20.000000  \n",
       "max                   25.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Numeric Analysis\n",
    "df.describe()\n",
    "# Can see that there is an issue with Min/Max for Driving Commuter Distance\n",
    "# Can see negatives for AnnualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d577283-aada-4747-a765-fac6a2946b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Pandas_Dtype</th>\n",
       "      <th>Variable_Type</th>\n",
       "      <th>Subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>employeenumber</th>\n",
       "      <td>employeenumber</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>age</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>tenure</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turnover</th>\n",
       "      <td>turnover</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hourlyrate</th>\n",
       "      <td>hourlyrate</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoursweekly</th>\n",
       "      <td>hoursweekly</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compensationtype</th>\n",
       "      <td>compensationtype</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Ordinal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annualsalary</th>\n",
       "      <td>annualsalary</td>\n",
       "      <td>float64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drivingcommuterdistance</th>\n",
       "      <td>drivingcommuterdistance</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobrolearea</th>\n",
       "      <td>jobrolearea</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>gender</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maritalstatus</th>\n",
       "      <td>maritalstatus</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numcompaniespreviouslyworked</th>\n",
       "      <td>numcompaniespreviouslyworked</td>\n",
       "      <td>float64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annualprofessionaldevhrs</th>\n",
       "      <td>annualprofessionaldevhrs</td>\n",
       "      <td>float64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paycheckmethod</th>\n",
       "      <td>paycheckmethod</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textmessageoptin</th>\n",
       "      <td>textmessageoptin</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Column Pandas_Dtype  \\\n",
       "employeenumber                              employeenumber        int64   \n",
       "age                                                    age        int64   \n",
       "tenure                                              tenure        int64   \n",
       "turnover                                          turnover       object   \n",
       "hourlyrate                                      hourlyrate       object   \n",
       "hoursweekly                                    hoursweekly        int64   \n",
       "compensationtype                          compensationtype       object   \n",
       "annualsalary                                  annualsalary      float64   \n",
       "drivingcommuterdistance            drivingcommuterdistance        int64   \n",
       "jobrolearea                                    jobrolearea       object   \n",
       "gender                                              gender       object   \n",
       "maritalstatus                                maritalstatus       object   \n",
       "numcompaniespreviouslyworked  numcompaniespreviouslyworked      float64   \n",
       "annualprofessionaldevhrs          annualprofessionaldevhrs      float64   \n",
       "paycheckmethod                              paycheckmethod       object   \n",
       "textmessageoptin                          textmessageoptin       object   \n",
       "\n",
       "                             Variable_Type     Subtype  \n",
       "employeenumber                Quantitative  Continuous  \n",
       "age                           Quantitative  Continuous  \n",
       "tenure                        Quantitative  Continuous  \n",
       "turnover                       Qualitative     Nominal  \n",
       "hourlyrate                     Qualitative     Nominal  \n",
       "hoursweekly                   Quantitative    Discrete  \n",
       "compensationtype               Qualitative     Ordinal  \n",
       "annualsalary                  Quantitative  Continuous  \n",
       "drivingcommuterdistance       Quantitative  Continuous  \n",
       "jobrolearea                    Qualitative     Nominal  \n",
       "gender                         Qualitative     Nominal  \n",
       "maritalstatus                  Qualitative     Nominal  \n",
       "numcompaniespreviouslyworked  Quantitative  Continuous  \n",
       "annualprofessionaldevhrs      Quantitative  Continuous  \n",
       "paycheckmethod                 Qualitative     Nominal  \n",
       "textmessageoptin               Qualitative     Nominal  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A2 - List each variable and indicate the variable’s data type and attempt \n",
    "# (quantitative/numerical or qualitative/categorical) and data subtype (i.e., continuous/discrete or nominal/ordinal).\n",
    "def variable_type_summary(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Pandas_Dtype': df.dtypes.astype(str),\n",
    "        'Non_Null_Count': df.notnull().sum()\n",
    "    })\n",
    "\n",
    "    summary['Variable_Type'] = summary['Pandas_Dtype'].apply(lambda x:\n",
    "        'Quantitative' if 'int' in x or 'float' in x else\n",
    "        'Qualitative'\n",
    "    )\n",
    "\n",
    "    def guess_subtype(col):\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            unique_vals = df[col].dropna().unique()\n",
    "            if df[col].dtype == 'int64' and len(unique_vals) < 20:\n",
    "                return 'Discrete'\n",
    "            else:\n",
    "                return 'Continuous'\n",
    "        elif df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "            n_unique = df[col].nunique()\n",
    "            if n_unique < 10:\n",
    "                unique_vals = df[col].dropna().unique()\n",
    "                return 'Ordinal' if sorted(unique_vals) == list(unique_vals) else 'Nominal'\n",
    "            else:\n",
    "                return 'Nominal'\n",
    "        return 'Unknown'\n",
    "\n",
    "    summary['Subtype'] = summary['Column'].apply(guess_subtype)\n",
    "\n",
    "    return summary[['Column', 'Pandas_Dtype', 'Variable_Type', 'Subtype']]\n",
    "\n",
    "summary_table = variable_type_summary(df)\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689fdb77-b91b-4638-9698-983a80b2c4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Missing Values  Percentage\n",
      "textmessageoptin                        2266   22.217864\n",
      "annualprofessionaldevhrs                1969   19.305814\n",
      "numcompaniespreviouslyworked             665    6.520247\n",
      "employeenumber                             0    0.000000\n",
      "hourlyrate                                 0    0.000000\n",
      "age                                        0    0.000000\n",
      "tenure                                     0    0.000000\n",
      "turnover                                   0    0.000000\n",
      "annualsalary                               0    0.000000\n",
      "compensationtype                           0    0.000000\n",
      "hoursweekly                                0    0.000000\n",
      "drivingcommuterdistance                    0    0.000000\n",
      "maritalstatus                              0    0.000000\n",
      "gender                                     0    0.000000\n",
      "jobrolearea                                0    0.000000\n",
      "paycheckmethod                             0    0.000000\n"
     ]
    }
   ],
   "source": [
    "# B2 - Check Missing values by column\n",
    "def missing_values_by_column(dataframe):\n",
    "    missing_counts = dataframe.isnull().sum()\n",
    "    missing_percentage = (missing_counts / len(dataframe)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Values': missing_counts,\n",
    "        'Percentage': missing_percentage\n",
    "    }).sort_values(by='Missing Values', ascending=False)\n",
    "    return missing_df\n",
    "\n",
    "# Run the function\n",
    "missing_df = missing_values_by_column(df)\n",
    "\n",
    "# Display the results\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43fcb320-234f-4294-b9de-39e49766d171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: employeenumber\n",
      "Unique count: 10100\n",
      "Unique values: [    1     2     3 ... 10098 10099 10100]\n",
      "\n",
      "Column: age\n",
      "Unique count: 41\n",
      "Unique values: [28 33 22 23 40 45 34 37 24 30 38 47 55 59 29 35 44 54 36 32 41 56 21 27\n",
      " 50 31 46 48 39 57 52 53 58 49 42 60 43 61 26 51 25]\n",
      "\n",
      "Column: tenure\n",
      "Unique count: 20\n",
      "Unique values: [ 6  2  1 16  9  3  8  4 20 10  7 15  5 18 17 14 13 19 12 11]\n",
      "\n",
      "Column: turnover\n",
      "Unique count: 2\n",
      "Unique values: ['Yes' 'No']\n",
      "\n",
      "Column: hourlyrate\n",
      "Unique count: 5244\n",
      "Unique values: ['$24.37 ' '$22.52 ' '$88.77 ' ... '$30.86 ' '$95.07 ' '$93.05 ']\n",
      "\n",
      "Column: hoursweekly\n",
      "Unique count: 1\n",
      "Unique values: [40]\n",
      "\n",
      "Column: compensationtype\n",
      "Unique count: 1\n",
      "Unique values: ['Salary']\n",
      "\n",
      "Column: annualsalary\n",
      "Unique count: 5538\n",
      "Unique values: [ 50689.6  46841.6 284641.6 ... 337745.6 164902.4 333544. ]\n",
      "\n",
      "Column: drivingcommuterdistance\n",
      "Unique count: 120\n",
      "Unique values: [  89   35   12    0   76   15    2   36   60   14   75    5  910   28\n",
      "   -4   33   79   50   13   57   82    4   42   -5   64   -8   77    1\n",
      "   24   67   41   62   47   -7   31   32   56   22   51   58   34   37\n",
      "   16   26   74  -10   -2   84   44   61   87   46   52   73   53   85\n",
      "   66   80   55  950   70   17  250  -12   43   49   81   86   -3   48\n",
      "   45   68   10    7   20   38   21  -11   65   78   69   -6   25   54\n",
      "    8   83   27    9   -9  -14  -13   39   40   29   71   30   -1    3\n",
      "  -15   63   72  125   88   59   11    6   23 -125 -275  322   99   91\n",
      "   94   97   93   92   90   96   95   98]\n",
      "\n",
      "Column: jobrolearea\n",
      "Unique count: 12\n",
      "Unique values: ['Research' 'Information_Technology' 'Sales' 'Human_Resources'\n",
      " 'Laboratory' 'Manufacturing' 'Healthcare' 'Marketing'\n",
      " 'InformationTechnology' 'HumanResources' 'Information Technology'\n",
      " 'Human Resources']\n",
      "\n",
      "Column: gender\n",
      "Unique count: 3\n",
      "Unique values: ['Female' 'Prefer Not to Answer' 'Male']\n",
      "\n",
      "Column: maritalstatus\n",
      "Unique count: 3\n",
      "Unique values: ['Married' 'Single' 'Divorced']\n",
      "\n",
      "Column: numcompaniespreviouslyworked\n",
      "Unique count: 9\n",
      "Unique values: [3. 6. 1. 7. 2. 5. 4. 8. 9.]\n",
      "\n",
      "Column: annualprofessionaldevhrs\n",
      "Unique count: 21\n",
      "Unique values: [ 7.  8. 19. 23. 25.  9.  6.  5. 15. 16. 24. 10. 18. 11. 20. 17. 21. 12.\n",
      " 22. 14. 13.]\n",
      "\n",
      "Column: paycheckmethod\n",
      "Unique count: 7\n",
      "Unique values: ['Mail Check' 'Mailed Check' 'Direct_Deposit' 'DirectDeposit'\n",
      " 'Direct Deposit' 'Mail_Check' 'MailedCheck']\n",
      "\n",
      "Column: textmessageoptin\n",
      "Unique count: 2\n",
      "Unique values: ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "# B2 - check inconsistent entries by checking unique values\n",
    "def check_inconsistent_entries(dataframe):\n",
    "    for col in dataframe.columns:\n",
    "        unique_vals = dataframe[col].dropna().unique()\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(f\"Unique count: {len(unique_vals)}\")\n",
    "        print(\"Unique values:\", unique_vals)\n",
    "\n",
    "# Run the check\n",
    "check_inconsistent_entries(df)\n",
    "# Based on the data below I found that three columns have inconsistent entrires\n",
    "# HourlyRate - Should be numeric, set as float.  \n",
    "# JobRoleArea - Has too many unique values.  Need to create one entry for Information_Technology and human resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e6c525b-0565-4167-9608-8ddea682b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: hourlyrate\n",
      "Type: dtype_mismatch_numeric_expected\n",
      "Issue: Column should be numeric but contains non-numeric values\n",
      "\n",
      "Column: annualsalary\n",
      "Type: invalid_negative_numeric\n",
      "Issue: Negative values may be invalid\n",
      "Invalid negatives: [-15896.0, -28660.8, -15022.4, -10433.6, -14475.2, -16540.8, -15001.6, -10392.0, -13601.6, -13352.0, -13435.2, -9705.6, -13268.8, -16041.6, -12056.0, -14828.8, -9497.6, -12852.8, -10932.8, -12624.0, -9268.8, -33326.4, -9580.8, -9872.0, -15494.4, -14980.8, -13331.2, -15099.2, -9643.2, -13560.0, -14558.4, -11452.8, -10953.6, -33222.4, -12748.8, -10641.6, -15334.4, -16374.4, -13414.4, -10412.8, -16353.6, -12868.8, -10246.4, -15521.6, -16270.4, -10828.8, -33056.0]\n",
      "\n",
      "Column: drivingcommuterdistance\n",
      "Type: invalid_negative_numeric\n",
      "Issue: Negative values may be invalid\n",
      "Invalid negatives: [-4, -5, -8, -7, -10, -2, -12, -3, -11, -6, -9, -14, -13, -1, -15, -125, -275]\n",
      "\n",
      "Column: jobrolearea\n",
      "Type: categorical_inconsistencies\n",
      "Issue: Possible casing/spacing/underscore inconsistencies\n",
      "Original values: ['Healthcare', 'Human Resources', 'HumanResources', 'Human_Resources', 'Information Technology', 'InformationTechnology', 'Information_Technology', 'Laboratory', 'Manufacturing', 'Marketing', 'Research', 'Sales']\n",
      "Suggested normalized: ['healthcare', 'human resources', 'humanresources', 'information technology', 'informationtechnology', 'laboratory', 'manufacturing', 'marketing', 'research', 'sales']\n",
      "\n",
      "Column: paycheckmethod\n",
      "Type: categorical_inconsistencies\n",
      "Issue: Possible casing/spacing/underscore inconsistencies\n",
      "Original values: ['Direct Deposit', 'DirectDeposit', 'Direct_Deposit', 'Mail Check', 'Mail_Check', 'Mailed Check', 'MailedCheck']\n",
      "Suggested normalized: ['direct deposit', 'directdeposit', 'mail check', 'mailed check', 'mailedcheck']\n"
     ]
    }
   ],
   "source": [
    "#B2 - View Formatting Errors\n",
    "def find_formatting_errors(df, force_numeric_cols=None, numeric_object_threshold: float = 0.9):\n",
    "    \"\"\"\n",
    "    Identify potential formatting errors in a DataFrame with tightened reporting.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    force_numeric_cols = force_numeric_cols or []\n",
    "\n",
    "    for col in df.columns:\n",
    "        s = df[col]\n",
    "\n",
    "        # --- 1. Forced numeric columns ---\n",
    "        if col in force_numeric_cols:\n",
    "            numeric_version = pd.to_numeric(s, errors=\"coerce\")\n",
    "            parse_rate = numeric_version.notna().sum() / max(1, s.notna().sum())\n",
    "\n",
    "            if parse_rate < 1.0:\n",
    "                results[col] = {\n",
    "                    \"type\": \"dtype_mismatch_numeric_expected\",\n",
    "                    \"issue\": \"Column should be numeric but contains non-numeric values\",\n",
    "                    \"parse_rate\": round(100 * parse_rate, 2),\n",
    "                    \"examples_failed\": s[numeric_version.isna()].dropna().unique().tolist()[:10],\n",
    "                }\n",
    "            else:\n",
    "                if not pd.api.types.is_numeric_dtype(s):\n",
    "                    results[col] = {\n",
    "                        \"type\": \"dtype_mismatch_numeric_expected\",\n",
    "                        \"issue\": \"Likely numeric column stored as object\",\n",
    "                        \"parse_rate\": round(100 * parse_rate, 2),\n",
    "                        \"examples\": s.dropna().unique().tolist()[:10],\n",
    "                    }\n",
    "                else:\n",
    "                    # If it's already numeric and clean, log it as OK\n",
    "                    results[col] = {\n",
    "                        \"type\": \"numeric_ok\",\n",
    "                        \"issue\": \"Column is numeric and contains valid values\",\n",
    "                        \"parse_rate\": 100.0,\n",
    "                    }\n",
    "            continue  # done with this col\n",
    "\n",
    "        # --- 2. Object columns (not forced numeric) ---\n",
    "        if pd.api.types.is_object_dtype(s):\n",
    "            numeric_version = pd.to_numeric(s, errors=\"coerce\")\n",
    "            parse_rate = numeric_version.notna().sum() / max(1, s.notna().sum())\n",
    "\n",
    "            if parse_rate >= numeric_object_threshold:\n",
    "                results[col] = {\n",
    "                    \"type\": \"dtype_mismatch_numeric_expected\",\n",
    "                    \"issue\": \"Likely numeric column stored as object\",\n",
    "                    \"parse_rate\": round(100 * parse_rate, 2),\n",
    "                    \"examples\": s.dropna().unique().tolist()[:10],\n",
    "                }\n",
    "            elif 0 < numeric_version.notna().sum() < s.notna().sum():\n",
    "                results[col] = {\n",
    "                    \"type\": \"mixed_numeric_categorical\",\n",
    "                    \"issue\": \"Column mixes numeric-like and categorical values\",\n",
    "                    \"examples_non_numeric\": s[numeric_version.isna()].dropna().unique().tolist()[:10],\n",
    "                    \"examples_numeric\": s[numeric_version.notna()].dropna().unique().tolist()[:10],\n",
    "                }\n",
    "            else:\n",
    "                # Pure categorical → check inconsistencies\n",
    "                non_null = s.dropna()\n",
    "                if not non_null.empty:\n",
    "                    original_unique = set(non_null.unique())\n",
    "                    normalized = (\n",
    "                        non_null.str.strip()\n",
    "                        .str.replace(\"_\", \" \", regex=False)\n",
    "                        .str.lower()\n",
    "                    )\n",
    "                    normalized_unique = set(normalized.unique())\n",
    "                    if len(original_unique) != len(normalized_unique):\n",
    "                        results[col] = {\n",
    "                            \"type\": \"categorical_inconsistencies\",\n",
    "                            \"issue\": \"Possible casing/spacing/underscore inconsistencies\",\n",
    "                            \"original_values\": sorted(list(original_unique))[:20],\n",
    "                            \"suggested_normalized\": sorted(list(normalized_unique))[:20],\n",
    "                        }\n",
    "\n",
    "        # --- 3. True numeric columns ---\n",
    "        elif pd.api.types.is_numeric_dtype(s):\n",
    "            invalid_negatives = s[s < 0]\n",
    "            if not invalid_negatives.empty:\n",
    "                results[col] = {\n",
    "                    \"type\": \"invalid_negative_numeric\",\n",
    "                    \"issue\": \"Negative values may be invalid\",\n",
    "                    \"invalid_negatives\": invalid_negatives.unique().tolist(),\n",
    "                }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run the check\n",
    "formatting_issues = find_formatting_errors(df, force_numeric_cols=[\"hourlyrate\"]) \n",
    "\n",
    "# Display results\n",
    "for col, info in formatting_issues.items():\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Type: {info['type']}\")\n",
    "    print(f\"Issue: {info['issue']}\")\n",
    "    if \"original_values\" in info:\n",
    "        print(\"Original values:\", info[\"original_values\"])\n",
    "        print(\"Suggested normalized:\", info[\"suggested_normalized\"])\n",
    "    if \"invalid_negatives\" in info:\n",
    "        print(\"Invalid negatives:\", info[\"invalid_negatives\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e48488e3-d71e-41d9-bc3a-3cbeea238874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create backup before any cleaning is done\n",
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79538185-9e1b-4a34-a33d-a134fd1b7c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Old Dtype</th>\n",
       "      <th>New Dtype</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Non-Null Before</th>\n",
       "      <th>Parsable After</th>\n",
       "      <th>Parse Rate %</th>\n",
       "      <th>Introduced NaNs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>Already numeric</td>\n",
       "      <td>10199</td>\n",
       "      <td>10199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annualprofessionaldevhrs</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>Already numeric</td>\n",
       "      <td>8230</td>\n",
       "      <td>8230</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annualsalary</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>Already numeric</td>\n",
       "      <td>10199</td>\n",
       "      <td>10199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compensationtype</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>Left as-is (low parse rate)</td>\n",
       "      <td>10199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drivingcommuterdistance</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>Forced float</td>\n",
       "      <td>10199</td>\n",
       "      <td>10199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>employeenumber</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>Already numeric</td>\n",
       "      <td>10199</td>\n",
       "      <td>10199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gender</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>Left as-is (low parse rate)</td>\n",
       "      <td>10199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hourlyrate</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>Cleaned &amp; converted</td>\n",
       "      <td>10199</td>\n",
       "      <td>10199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hoursweekly</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>Forced float</td>\n",
       "      <td>10199</td>\n",
       "      <td>10199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jobrolearea</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>Left as-is (low parse rate)</td>\n",
       "      <td>10199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>maritalstatus</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>Left as-is (low parse rate)</td>\n",
       "      <td>10199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>numcompaniespreviouslyworked</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>Already numeric</td>\n",
       "      <td>9534</td>\n",
       "      <td>9534</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>paycheckmethod</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>Left as-is (low parse rate)</td>\n",
       "      <td>10199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tenure</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>Already numeric</td>\n",
       "      <td>10199</td>\n",
       "      <td>10199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>textmessageoptin</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>Left as-is (low parse rate)</td>\n",
       "      <td>7933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>turnover</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>Left as-is (low parse rate)</td>\n",
       "      <td>10199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Column Old Dtype New Dtype  \\\n",
       "0                            age     int64     int64   \n",
       "1       annualprofessionaldevhrs   float64   float64   \n",
       "2                   annualsalary   float64   float64   \n",
       "3               compensationtype    object    object   \n",
       "4        drivingcommuterdistance     int64   float64   \n",
       "5                 employeenumber     int64     int64   \n",
       "6                         gender    object    object   \n",
       "7                     hourlyrate    object   float64   \n",
       "8                    hoursweekly     int64   float64   \n",
       "9                    jobrolearea    object    object   \n",
       "10                 maritalstatus    object    object   \n",
       "11  numcompaniespreviouslyworked   float64   float64   \n",
       "12                paycheckmethod    object    object   \n",
       "13                        tenure     int64     int64   \n",
       "14              textmessageoptin    object    object   \n",
       "15                      turnover    object    object   \n",
       "\n",
       "                         Reason  Non-Null Before  Parsable After  \\\n",
       "0               Already numeric            10199           10199   \n",
       "1               Already numeric             8230            8230   \n",
       "2               Already numeric            10199           10199   \n",
       "3   Left as-is (low parse rate)            10199               0   \n",
       "4                  Forced float            10199           10199   \n",
       "5               Already numeric            10199           10199   \n",
       "6   Left as-is (low parse rate)            10199               0   \n",
       "7           Cleaned & converted            10199           10199   \n",
       "8                  Forced float            10199           10199   \n",
       "9   Left as-is (low parse rate)            10199               0   \n",
       "10  Left as-is (low parse rate)            10199               0   \n",
       "11              Already numeric             9534            9534   \n",
       "12  Left as-is (low parse rate)            10199               0   \n",
       "13              Already numeric            10199           10199   \n",
       "14  Left as-is (low parse rate)             7933               0   \n",
       "15  Left as-is (low parse rate)            10199               0   \n",
       "\n",
       "    Parse Rate %  Introduced NaNs  \n",
       "0          100.0              0.0  \n",
       "1          100.0              0.0  \n",
       "2          100.0              0.0  \n",
       "3            0.0              NaN  \n",
       "4          100.0              0.0  \n",
       "5          100.0              0.0  \n",
       "6            0.0              NaN  \n",
       "7          100.0              0.0  \n",
       "8          100.0              0.0  \n",
       "9            0.0              NaN  \n",
       "10           0.0              NaN  \n",
       "11         100.0              0.0  \n",
       "12           0.0              NaN  \n",
       "13         100.0              0.0  \n",
       "14           0.0              NaN  \n",
       "15           0.0              NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Update data types to numerice as needed.  \n",
    "# I force \"drivingcommuterdistance\", \"hoursweekly\" so they go from int64 to float64 for future reporting purposes. \n",
    "def _clean_numeric_like(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cleans numeric-like strings:\n",
    "    - Removes currency symbols, commas, whitespace\n",
    "    - Removes text units like 'hrs', 'hour', '/hr'\n",
    "    - Keeps digits, dots, and minus signs\n",
    "    - Coerces to numeric\n",
    "    \"\"\"\n",
    "    s = series.astype(str)\n",
    "\n",
    "    # remove common units/words\n",
    "    s = s.str.replace(r'(hours?|hrs?|/hr)\\b', '', flags=re.IGNORECASE, regex=True)\n",
    "\n",
    "    # remove currency, commas, percent, and other symbols except digits . and -\n",
    "    s = s.str.replace(r'[^0-9.\\-]', '', regex=True)\n",
    "\n",
    "    # fix multiple minus/dot issues (basic normalization)\n",
    "    s = s.str.replace(r'(?<=.)\\-', '', regex=True)\n",
    "\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "\n",
    "# --- main cleaner ---\n",
    "def clean_and_convert_numeric(\n",
    "    df: pd.DataFrame,\n",
    "    numeric_threshold: float = 0.95,\n",
    "    force_numeric_cols: list | None = None,\n",
    "    force_float_cols: list | None = None,\n",
    "    preview_examples: int = 5\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Convert likely-numeric columns to numeric dtypes,\n",
    "    with support for forcing specific columns to numeric or float.\n",
    "    Adds a 'Reason' column to the audit.\n",
    "    \"\"\"\n",
    "    cleaned = df.copy()\n",
    "    audit_rows = []\n",
    "\n",
    "    force_set = set(force_numeric_cols or [])\n",
    "    force_float_set = set(force_float_cols or [])\n",
    "\n",
    "    for col in cleaned.columns:\n",
    "        s = cleaned[col]\n",
    "        old_dtype = str(s.dtype)\n",
    "        n_nonnull = int(s.notna().sum())\n",
    "\n",
    "        direct_num = pd.to_numeric(s, errors='coerce') if not pd.api.types.is_numeric_dtype(s) else s\n",
    "        direct_ok = int(direct_num.notna().sum()) if n_nonnull else 0\n",
    "        direct_rate = (direct_ok / n_nonnull) if n_nonnull else 0.0\n",
    "\n",
    "        if (not pd.api.types.is_numeric_dtype(s)) and (direct_rate < numeric_threshold or col in force_set):\n",
    "            cleaned_num = _clean_numeric_like(s)\n",
    "            cleaned_ok = int(cleaned_num.notna().sum()) if n_nonnull else 0\n",
    "            cleaned_rate = (cleaned_ok / n_nonnull) if n_nonnull else 0.0\n",
    "\n",
    "            should_convert = (col in force_set) or (cleaned_rate >= numeric_threshold and cleaned_rate >= direct_rate)\n",
    "\n",
    "            if should_convert:\n",
    "                cleaned[col] = cleaned_num\n",
    "                new_dtype = str(cleaned[col].dtype)\n",
    "                introduced_nans = max(0, n_nonnull - cleaned_ok)\n",
    "                reason = \"Forced numeric\" if col in force_set else \"Cleaned & converted\"\n",
    "                audit_rows.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Old Dtype\": old_dtype,\n",
    "                    \"New Dtype\": new_dtype,\n",
    "                    \"Reason\": reason,\n",
    "                    \"Non-Null Before\": n_nonnull,\n",
    "                    \"Parsable After\": cleaned_ok,\n",
    "                    \"Parse Rate %\": round(100 * cleaned_rate, 2),\n",
    "                    \"Introduced NaNs\": introduced_nans,\n",
    "                })\n",
    "            else:\n",
    "                audit_rows.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Old Dtype\": old_dtype,\n",
    "                    \"New Dtype\": old_dtype,\n",
    "                    \"Reason\": \"Left as-is (low parse rate)\",\n",
    "                    \"Non-Null Before\": n_nonnull,\n",
    "                    \"Parsable After\": cleaned_ok,\n",
    "                    \"Parse Rate %\": round(100 * cleaned_rate, 2),\n",
    "                    \"Introduced NaNs\": None,\n",
    "                })\n",
    "        else:\n",
    "            if pd.api.types.is_numeric_dtype(s):\n",
    "                audit_rows.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Old Dtype\": old_dtype,\n",
    "                    \"New Dtype\": old_dtype,\n",
    "                    \"Reason\": \"Already numeric\",\n",
    "                    \"Non-Null Before\": n_nonnull,\n",
    "                    \"Parsable After\": n_nonnull,\n",
    "                    \"Parse Rate %\": 100.00,\n",
    "                    \"Introduced NaNs\": 0,\n",
    "                })\n",
    "            else:\n",
    "                should_convert = (col in force_set) or (direct_rate >= numeric_threshold)\n",
    "                if should_convert:\n",
    "                    cleaned[col] = direct_num\n",
    "                    new_dtype = str(cleaned[col].dtype)\n",
    "                    introduced_nans = max(0, n_nonnull - direct_ok)\n",
    "                    reason = \"Forced numeric\" if col in force_set else \"Direct conversion\"\n",
    "                    audit_rows.append({\n",
    "                        \"Column\": col,\n",
    "                        \"Old Dtype\": old_dtype,\n",
    "                        \"New Dtype\": new_dtype,\n",
    "                        \"Reason\": reason,\n",
    "                        \"Non-Null Before\": n_nonnull,\n",
    "                        \"Parsable After\": direct_ok,\n",
    "                        \"Parse Rate %\": round(100 * direct_rate, 2),\n",
    "                        \"Introduced NaNs\": introduced_nans,\n",
    "                    })\n",
    "                else:\n",
    "                    audit_rows.append({\n",
    "                        \"Column\": col,\n",
    "                        \"Old Dtype\": old_dtype,\n",
    "                        \"New Dtype\": old_dtype,\n",
    "                        \"Reason\": \"Left as-is (low parse rate)\",\n",
    "                        \"Non-Null Before\": n_nonnull,\n",
    "                        \"Parsable After\": direct_ok,\n",
    "                        \"Parse Rate %\": round(100 * direct_rate, 2),\n",
    "                        \"Introduced NaNs\": None,\n",
    "                    })\n",
    "\n",
    "  # Force float conversion (even if already numeric)\n",
    "    for col in force_float_set:\n",
    "        if col in cleaned.columns:\n",
    "            old_dtype = str(cleaned[col].dtype)\n",
    "            cleaned[col] = cleaned[col].astype(float)\n",
    "            new_dtype = str(cleaned[col].dtype)\n",
    "\n",
    "            # If column already exists in audit, update last entry\n",
    "            if any(a[\"Column\"] == col for a in audit_rows):\n",
    "                for a in audit_rows:\n",
    "                    if a[\"Column\"] == col:\n",
    "                        a.update({\n",
    "                            \"New Dtype\": new_dtype,\n",
    "                            \"Reason\": \"Forced float\"\n",
    "                        })\n",
    "            else:\n",
    "                # If somehow missing, add new row\n",
    "                audit_rows.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Old Dtype\": old_dtype,\n",
    "                    \"New Dtype\": new_dtype,\n",
    "                    \"Reason\": \"Forced float\",\n",
    "                    \"Non-Null Before\": int(cleaned[col].notna().sum()),\n",
    "                    \"Parsable After\": int(cleaned[col].notna().sum()),\n",
    "                    \"Parse Rate %\": 100.00,\n",
    "                    \"Introduced NaNs\": 0,\n",
    "                })\n",
    "\n",
    "    audit = pd.DataFrame(audit_rows).sort_values(\n",
    "        by=[\"Column\"], ascending=True\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return cleaned, audit\n",
    "\n",
    "    audit = pd.DataFrame(audit_rows).sort_values(\n",
    "        by=[\"Column\"], ascending=True\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return cleaned, audit\n",
    "# Run the cleaner audit with forced floats\n",
    "df, type_audit = clean_and_convert_numeric(\n",
    "    df,\n",
    "    force_float_cols=[\"drivingcommuterdistance\", \"hoursweekly\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Inspect audit table\n",
    "type_audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ee2230-2ebf-4378-b102-7d03076e82af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employeenumber</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>hourlyrate</th>\n",
       "      <th>hoursweekly</th>\n",
       "      <th>annualsalary</th>\n",
       "      <th>drivingcommuterdistance</th>\n",
       "      <th>numcompaniespreviouslyworked</th>\n",
       "      <th>annualprofessionaldevhrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10199.000000</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>10199.0</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>9534.000000</td>\n",
       "      <td>8230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5001.960977</td>\n",
       "      <td>44.028826</td>\n",
       "      <td>8.992744</td>\n",
       "      <td>52.792995</td>\n",
       "      <td>40.0</td>\n",
       "      <td>120947.568526</td>\n",
       "      <td>45.411903</td>\n",
       "      <td>4.214810</td>\n",
       "      <td>14.938518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2942.709195</td>\n",
       "      <td>10.217864</td>\n",
       "      <td>5.511985</td>\n",
       "      <td>23.941940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77566.715759</td>\n",
       "      <td>54.011750</td>\n",
       "      <td>2.481994</td>\n",
       "      <td>6.087415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-33326.400000</td>\n",
       "      <td>-275.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2451.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.955000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>63252.800000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5001.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>48.830000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>101566.400000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7550.500000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>73.980000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>153878.400000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10100.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>339950.400000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       employeenumber           age        tenure    hourlyrate  hoursweekly  \\\n",
       "count    10199.000000  10199.000000  10199.000000  10199.000000      10199.0   \n",
       "mean      5001.960977     44.028826      8.992744     52.792995         40.0   \n",
       "std       2942.709195     10.217864      5.511985     23.941940          0.0   \n",
       "min          1.000000     21.000000      1.000000     17.210000         40.0   \n",
       "25%       2451.500000     37.000000      5.000000     30.955000         40.0   \n",
       "50%       5001.000000     44.000000      8.000000     48.830000         40.0   \n",
       "75%       7550.500000     53.000000     13.000000     73.980000         40.0   \n",
       "max      10100.000000     61.000000     20.000000     98.070000         40.0   \n",
       "\n",
       "        annualsalary  drivingcommuterdistance  numcompaniespreviouslyworked  \\\n",
       "count   10199.000000             10199.000000                   9534.000000   \n",
       "mean   120947.568526                45.411903                      4.214810   \n",
       "std     77566.715759                54.011750                      2.481994   \n",
       "min    -33326.400000              -275.000000                      1.000000   \n",
       "25%     63252.800000                13.000000                      2.000000   \n",
       "50%    101566.400000                42.000000                      4.000000   \n",
       "75%    153878.400000                71.000000                      6.000000   \n",
       "max    339950.400000               950.000000                      9.000000   \n",
       "\n",
       "       annualprofessionaldevhrs  \n",
       "count               8230.000000  \n",
       "mean                  14.938518  \n",
       "std                    6.087415  \n",
       "min                    5.000000  \n",
       "25%                   10.000000  \n",
       "50%                   15.000000  \n",
       "75%                   20.000000  \n",
       "max                   25.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check to ensure HourlyRate has conveted to Numeric\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7409e91e-be14-4269-8455-9f551610d6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>employeenumber</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turnover</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hourlyrate</th>\n",
       "      <td>24.37</td>\n",
       "      <td>24.37</td>\n",
       "      <td>22.52</td>\n",
       "      <td>22.52</td>\n",
       "      <td>88.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoursweekly</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compensationtype</th>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annualsalary</th>\n",
       "      <td>50689.6</td>\n",
       "      <td>50689.6</td>\n",
       "      <td>46841.6</td>\n",
       "      <td>46841.6</td>\n",
       "      <td>284641.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drivingcommuterdistance</th>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobrolearea</th>\n",
       "      <td>Research</td>\n",
       "      <td>Research</td>\n",
       "      <td>Information_Technology</td>\n",
       "      <td>Information_Technology</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Prefer Not to Answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maritalstatus</th>\n",
       "      <td>Married</td>\n",
       "      <td>Married</td>\n",
       "      <td>Single</td>\n",
       "      <td>Single</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numcompaniespreviouslyworked</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annualprofessionaldevhrs</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paycheckmethod</th>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Mailed Check</td>\n",
       "      <td>Mailed Check</td>\n",
       "      <td>Mail Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textmessageoptin</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0           1                       2  \\\n",
       "employeenumber                         1           2                       3   \n",
       "age                                   28          33                      22   \n",
       "tenure                                 6           2                       1   \n",
       "turnover                             Yes         Yes                      No   \n",
       "hourlyrate                         24.37       24.37                   22.52   \n",
       "hoursweekly                         40.0        40.0                    40.0   \n",
       "compensationtype                  Salary      Salary                  Salary   \n",
       "annualsalary                     50689.6     50689.6                 46841.6   \n",
       "drivingcommuterdistance             89.0        89.0                    35.0   \n",
       "jobrolearea                     Research    Research  Information_Technology   \n",
       "gender                            Female      Female                  Female   \n",
       "maritalstatus                    Married     Married                  Single   \n",
       "numcompaniespreviouslyworked         3.0         6.0                     1.0   \n",
       "annualprofessionaldevhrs             7.0         7.0                     8.0   \n",
       "paycheckmethod                Mail Check  Mail Check            Mailed Check   \n",
       "textmessageoptin                     Yes         Yes                     Yes   \n",
       "\n",
       "                                                   3                     4  \n",
       "employeenumber                                     4                     5  \n",
       "age                                               23                    40  \n",
       "tenure                                             1                     6  \n",
       "turnover                                          No                    No  \n",
       "hourlyrate                                     22.52                 88.77  \n",
       "hoursweekly                                     40.0                  40.0  \n",
       "compensationtype                              Salary                Salary  \n",
       "annualsalary                                 46841.6              284641.6  \n",
       "drivingcommuterdistance                         35.0                  12.0  \n",
       "jobrolearea                   Information_Technology                 Sales  \n",
       "gender                                        Female  Prefer Not to Answer  \n",
       "maritalstatus                                 Single                Single  \n",
       "numcompaniespreviouslyworked                     3.0                   7.0  \n",
       "annualprofessionaldevhrs                         NaN                   NaN  \n",
       "paycheckmethod                          Mailed Check            Mail Check  \n",
       "textmessageoptin                                 Yes                   Yes  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View data as sanity check after conversion\n",
    "df.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3caa062-a7c7-4271-9e23-238e880337b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set Business Rules for absurd values as a dict\n",
    "\n",
    "rules = {\n",
    "    \"age\": {\"min\": 18, \"max\": 80, \"integer\": True, \"fix\": \"clip\", \"clip_min\": 18, \"clip_max\": 80},\n",
    "    \"tenure\": {\"min\": 0, \"max\": 60, \"integer\": True, \"fix\": \"clip\", \"clip_min\": 0, \"clip_max\": 60},\n",
    "    \"hoursweekly\": {\"min\": 0, \"max\": 80, \"integer\": True, \"fix\": \"clip\", \"clip_min\": 0, \"clip_max\": 80},\n",
    "    \"annualsalary\": {\"min\": 0, \"max\": None, \"integer\": False, \"fix\": \"abs\"},\n",
    "    \"hourlyrate\": {\"min\": 0, \"max\": 200, \"integerz\": False, \"fix\": \"clip\", \"clip_min\": 0, \"clip_max\": 200},\n",
    "    \"drivingcommuterdistance\": {\n",
    "        \"min\": 0, \"max\": 200, \"integer\": True,\n",
    "        \"fix\": \"abs_or_nan\", \"abs_threshold\": 100\n",
    "    },\n",
    "    \"numcompaniespreviouslyworked\": {\"min\": 0, \"max\": 50, \"integer\": True, \"fix\": \"clip\", \"clip_min\": 0, \"clip_max\": 50},\n",
    "    \"annualprofessionaldevhrs\": {\"min\": 0, \"max\": 1000, \"integer\": True, \"fix\": \"clip\", \"clip_min\": 0, \"clip_max\": 1000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2eeec3f-c0ad-4f43-8eab-0a57f29e0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up functions for Absured, Outliers, and cleaning process\n",
    "\n",
    "# ----------------------------\n",
    "# Utility: absurd mask & fixer\n",
    "# ----------------------------\n",
    "def _absurd_mask(s: pd.Series, r: dict) -> pd.Series:\n",
    "    m = pd.Series(False, index=s.index)\n",
    "    if r.get(\"min\") is not None:\n",
    "        m |= s < r[\"min\"]\n",
    "    if r.get(\"max\") is not None:\n",
    "        m |= s > r[\"max\"]\n",
    "    if r.get(\"integer\", False):\n",
    "        if not pd.api.types.is_integer_dtype(s):\n",
    "            finite = s.notna() & np.isfinite(s)\n",
    "            non_integer = finite & (s != np.floor(s))\n",
    "            m |= non_integer\n",
    "    return m\n",
    "\n",
    "def _apply_absurd_fix(s: pd.Series, r: dict, m: pd.Series) -> pd.Series:\n",
    "    fix = r.get(\"fix\", None)\n",
    "    if fix is None or m.sum() == 0:\n",
    "        return s\n",
    "\n",
    "    if callable(fix):\n",
    "        return fix(s)\n",
    "\n",
    "    if fix == \"abs\":\n",
    "        neg_mask = m & (s < 0)\n",
    "        s.loc[neg_mask] = s.loc[neg_mask].abs()\n",
    "        return s\n",
    "\n",
    "    if fix == \"abs_or_nan\":\n",
    "        thresh = r.get(\"abs_threshold\", 100)\n",
    "        neg_mask = s < 0\n",
    "        small_neg = neg_mask & (s.abs() < thresh)\n",
    "        s.loc[small_neg] = s.loc[small_neg].abs()\n",
    "        s.loc[neg_mask & ~small_neg] = np.nan\n",
    "        # values above max → NaN\n",
    "        if r.get(\"max\") is not None:\n",
    "            s.loc[s > r[\"max\"]] = np.nan\n",
    "        # non-negative below min → NaN\n",
    "        if r.get(\"min\") is not None:\n",
    "            s.loc[(s < r[\"min\"]) & (s >= 0)] = np.nan\n",
    "        return s\n",
    "\n",
    "    if fix == \"clip\":\n",
    "        s = s.clip(lower=r.get(\"clip_min\", None), upper=r.get(\"clip_max\", None))\n",
    "        return s\n",
    "\n",
    "    if fix == \"nan\":\n",
    "        s.loc[m] = np.nan\n",
    "        return s\n",
    "\n",
    "    return s\n",
    "\n",
    "# ----------------------------\n",
    "# Utility: outlier detect/cap\n",
    "# ----------------------------\n",
    "def detect_and_cap_outliers(\n",
    "    s: pd.Series,\n",
    "    method: str = \"iqr\",\n",
    "    iqr_factor: float = 1.5,\n",
    "    z_thresh: float = 3.0,\n",
    "    cap: bool = True,\n",
    "    ddof: int = 0\n",
    "):\n",
    "    x = s.astype(float)\n",
    "    finite = np.isfinite(x)\n",
    "\n",
    "    if method == \"iqr\":\n",
    "        q1 = np.nanpercentile(x[finite], 25)\n",
    "        q3 = np.nanpercentile(x[finite], 75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - iqr_factor * iqr\n",
    "        upper = q3 + iqr_factor * iqr\n",
    "        out_mask = (x < lower) | (x > upper)\n",
    "    elif method == \"zscore\":\n",
    "        mu = np.nanmean(x[finite])\n",
    "        sd = np.nanstd(x[finite], ddof=ddof)\n",
    "        if sd == 0 or np.isnan(sd):\n",
    "            lower = upper = np.nan\n",
    "            out_mask = pd.Series(False, index=s.index)\n",
    "        else:\n",
    "            z = (x - mu) / sd\n",
    "            out_mask = np.abs(z) > z_thresh\n",
    "            lower = mu - z_thresh * sd\n",
    "            upper = mu + z_thresh * sd\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'iqr' or 'zscore'\")\n",
    "\n",
    "    n_out = int(out_mask.sum())\n",
    "    if cap and np.isfinite(lower) and np.isfinite(upper):\n",
    "        x_cap = x.clip(lower=lower, upper=upper)\n",
    "    else:\n",
    "        x_cap = x\n",
    "\n",
    "    return out_mask, lower, upper, n_out, x_cap.astype(s.dtype)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Start cleaning process\n",
    "# -----------------------------------------\n",
    "def run_task1_cleaning(\n",
    "    df: pd.DataFrame,\n",
    "    rules: dict,\n",
    "    outlier_cols: list[str] | None = None,\n",
    "    outlier_method: str = \"iqr\",\n",
    "    iqr_factor: float = 1.5,\n",
    "    z_thresh: float = 3.0,\n",
    "    cap_outliers: bool = True,\n",
    "    impute_plan: dict | None = None,\n",
    "    categorical_standardizers: dict | None = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      df_clean : cleaned dataframe\n",
    "      task_log : long-form log with B1/B2/C1 info per column + duplicates\n",
    "    \"\"\"\n",
    "\n",
    "    logs = []\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # ---------- Duplicates (global) ----------\n",
    "    # B1: looked via df.duplicated()\n",
    "    dup_count = int(df_clean.duplicated().sum())\n",
    "    logs.append({\n",
    "        \"column\": \"__ALL__\",\n",
    "        \"step\": \"B2\",\n",
    "        \"metric\": \"duplicate_count\",\n",
    "        \"before\": dup_count,\n",
    "        \"after\": None,\n",
    "        \"action\": \"Checked with df.duplicated().sum()\"\n",
    "    })\n",
    "\n",
    "    # C1: remove duplicates\n",
    "    if dup_count > 0:\n",
    "        df_clean = df_clean.drop_duplicates().reset_index(drop=True)\n",
    "    logs.append({\n",
    "        \"column\": \"__ALL__\",\n",
    "        \"step\": \"C1\",\n",
    "        \"metric\": \"duplicates_removed\",\n",
    "        \"before\": dup_count,\n",
    "        \"after\": 0,\n",
    "        \"action\": \"Removed with df.drop_duplicates()\"\n",
    "    })\n",
    "\n",
    "    # ---------- Column-by-column ----------\n",
    "    if outlier_cols is None:\n",
    "        outlier_cols = [c for c in df_clean.columns if pd.api.types.is_numeric_dtype(df_clean[c])]\n",
    "\n",
    "    # defaults for imputation\n",
    "    # Decided to set drivingcommuterdistance to NaN because 0 seems to say that the emaployee is remote. NaN tells us that we are not sure of the status of the data\n",
    "    \n",
    "    if impute_plan is None:\n",
    "        impute_plan = {\n",
    "            \"textmessageoptin\": \"Unknown\",\n",
    "            \"numcompaniespreviouslyworked\": \"median\",\n",
    "            \"annualprofessionaldevhrs\": 0\n",
    "        }\n",
    "\n",
    "    # standardizers for categorical inconsistencies I identified during inspection\n",
    "    if categorical_standardizers is None:\n",
    "        categorical_standardizers = {\n",
    "            \"paycheckmethod\": {\n",
    "                \"DirectDeposit\": \"Direct Deposit\",\n",
    "                \"Direct_Deposit\": \"Direct Deposit\",\n",
    "                \"Mail_Check\": \"Mail Check\",\n",
    "                \"Mailed Check\": \"Mail Check\",\n",
    "                \"MailedCheck\": \"Mail Check\"\n",
    "            },\n",
    "            \"jobrolearea\": {\n",
    "                \"Information_Technology\": \"Information Technology\",\n",
    "                \"InformationTechnology\": \"Information Technology\",\n",
    "                \"Human_Resources\": \"Human Resources\",\n",
    "                \"HumanResources\": \"Human Resources\"\n",
    "                \n",
    "                \n",
    "            }\n",
    "        }\n",
    "\n",
    "    for col in df_clean.columns:\n",
    "        s = df_clean[col]\n",
    "        dtype = str(s.dtype)\n",
    "\n",
    "        # ---------- Inconsistencies / formatting (categorical only) ----------\n",
    "        if pd.api.types.is_object_dtype(s):\n",
    "            unique_before = s.nunique(dropna=False)\n",
    "            # Strip whitespace (B1/C1)\n",
    "            df_clean[col] = s.apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "            action_notes = [\"Stripped leading/trailing whitespace\"]\n",
    "\n",
    "            # Apply canonical maps if provided\n",
    "            if col in categorical_standardizers:\n",
    "                df_clean[col] = df_clean[col].replace(categorical_standardizers[col])\n",
    "                action_notes.append(\"Standardized known variants via mapping\")\n",
    "\n",
    "            # Title-case & underscore->space normalization pass (non-destructive idea)\n",
    "            # (Only demonstrate; you already standardized explicit items above)\n",
    "            # df_clean[col] = df_clean[col].apply(lambda x: x.replace(\"_\", \" \").title() if isinstance(x, str) else x)\n",
    "\n",
    "            unique_after = df_clean[col].nunique(dropna=False)\n",
    "            logs.append({\n",
    "                \"column\": col,\n",
    "                \"step\": \"B2\",\n",
    "                \"metric\": \"unique_values_count\",\n",
    "                \"before\": unique_before,\n",
    "                \"after\": unique_after,\n",
    "                \"action\": \"; \".join(action_notes)\n",
    "            })\n",
    "\n",
    "            # Missing values (B2/C1)\n",
    "            miss_before = int(df_clean[col].isna().sum())\n",
    "            if col in impute_plan:\n",
    "                strat = impute_plan[col]\n",
    "                if strat == \"median\":\n",
    "                    # for categorical this won't be used; kept for numeric names appearing here\n",
    "                    pass\n",
    "                else:\n",
    "                    df_clean[col] = df_clean[col].fillna(strat)\n",
    "                    action = f\"Imputed missing with '{strat}'\"\n",
    "            else:\n",
    "                action = \"No imputation rule (left as-is)\"\n",
    "\n",
    "            miss_after = int(df_clean[col].isna().sum())\n",
    "            logs.append({\n",
    "                \"column\": col,\n",
    "                \"step\": \"B2\",\n",
    "                \"metric\": \"missing_count\",\n",
    "                \"before\": miss_before,\n",
    "                \"after\": miss_after,\n",
    "                \"action\": action\n",
    "            })\n",
    "\n",
    "        # ---------- Numeric columns ----------\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            # Missing values (B2)\n",
    "            miss_before = int(s.isna().sum())\n",
    "\n",
    "            # Absurd values (B1/B2): use provided rules if present\n",
    "            r = rules.get(col, None)\n",
    "            if r is not None:\n",
    "                m_before = _absurd_mask(df_clean[col], r)\n",
    "                absurd_before = int(m_before.sum())\n",
    "                # C1: fix absurd values\n",
    "                if absurd_before > 0:\n",
    "                    df_clean[col] = _apply_absurd_fix(df_clean[col], r, m_before)\n",
    "                # Recompute after\n",
    "                absurd_after = int(_absurd_mask(df_clean[col], r).sum())\n",
    "\n",
    "                logs.append({\n",
    "                    \"column\": col,\n",
    "                    \"step\": \"B2\",\n",
    "                    \"metric\": \"absurd_count\",\n",
    "                    \"before\": absurd_before,\n",
    "                    \"after\": absurd_after,\n",
    "                    \"action\": f\"Applied absurd fix: {r.get('fix')} (bounds: {r.get('min')}–{r.get('max')})\"\n",
    "                })\n",
    "            else:\n",
    "                absurd_after = np.nan\n",
    "                logs.append({\n",
    "                    \"column\": col,\n",
    "                    \"step\": \"B2\",\n",
    "                    \"metric\": \"absurd_count\",\n",
    "                    \"before\": 0,\n",
    "                    \"after\": 0,\n",
    "                    \"action\": \"No absurd rule specified\"\n",
    "                })\n",
    "\n",
    "            # Imputation for numeric columns\n",
    "            if col in impute_plan:\n",
    "                strat = impute_plan[col]\n",
    "                if strat == \"median\":\n",
    "                    val = df_clean[col].median()\n",
    "                    df_clean[col] = df_clean[col].fillna(val)\n",
    "                    imp_action = f\"Imputed missing with median ({val})\"\n",
    "                else:\n",
    "                    df_clean[col] = df_clean[col].fillna(strat)\n",
    "                    imp_action = f\"Imputed missing with {strat}\"\n",
    "            else:\n",
    "                imp_action = \"No imputation rule (left as-is)\"\n",
    "\n",
    "            miss_after = int(df_clean[col].isna().sum())\n",
    "            logs.append({\n",
    "                \"column\": col,\n",
    "                \"step\": \"B2\",\n",
    "                \"metric\": \"missing_count\",\n",
    "                \"before\": miss_before,\n",
    "                \"after\": miss_after,\n",
    "                \"action\": imp_action\n",
    "            })\n",
    "\n",
    "            # Outliers (B1/B2): detect then cap (C1)\n",
    "            if col in outlier_cols:\n",
    "                out_mask, lower, upper, n_out, s_capped = detect_and_cap_outliers(\n",
    "                    df_clean[col],\n",
    "                    method=outlier_method,\n",
    "                    iqr_factor=iqr_factor,\n",
    "                    z_thresh=z_thresh,\n",
    "                    cap=cap_outliers\n",
    "                )\n",
    "                # Apply cap\n",
    "                if cap_outliers:\n",
    "                    df_clean[col] = s_capped\n",
    "                logs.append({\n",
    "                    \"column\": col,\n",
    "                    \"step\": \"B2\",\n",
    "                    \"metric\": \"outliers_count\",\n",
    "                    \"before\": n_out,\n",
    "                    \"after\": 0 if cap_outliers else n_out,\n",
    "                    \"action\": f\"Outliers via {outlier_method.upper()} \"\n",
    "                              f\"(lower={round(lower,3) if pd.notna(lower) else None}, \"\n",
    "                              f\"upper={round(upper,3) if pd.notna(upper) else None}); \"\n",
    "                              f\"{'capped to thresholds' if cap_outliers else 'flagged only'}\"\n",
    "                })\n",
    "\n",
    "    task_log = pd.DataFrame(logs)\n",
    "    return df_clean, task_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3d2c882-066d-4077-9eff-e330ed42a348",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rules' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Run absurd, outlier, and cleaning on dataset.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df, task_log \u001b[38;5;241m=\u001b[39m run_task1_cleaning(\n\u001b[1;32m      5\u001b[0m     df,\n\u001b[0;32m----> 6\u001b[0m     rules\u001b[38;5;241m=\u001b[39m\u001b[43mrules\u001b[49m,\n\u001b[1;32m      7\u001b[0m     outlier_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,        \u001b[38;5;66;03m# or a specific list\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     outlier_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miqr\u001b[39m\u001b[38;5;124m\"\u001b[39m,     \u001b[38;5;66;03m# or \"zscore\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     iqr_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m,\n\u001b[1;32m     10\u001b[0m     cap_outliers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Show Task log\u001b[39;00m\n\u001b[1;32m     13\u001b[0m task_log\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rules' is not defined"
     ]
    }
   ],
   "source": [
    "# Set max display for all tables\n",
    "pd.set_option(\"display.max_colwidth\", None)  \n",
    "# Run absurd, outlier, and cleaning on dataset.\n",
    "df, task_log = run_task1_cleaning(\n",
    "    df,\n",
    "    rules=rules,\n",
    "    outlier_cols=None,        # or a specific list\n",
    "    outlier_method=\"iqr\",     # or \"zscore\"\n",
    "    iqr_factor=1.5,\n",
    "    cap_outliers=True\n",
    ")\n",
    "# Show Task log\n",
    "task_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3efd959-f8cf-47eb-947e-e3af85c9a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# B2 - check inconsistent entrie after cleaning as sanity check\n",
    "def check_inconsistent_entries(dataframe):\n",
    "    for col in dataframe.columns:\n",
    "        unique_vals = dataframe[col].dropna().unique()\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(f\"Unique count: {len(unique_vals)}\")\n",
    "        print(\"Unique values:\", unique_vals)\n",
    "\n",
    "# Run the check\n",
    "check_inconsistent_entries(df)\n",
    "# Check to ensure all values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03c8d2-d6f2-4244-a022-4e36443b3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall duplicate count (before removal is logged)\n",
    "task_log[task_log.metric == \"duplicate_count\"][[\"before\"]].tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b886f-3034-4d16-b446-ce15de5264e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-column missing values (before/after)\n",
    "task_log[task_log.metric == \"missing_count\"][[\"column\",\"before\",\"after\",\"action\"]].sort_values(\"column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8404b20-56fc-4d49-bf24-6286c4796922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-column inconsistent/formatting (categorical unique counts before/after)\n",
    "task_log[task_log.metric == \"unique_values_count\"][[\"column\",\"before\",\"after\",\"action\"]].sort_values(\"column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c96fb1-9df6-4455-ab34-98106f958e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-column absurd values (before/after)\n",
    "task_log[task_log.metric == \"absurd_count\"][[\"column\",\"before\",\"after\",\"action\"]].sort_values(\"column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fdf5bb-25d9-4350-adbc-416b42a95479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-column outliers (detected and (if enabled) capped)\n",
    "# Display maxcolwidth\n",
    "task_log[task_log.metric == \"outliers_count\"][[\"column\",\"before\",\"after\",\"action\"]].sort_values(\"column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f26389-81f1-4ba7-9bd1-6c21309889ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B2 - View Formatting Errors after cleaning as sanity check\n",
    "def find_formatting_errors(df, force_numeric_cols=None, numeric_object_threshold: float = 0.9):\n",
    "    \"\"\"\n",
    "    Identify potential formatting errors in a DataFrame with tightened reporting.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    force_numeric_cols = force_numeric_cols or []\n",
    "\n",
    "    for col in df.columns:\n",
    "        s = df[col]\n",
    "\n",
    "        # --- 1. Forced numeric columns ---\n",
    "        if col in force_numeric_cols:\n",
    "            numeric_version = pd.to_numeric(s, errors=\"coerce\")\n",
    "            parse_rate = numeric_version.notna().sum() / max(1, s.notna().sum())\n",
    "\n",
    "            if parse_rate < 1.0:\n",
    "                results[col] = {\n",
    "                    \"type\": \"dtype_mismatch_numeric_expected\",\n",
    "                    \"issue\": \"Column should be numeric but contains non-numeric values\",\n",
    "                    \"parse_rate\": round(100 * parse_rate, 2),\n",
    "                    \"examples_failed\": s[numeric_version.isna()].dropna().unique().tolist()[:10],\n",
    "                }\n",
    "            else:\n",
    "                if not pd.api.types.is_numeric_dtype(s):\n",
    "                    results[col] = {\n",
    "                        \"type\": \"dtype_mismatch_numeric_expected\",\n",
    "                        \"issue\": \"Likely numeric column stored as object\",\n",
    "                        \"parse_rate\": round(100 * parse_rate, 2),\n",
    "                        \"examples\": s.dropna().unique().tolist()[:10],\n",
    "                    }\n",
    "                else:\n",
    "                    # If it's already numeric and clean, log it as OK\n",
    "                    results[col] = {\n",
    "                        \"type\": \"numeric_ok\",\n",
    "                        \"issue\": \"Column is numeric and contains valid values\",\n",
    "                        \"parse_rate\": 100.0,\n",
    "                    }\n",
    "            continue  # done with this col\n",
    "\n",
    "        # --- 2. Object columns (not forced numeric) ---\n",
    "        if pd.api.types.is_object_dtype(s):\n",
    "            numeric_version = pd.to_numeric(s, errors=\"coerce\")\n",
    "            parse_rate = numeric_version.notna().sum() / max(1, s.notna().sum())\n",
    "\n",
    "            if parse_rate >= numeric_object_threshold:\n",
    "                results[col] = {\n",
    "                    \"type\": \"dtype_mismatch_numeric_expected\",\n",
    "                    \"issue\": \"Likely numeric column stored as object\",\n",
    "                    \"parse_rate\": round(100 * parse_rate, 2),\n",
    "                    \"examples\": s.dropna().unique().tolist()[:10],\n",
    "                }\n",
    "            elif 0 < numeric_version.notna().sum() < s.notna().sum():\n",
    "                results[col] = {\n",
    "                    \"type\": \"mixed_numeric_categorical\",\n",
    "                    \"issue\": \"Column mixes numeric-like and categorical values\",\n",
    "                    \"examples_non_numeric\": s[numeric_version.isna()].dropna().unique().tolist()[:10],\n",
    "                    \"examples_numeric\": s[numeric_version.notna()].dropna().unique().tolist()[:10],\n",
    "                }\n",
    "            else:\n",
    "                # Pure categorical → check inconsistencies\n",
    "                non_null = s.dropna()\n",
    "                if not non_null.empty:\n",
    "                    original_unique = set(non_null.unique())\n",
    "                    normalized = (\n",
    "                        non_null.str.strip()\n",
    "                        .str.replace(\"_\", \" \", regex=False)\n",
    "                        .str.lower()\n",
    "                    )\n",
    "                    normalized_unique = set(normalized.unique())\n",
    "                    if len(original_unique) != len(normalized_unique):\n",
    "                        results[col] = {\n",
    "                            \"type\": \"categorical_inconsistencies\",\n",
    "                            \"issue\": \"Possible casing/spacing/underscore inconsistencies\",\n",
    "                            \"original_values\": sorted(list(original_unique))[:20],\n",
    "                            \"suggested_normalized\": sorted(list(normalized_unique))[:20],\n",
    "                        }\n",
    "\n",
    "        # --- 3. True numeric columns ---\n",
    "        elif pd.api.types.is_numeric_dtype(s):\n",
    "            invalid_negatives = s[s < 0]\n",
    "            if not invalid_negatives.empty:\n",
    "                results[col] = {\n",
    "                    \"type\": \"invalid_negative_numeric\",\n",
    "                    \"issue\": \"Negative values may be invalid\",\n",
    "                    \"invalid_negatives\": invalid_negatives.unique().tolist(),\n",
    "                }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run the check\n",
    "formatting_issues = find_formatting_errors(df, force_numeric_cols=[\"hourlyrate\"]) \n",
    "\n",
    "# Display results\n",
    "for col, info in formatting_issues.items():\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Type: {info['type']}\")\n",
    "    print(f\"Issue: {info['issue']}\")\n",
    "    if \"original_values\" in info:\n",
    "        print(\"Original values:\", info[\"original_values\"])\n",
    "        print(\"Suggested normalized:\", info[\"suggested_normalized\"])\n",
    "    if \"invalid_negatives\" in info:\n",
    "        print(\"Invalid negatives:\", info[\"invalid_negatives\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1b286-098c-4f3b-b0b7-b76a66a4dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV (no index column)\n",
    "df.to_csv(\"Employee_Turnover_Cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned dataset exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed6009-6adf-4f8c-8051-54a7e0eaadc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shap_env_new)",
   "language": "python",
   "name": "shap_env_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
