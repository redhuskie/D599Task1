{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce972983-14f7-4a43-98c8-87fb64956ae6",
   "metadata": {},
   "source": [
    "## WGU D599: Data Preparation and Exploration\n",
    "#### John D. Pickering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac240bc-a18e-4a3e-943f-757e55a1c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import shap\n",
    "import plotly\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a44a3439-5602-4d72-9470-75273d748eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset into pandas as df\n",
    "df = pd.read_csv('Employee Turnover Dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb733897-d248-496b-8b03-414f2dc80491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10199 entries, 0 to 10198\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   EmployeeNumber                10199 non-null  int64  \n",
      " 1   Age                           10199 non-null  int64  \n",
      " 2   Tenure                        10199 non-null  int64  \n",
      " 3   Turnover                      10199 non-null  object \n",
      " 4   HourlyRate                    10199 non-null  object \n",
      " 5   HoursWeekly                   10199 non-null  int64  \n",
      " 6   CompensationType              10199 non-null  object \n",
      " 7   AnnualSalary                  10199 non-null  float64\n",
      " 8   DrivingCommuterDistance       10199 non-null  int64  \n",
      " 9   JobRoleArea                   10199 non-null  object \n",
      " 10  Gender                        10199 non-null  object \n",
      " 11  MaritalStatus                 10199 non-null  object \n",
      " 12  NumCompaniesPreviouslyWorked  9534 non-null   float64\n",
      " 13  AnnualProfessionalDevHrs      8230 non-null   float64\n",
      " 14  PaycheckMethod                10199 non-null  object \n",
      " 15  TextMessageOptIn              7933 non-null   object \n",
      "dtypes: float64(3), int64(5), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# A1 - Identify the number of records and variables (columns)\n",
    "# Rows: 10199\n",
    "# Columns: 16\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e000b365-3e5d-4600-a013-00613ff98f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Pandas_Dtype</th>\n",
       "      <th>Variable_Type</th>\n",
       "      <th>Subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <td>EmployeeNumber</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>Age</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>Tenure</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turnover</th>\n",
       "      <td>Turnover</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HourlyRate</th>\n",
       "      <td>HourlyRate</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HoursWeekly</th>\n",
       "      <td>HoursWeekly</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CompensationType</th>\n",
       "      <td>CompensationType</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Ordinal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnnualSalary</th>\n",
       "      <td>AnnualSalary</td>\n",
       "      <td>float64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DrivingCommuterDistance</th>\n",
       "      <td>DrivingCommuterDistance</td>\n",
       "      <td>int64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobRoleArea</th>\n",
       "      <td>JobRoleArea</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>Gender</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaritalStatus</th>\n",
       "      <td>MaritalStatus</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumCompaniesPreviouslyWorked</th>\n",
       "      <td>NumCompaniesPreviouslyWorked</td>\n",
       "      <td>float64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnnualProfessionalDevHrs</th>\n",
       "      <td>AnnualProfessionalDevHrs</td>\n",
       "      <td>float64</td>\n",
       "      <td>Quantitative</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaycheckMethod</th>\n",
       "      <td>PaycheckMethod</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TextMessageOptIn</th>\n",
       "      <td>TextMessageOptIn</td>\n",
       "      <td>object</td>\n",
       "      <td>Qualitative</td>\n",
       "      <td>Nominal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Column Pandas_Dtype  \\\n",
       "EmployeeNumber                              EmployeeNumber        int64   \n",
       "Age                                                    Age        int64   \n",
       "Tenure                                              Tenure        int64   \n",
       "Turnover                                          Turnover       object   \n",
       "HourlyRate                                     HourlyRate        object   \n",
       "HoursWeekly                                    HoursWeekly        int64   \n",
       "CompensationType                          CompensationType       object   \n",
       "AnnualSalary                                  AnnualSalary      float64   \n",
       "DrivingCommuterDistance            DrivingCommuterDistance        int64   \n",
       "JobRoleArea                                    JobRoleArea       object   \n",
       "Gender                                              Gender       object   \n",
       "MaritalStatus                                MaritalStatus       object   \n",
       "NumCompaniesPreviouslyWorked  NumCompaniesPreviouslyWorked      float64   \n",
       "AnnualProfessionalDevHrs          AnnualProfessionalDevHrs      float64   \n",
       "PaycheckMethod                              PaycheckMethod       object   \n",
       "TextMessageOptIn                          TextMessageOptIn       object   \n",
       "\n",
       "                             Variable_Type     Subtype  \n",
       "EmployeeNumber                Quantitative  Continuous  \n",
       "Age                           Quantitative  Continuous  \n",
       "Tenure                        Quantitative  Continuous  \n",
       "Turnover                       Qualitative     Nominal  \n",
       "HourlyRate                     Qualitative     Nominal  \n",
       "HoursWeekly                   Quantitative    Discrete  \n",
       "CompensationType               Qualitative     Ordinal  \n",
       "AnnualSalary                  Quantitative  Continuous  \n",
       "DrivingCommuterDistance       Quantitative  Continuous  \n",
       "JobRoleArea                    Qualitative     Nominal  \n",
       "Gender                         Qualitative     Nominal  \n",
       "MaritalStatus                  Qualitative     Nominal  \n",
       "NumCompaniesPreviouslyWorked  Quantitative  Continuous  \n",
       "AnnualProfessionalDevHrs      Quantitative  Continuous  \n",
       "PaycheckMethod                 Qualitative     Nominal  \n",
       "TextMessageOptIn               Qualitative     Nominal  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A2 - List each variable and indicate the variable‚Äôs data type \n",
    "# (quantitative/numerical or qualitative/categorical) and data subtype (i.e., continuous/discrete or nominal/ordinal).\n",
    "def variable_type_summary(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Pandas_Dtype': df.dtypes.astype(str),\n",
    "        'Non_Null_Count': df.notnull().sum()\n",
    "    })\n",
    "\n",
    "    summary['Variable_Type'] = summary['Pandas_Dtype'].apply(lambda x:\n",
    "        'Quantitative' if 'int' in x or 'float' in x else\n",
    "        'Qualitative'\n",
    "    )\n",
    "\n",
    "    def guess_subtype(col):\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            unique_vals = df[col].dropna().unique()\n",
    "            if df[col].dtype == 'int64' and len(unique_vals) < 20:\n",
    "                return 'Discrete'\n",
    "            else:\n",
    "                return 'Continuous'\n",
    "        elif df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "            n_unique = df[col].nunique()\n",
    "            if n_unique < 10:\n",
    "                unique_vals = df[col].dropna().unique()\n",
    "                return 'Ordinal' if sorted(unique_vals) == list(unique_vals) else 'Nominal'\n",
    "            else:\n",
    "                return 'Nominal'\n",
    "        return 'Unknown'\n",
    "\n",
    "    summary['Subtype'] = summary['Column'].apply(guess_subtype)\n",
    "\n",
    "    return summary[['Column', 'Pandas_Dtype', 'Variable_Type', 'Subtype']]\n",
    "\n",
    "summary_table = variable_type_summary(df)\n",
    "summary_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d63af9-e365-4217-9ef8-10a1347f95a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turnover</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HourlyRate</th>\n",
       "      <td>$24.37</td>\n",
       "      <td>$24.37</td>\n",
       "      <td>$22.52</td>\n",
       "      <td>$22.52</td>\n",
       "      <td>$88.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HoursWeekly</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CompensationType</th>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "      <td>Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnnualSalary</th>\n",
       "      <td>50689.6</td>\n",
       "      <td>50689.6</td>\n",
       "      <td>46841.6</td>\n",
       "      <td>46841.6</td>\n",
       "      <td>284641.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DrivingCommuterDistance</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobRoleArea</th>\n",
       "      <td>Research</td>\n",
       "      <td>Research</td>\n",
       "      <td>Information_Technology</td>\n",
       "      <td>Information_Technology</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Prefer Not to Answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaritalStatus</th>\n",
       "      <td>Married</td>\n",
       "      <td>Married</td>\n",
       "      <td>Single</td>\n",
       "      <td>Single</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumCompaniesPreviouslyWorked</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnnualProfessionalDevHrs</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaycheckMethod</th>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Mailed Check</td>\n",
       "      <td>Mailed Check</td>\n",
       "      <td>Mail Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TextMessageOptIn</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0           1                       2  \\\n",
       "EmployeeNumber                         1           2                       3   \n",
       "Age                                   28          33                      22   \n",
       "Tenure                                 6           2                       1   \n",
       "Turnover                             Yes         Yes                      No   \n",
       "HourlyRate                       $24.37      $24.37                  $22.52    \n",
       "HoursWeekly                           40          40                      40   \n",
       "CompensationType                  Salary      Salary                  Salary   \n",
       "AnnualSalary                     50689.6     50689.6                 46841.6   \n",
       "DrivingCommuterDistance               89          89                      35   \n",
       "JobRoleArea                     Research    Research  Information_Technology   \n",
       "Gender                            Female      Female                  Female   \n",
       "MaritalStatus                    Married     Married                  Single   \n",
       "NumCompaniesPreviouslyWorked         3.0         6.0                     1.0   \n",
       "AnnualProfessionalDevHrs             7.0         7.0                     8.0   \n",
       "PaycheckMethod                Mail Check  Mail Check            Mailed Check   \n",
       "TextMessageOptIn                     Yes         Yes                     Yes   \n",
       "\n",
       "                                                   3                     4  \n",
       "EmployeeNumber                                     4                     5  \n",
       "Age                                               23                    40  \n",
       "Tenure                                             1                     6  \n",
       "Turnover                                          No                    No  \n",
       "HourlyRate                                   $22.52                $88.77   \n",
       "HoursWeekly                                       40                    40  \n",
       "CompensationType                              Salary                Salary  \n",
       "AnnualSalary                                 46841.6              284641.6  \n",
       "DrivingCommuterDistance                           35                    12  \n",
       "JobRoleArea                   Information_Technology                 Sales  \n",
       "Gender                                        Female  Prefer Not to Answer  \n",
       "MaritalStatus                                 Single                Single  \n",
       "NumCompaniesPreviouslyWorked                     3.0                   7.0  \n",
       "AnnualProfessionalDevHrs                         NaN                   NaN  \n",
       "PaycheckMethod                          Mailed Check            Mail Check  \n",
       "TextMessageOptIn                                 Yes                   Yes  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A3 - Identify a sample of observable values for each variable.\n",
    "df.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "090ac463-e672-4f36-a984-e0cd83a8a6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(99)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B1 - Explain how you inspected the dataset to detect the following data quality issues: \n",
    "# Get total rows of duplicated data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3184fb9-d431-419c-9004-fde5c72c8c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Turnover</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>HoursWeekly</th>\n",
       "      <th>CompensationType</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>DrivingCommuterDistance</th>\n",
       "      <th>JobRoleArea</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumCompaniesPreviouslyWorked</th>\n",
       "      <th>AnnualProfessionalDevHrs</th>\n",
       "      <th>PaycheckMethod</th>\n",
       "      <th>TextMessageOptIn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10100</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>$24.37</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>50689.6</td>\n",
       "      <td>89</td>\n",
       "      <td>Research</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>$24.37</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>50689.6</td>\n",
       "      <td>89</td>\n",
       "      <td>Research</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>$22.52</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>46841.6</td>\n",
       "      <td>35</td>\n",
       "      <td>Information_Technology</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Mailed Check</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10103</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>$22.52</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>46841.6</td>\n",
       "      <td>35</td>\n",
       "      <td>Information_Technology</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mailed Check</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>$88.77</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>284641.6</td>\n",
       "      <td>12</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Prefer Not to Answer</td>\n",
       "      <td>Single</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10194</th>\n",
       "      <td>95</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>$85.40</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>177632.0</td>\n",
       "      <td>31</td>\n",
       "      <td>Research</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>No</td>\n",
       "      <td>$85.40</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>177632.0</td>\n",
       "      <td>31</td>\n",
       "      <td>Research</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>97</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>$71.90</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>149552.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>98</td>\n",
       "      <td>58</td>\n",
       "      <td>19</td>\n",
       "      <td>No</td>\n",
       "      <td>$71.90</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>149552.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>99</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>$71.33</td>\n",
       "      <td>40</td>\n",
       "      <td>Salary</td>\n",
       "      <td>148075.2</td>\n",
       "      <td>50</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Prefer Not to Answer</td>\n",
       "      <td>Married</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Mail Check</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EmployeeNumber  Age  Tenure Turnover HourlyRate   HoursWeekly  \\\n",
       "10100               1   28       6      Yes     $24.37            40   \n",
       "10101               2   33       2      Yes     $24.37            40   \n",
       "10102               3   22       1       No     $22.52            40   \n",
       "10103               4   23       1       No     $22.52            40   \n",
       "10104               5   40       6       No     $88.77            40   \n",
       "...               ...  ...     ...      ...         ...          ...   \n",
       "10194              95   48      13      Yes     $85.40            40   \n",
       "10195              96   54      17       No     $85.40            40   \n",
       "10196              97   44       6       No     $71.90            40   \n",
       "10197              98   58      19       No     $71.90            40   \n",
       "10198              99   48      17      Yes     $71.33            40   \n",
       "\n",
       "      CompensationType  AnnualSalary  DrivingCommuterDistance  \\\n",
       "10100           Salary       50689.6                       89   \n",
       "10101           Salary       50689.6                       89   \n",
       "10102           Salary       46841.6                       35   \n",
       "10103           Salary       46841.6                       35   \n",
       "10104           Salary      284641.6                       12   \n",
       "...                ...           ...                      ...   \n",
       "10194           Salary      177632.0                       31   \n",
       "10195           Salary      177632.0                       31   \n",
       "10196           Salary      149552.0                       32   \n",
       "10197           Salary      149552.0                       32   \n",
       "10198           Salary      148075.2                       50   \n",
       "\n",
       "                  JobRoleArea                Gender MaritalStatus  \\\n",
       "10100                Research                Female       Married   \n",
       "10101                Research                Female       Married   \n",
       "10102  Information_Technology                Female        Single   \n",
       "10103  Information_Technology                Female        Single   \n",
       "10104                   Sales  Prefer Not to Answer        Single   \n",
       "...                       ...                   ...           ...   \n",
       "10194                Research                  Male        Single   \n",
       "10195                Research                  Male        Single   \n",
       "10196               Marketing                  Male       Married   \n",
       "10197               Marketing                  Male       Married   \n",
       "10198                   Sales  Prefer Not to Answer       Married   \n",
       "\n",
       "       NumCompaniesPreviouslyWorked  AnnualProfessionalDevHrs PaycheckMethod  \\\n",
       "10100                           3.0                       7.0     Mail Check   \n",
       "10101                           6.0                       7.0     Mail Check   \n",
       "10102                           1.0                       8.0   Mailed Check   \n",
       "10103                           3.0                       NaN   Mailed Check   \n",
       "10104                           7.0                       NaN     Mail Check   \n",
       "...                             ...                       ...            ...   \n",
       "10194                           7.0                       5.0     Mail Check   \n",
       "10195                           2.0                      25.0     Mail Check   \n",
       "10196                           6.0                       NaN     Mail Check   \n",
       "10197                           5.0                      23.0     Mail Check   \n",
       "10198                           8.0                       8.0     Mail Check   \n",
       "\n",
       "      TextMessageOptIn  \n",
       "10100              Yes  \n",
       "10101              Yes  \n",
       "10102              Yes  \n",
       "10103              Yes  \n",
       "10104              Yes  \n",
       "...                ...  \n",
       "10194              NaN  \n",
       "10195              Yes  \n",
       "10196              Yes  \n",
       "10197              Yes  \n",
       "10198              Yes  \n",
       "\n",
       "[99 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B1 - Show duplicated data\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecf5ce5-d52f-406d-ad5c-b96cd3312eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Column': 'EmployeeNumber', 'Missing Count': np.int64(0), 'Missing %': '0.0%'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_missing_for_column(df, column_name):\n",
    "    if column_name not in df.columns:\n",
    "        return f\"Column '{column_name}' not found in DataFrame.\"\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    missing_count = df[column_name].isna().sum()\n",
    "    missing_percent = round((missing_count / total_rows) * 100, 2)\n",
    "    \n",
    "    return {\n",
    "        'Column': column_name,\n",
    "        'Missing Count': missing_count,\n",
    "        'Missing %': f\"{missing_percent}%\"\n",
    "    }\n",
    "check_missing_for_column(df, 'EmployeeNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576de35b-ae48-461b-b820-08edce62425d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "Name: EmployeeNumber, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - EmployeeNumber\n",
    "# Check first 5 rows of data\n",
    "df['EmployeeNumber'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865c6ffb-6a51-4e30-9ddc-fe60ebacb0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmployeeNumber                     0\n",
       "Age                                0\n",
       "Tenure                             0\n",
       "Turnover                           0\n",
       "HourlyRate                         0\n",
       "HoursWeekly                        0\n",
       "CompensationType                   0\n",
       "AnnualSalary                       0\n",
       "DrivingCommuterDistance            0\n",
       "JobRoleArea                        0\n",
       "Gender                             0\n",
       "MaritalStatus                      0\n",
       "NumCompaniesPreviouslyWorked     665\n",
       "AnnualProfessionalDevHrs        1969\n",
       "PaycheckMethod                     0\n",
       "TextMessageOptIn                2266\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b766e8d-e4fd-4a9d-9b13-beee7e1d7ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmployeeNumber                     0\n",
       "Age                                0\n",
       "Tenure                             0\n",
       "Turnover                           0\n",
       "HourlyRate                         0\n",
       "HoursWeekly                        0\n",
       "CompensationType                   0\n",
       "AnnualSalary                       0\n",
       "DrivingCommuterDistance            0\n",
       "JobRoleArea                        0\n",
       "Gender                             0\n",
       "MaritalStatus                      0\n",
       "NumCompaniesPreviouslyWorked     665\n",
       "AnnualProfessionalDevHrs        1969\n",
       "PaycheckMethod                     0\n",
       "TextMessageOptIn                2266\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B1 - Explain how you inspected the dataset to detect the following data quality issues: \n",
    "# missing values\n",
    "# Get the number of missing values p/comlumn\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2d440b6-6693-4100-a6f2-f677f8eea36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmployeeNumber                   0.000000\n",
       "Age                              0.000000\n",
       "Tenure                           0.000000\n",
       "Turnover                         0.000000\n",
       "HourlyRate                       0.000000\n",
       "HoursWeekly                      0.000000\n",
       "CompensationType                 0.000000\n",
       "AnnualSalary                     0.000000\n",
       "DrivingCommuterDistance          0.000000\n",
       "JobRoleArea                      0.000000\n",
       "Gender                           0.000000\n",
       "MaritalStatus                    0.000000\n",
       "NumCompaniesPreviouslyWorked     6.520247\n",
       "AnnualProfessionalDevHrs        19.305814\n",
       "PaycheckMethod                   0.000000\n",
       "TextMessageOptIn                22.217864\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B1 - missing values \n",
    "# Show percent of values missing by column.\n",
    "df.isna().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c3509a-81c0-4b63-8512-84cc3396152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turnover: ['Yes' 'No']\n",
      "HourlyRate : ['$24.37 ' '$22.52 ' '$88.77 ' ... '$30.86 ' '$95.07 ' '$93.05 ']\n",
      "CompensationType: ['Salary']\n",
      "JobRoleArea: ['Research' 'Information_Technology' 'Sales' 'Human_Resources'\n",
      " 'Laboratory' 'Manufacturing' 'Healthcare' 'Marketing'\n",
      " 'InformationTechnology' 'HumanResources' 'Information Technology'\n",
      " 'Human Resources']\n",
      "Gender: ['Female' 'Prefer Not to Answer' 'Male']\n",
      "MaritalStatus: ['Married' 'Single' 'Divorced']\n",
      "PaycheckMethod: ['Mail Check' 'Mailed Check' 'Direct_Deposit' 'DirectDeposit'\n",
      " 'Direct Deposit' 'Mail_Check' 'MailedCheck']\n",
      "TextMessageOptIn: ['Yes' nan 'No']\n"
     ]
    }
   ],
   "source": [
    "# B1 - inconsistent entries\n",
    "#  list all unique values in each categorical column\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    print(f\"{col}:\", df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d794ee63-6dae-446d-a7ad-f2ce5c5f5425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Count, count]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# B1 - inconsistent entries\n",
    "# Find rare categories\n",
    "def find_rare_categories(df, column, threshold=10):\n",
    "    value_counts = df[column].value_counts(dropna=False)\n",
    "    rare = value_counts[value_counts < threshold]\n",
    "    return rare.reset_index().rename(columns={'index': column, column: 'Count'})\n",
    "\n",
    "# Check rare JobRoleArea values\n",
    "rare_job_roles = find_rare_categories(df, 'JobRoleArea', threshold=10)\n",
    "print(rare_job_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9cb7a0d-0957-4ed2-b293-aa3bc754125b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmployeeNumber                    int64\n",
       "Age                               int64\n",
       "Tenure                            int64\n",
       "Turnover                         object\n",
       "HourlyRate                       object\n",
       "HoursWeekly                       int64\n",
       "CompensationType                 object\n",
       "AnnualSalary                    float64\n",
       "DrivingCommuterDistance           int64\n",
       "JobRoleArea                      object\n",
       "Gender                           object\n",
       "MaritalStatus                    object\n",
       "NumCompaniesPreviouslyWorked    float64\n",
       "AnnualProfessionalDevHrs        float64\n",
       "PaycheckMethod                   object\n",
       "TextMessageOptIn                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B1 - Formatting Errors\n",
    "# Check for data types to ensure each field is listed correctly\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40b6f8a-9d40-4f32-8a11-21b27b5aa108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'HourlyRate ' has entries with leading/trailing whitespace.\n",
      "Column 'JobRoleArea' has inconsistent casing:\n",
      "0                   Research\n",
      "1     Information_Technology\n",
      "2                      Sales\n",
      "3            Human_Resources\n",
      "4                 Laboratory\n",
      "5              Manufacturing\n",
      "6                 Healthcare\n",
      "7                  Marketing\n",
      "8      InformationTechnology\n",
      "9             HumanResources\n",
      "10    Information Technology\n",
      "11           Human Resources\n",
      "dtype: object\n",
      "Column 'Gender' has inconsistent casing:\n",
      "0                  Female\n",
      "1    Prefer Not to Answer\n",
      "2                    Male\n",
      "dtype: object\n",
      "Column 'PaycheckMethod' has inconsistent casing:\n",
      "0        Mail Check\n",
      "1      Mailed Check\n",
      "2    Direct_Deposit\n",
      "3     DirectDeposit\n",
      "4    Direct Deposit\n",
      "5        Mail_Check\n",
      "6       MailedCheck\n",
      "dtype: object\n",
      "Column 'HourlyRate ' contains special characters.\n"
     ]
    }
   ],
   "source": [
    "# B1 - Formatting issues\n",
    "# 1. Check for leading/trailing whitespace in string columns (before cleaning)\n",
    "string_columns = df.select_dtypes(include='object').columns\n",
    "for col in string_columns:\n",
    "    whitespace_issues = df[col].apply(lambda x: isinstance(x, str) and (x != x.strip()))\n",
    "    if whitespace_issues.any():\n",
    "        print(f\"Column '{col}' has entries with leading/trailing whitespace.\")\n",
    "\n",
    "# 2. Check for inconsistent casing\n",
    "for col in string_columns:\n",
    "    unique_vals = df[col].dropna().unique()\n",
    "    if any(v != v.title() for v in unique_vals if isinstance(v, str)):\n",
    "        print(f\"Column '{col}' has inconsistent casing:\")\n",
    "        print(pd.Series(unique_vals))\n",
    "\n",
    "# 3. Check for special characters or formatting symbols in string columns\n",
    "import re\n",
    "for col in string_columns:\n",
    "    if df[col].astype(str).str.contains(r'[\\$%#@!&*]', regex=True).any():\n",
    "        print(f\"Column '{col}' contains special characters.\")\n",
    "\n",
    "# 4. Check for unexpected numeric types stored as objects\n",
    "for col in string_columns:\n",
    "    sample = df[col].dropna().sample(n=min(100, df[col].dropna().shape[0]), random_state=1)\n",
    "    if sample.apply(lambda x: str(x).replace('.', '', 1).isdigit()).mean() > 0.8:\n",
    "        print(f\"Column '{col}' may be numeric but stored as object.\")\n",
    "\n",
    "# 5. Check for placeholder or dummy values (e.g., 'N/A', 'unknown', '-')\n",
    "placeholder_values = ['n/a', 'na', 'unknown', '-', '--', 'none', 'null']\n",
    "for col in string_columns:\n",
    "    found = df[col].astype(str).str.lower().isin(placeholder_values).sum()\n",
    "    if found > 0:\n",
    "        print(f\"Column '{col}' has {found} placeholder or dummy values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "580346bf-288e-4ee2-bdb3-9b9bd5c21a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0   None\n",
      "1   None\n",
      "2   None\n",
      "3   None\n",
      "4   None\n",
      "5   None\n",
      "6   None\n",
      "7   None\n",
      "8   None\n",
      "9   None\n",
      "10  None\n",
      "11  None\n",
      "12  None\n",
      "13  None\n",
      "14  None\n",
      "15  None\n"
     ]
    }
   ],
   "source": [
    "summary_df = inspect_columns(df, df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcfec45-4f09-44f9-830c-c915e977a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "def inspect_data_quality(df: pd.DataFrame, \n",
    "                        numeric_columns: List[str] = None,\n",
    "                        categorical_columns: List[str] = None,\n",
    "                        outlier_method: str = 'iqr',\n",
    "                        outlier_threshold: float = 1.5) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Comprehensive data quality inspection function that checks for:\n",
    "    - Duplicate entries\n",
    "    - Missing values\n",
    "    - Inconsistent entries\n",
    "    - Formatting errors\n",
    "    - Outliers\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe to inspect\n",
    "    numeric_columns : List[str], optional\n",
    "        List of numeric column names. If None, will auto-detect\n",
    "    categorical_columns : List[str], optional\n",
    "        List of categorical column names. If None, will auto-detect\n",
    "    outlier_method : str, default 'iqr'\n",
    "        Method for outlier detection ('iqr', 'zscore', 'modified_zscore')\n",
    "    outlier_threshold : float, default 1.5\n",
    "        Threshold for outlier detection\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict[str, Any] : Comprehensive report of data quality issues\n",
    "    \"\"\"\n",
    "    \n",
    "    report = {\n",
    "        'dataset_overview': {},\n",
    "        'duplicates': {},\n",
    "        'missing_values': {},\n",
    "        'inconsistent_entries': {},\n",
    "        'formatting_errors': {},\n",
    "        'outliers': {},\n",
    "        'summary': {}\n",
    "    }\n",
    "    \n",
    "    # Dataset Overview\n",
    "    report['dataset_overview'] = {\n",
    "        'total_rows': len(df),\n",
    "        'total_columns': len(df.columns),\n",
    "        'columns': list(df.columns),\n",
    "        'data_types': df.dtypes.to_dict()\n",
    "    }\n",
    "    \n",
    "    # Auto-detect column types if not specified\n",
    "    if numeric_columns is None:\n",
    "        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # 1. DUPLICATE ENTRIES\n",
    "    print(\"üîç Checking for duplicate entries...\")\n",
    "    \n",
    "    # Full row duplicates\n",
    "    full_duplicates = df.duplicated()\n",
    "    report['duplicates']['full_row_duplicates'] = {\n",
    "        'count': full_duplicates.sum(),\n",
    "        'percentage': (full_duplicates.sum() / len(df)) * 100,\n",
    "        'duplicate_indices': df[full_duplicates].index.tolist()\n",
    "    }\n",
    "    \n",
    "    # Column-wise duplicate analysis\n",
    "    column_duplicates = {}\n",
    "    for col in df.columns:\n",
    "        col_dups = df[col].duplicated()\n",
    "        column_duplicates[col] = {\n",
    "            'count': col_dups.sum(),\n",
    "            'percentage': (col_dups.sum() / len(df)) * 100,\n",
    "            'unique_values': df[col].nunique(),\n",
    "            'unique_percentage': (df[col].nunique() / len(df)) * 100\n",
    "        }\n",
    "    \n",
    "    report['duplicates']['column_wise'] = column_duplicates\n",
    "    \n",
    "    # 2. MISSING VALUES\n",
    "    print(\"üîç Checking for missing values...\")\n",
    "    \n",
    "    missing_stats = {}\n",
    "    for col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        missing_stats[col] = {\n",
    "            'count': int(missing_count),\n",
    "            'percentage': (missing_count / len(df)) * 100,\n",
    "            'missing_indices': df[df[col].isnull()].index.tolist()\n",
    "        }\n",
    "        \n",
    "        # Check for different representations of missing values\n",
    "        if df[col].dtype == 'object':\n",
    "            potential_missing = df[col].isin(['', ' ', 'NULL', 'null', 'NaN', 'nan', 'N/A', 'n/a', 'None', 'none'])\n",
    "            if potential_missing.sum() > 0:\n",
    "                missing_stats[col]['potential_missing_representations'] = {\n",
    "                    'count': int(potential_missing.sum()),\n",
    "                    'values': df[potential_missing][col].value_counts().to_dict()\n",
    "                }\n",
    "    \n",
    "    report['missing_values'] = missing_stats\n",
    "    \n",
    "    # 3. INCONSISTENT ENTRIES\n",
    "    print(\"üîç Checking for inconsistent entries...\")\n",
    "    \n",
    "    inconsistency_report = {}\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in df.columns:\n",
    "            inconsistencies = {}\n",
    "            \n",
    "            # Case variations\n",
    "            if df[col].dtype == 'object':\n",
    "                values = df[col].dropna().astype(str)\n",
    "                case_variations = {}\n",
    "                \n",
    "                # Group by lowercase to find case variations\n",
    "                lowercase_groups = values.str.lower().value_counts()\n",
    "                for lower_val in lowercase_groups.index:\n",
    "                    original_variations = values[values.str.lower() == lower_val].unique()\n",
    "                    if len(original_variations) > 1:\n",
    "                        case_variations[lower_val] = original_variations.tolist()\n",
    "                \n",
    "                if case_variations:\n",
    "                    inconsistencies['case_variations'] = case_variations\n",
    "                \n",
    "                # Whitespace issues\n",
    "                whitespace_issues = {}\n",
    "                for val in values.unique():\n",
    "                    if val != val.strip():\n",
    "                        whitespace_issues[val] = val.strip()\n",
    "                \n",
    "                if whitespace_issues:\n",
    "                    inconsistencies['whitespace_issues'] = whitespace_issues\n",
    "                \n",
    "                # Similar values (potential typos)\n",
    "                from difflib import SequenceMatcher\n",
    "                unique_vals = values.unique()\n",
    "                similar_pairs = []\n",
    "                \n",
    "                for i, val1 in enumerate(unique_vals):\n",
    "                    for val2 in unique_vals[i+1:]:\n",
    "                        similarity = SequenceMatcher(None, str(val1).lower(), str(val2).lower()).ratio()\n",
    "                        if 0.8 <= similarity < 1.0:  # High similarity but not identical\n",
    "                            similar_pairs.append({\n",
    "                                'value1': val1,\n",
    "                                'value2': val2,\n",
    "                                'similarity': similarity,\n",
    "                                'count1': (values == val1).sum(),\n",
    "                                'count2': (values == val2).sum()\n",
    "                            })\n",
    "                \n",
    "                if similar_pairs:\n",
    "                    inconsistencies['similar_values'] = similar_pairs\n",
    "            \n",
    "            if inconsistencies:\n",
    "                inconsistency_report[col] = inconsistencies\n",
    "    \n",
    "    report['inconsistent_entries'] = inconsistency_report\n",
    "    \n",
    "    # 4. FORMATTING ERRORS\n",
    "    print(\"üîç Checking for formatting errors...\")\n",
    "    \n",
    "    formatting_errors = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_errors = {}\n",
    "        \n",
    "        if df[col].dtype == 'object':\n",
    "            values = df[col].dropna().astype(str)\n",
    "            \n",
    "            # Check for mixed data types in string columns\n",
    "            numeric_pattern = re.compile(r'^-?\\d+\\.?\\d*$')\n",
    "            date_pattern = re.compile(r'\\d{1,4}[-/]\\d{1,2}[-/]\\d{1,4}')\n",
    "            email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n",
    "            \n",
    "            mixed_types = {\n",
    "                'numeric_like': values[values.str.match(numeric_pattern, na=False)].tolist(),\n",
    "                'date_like': values[values.str.match(date_pattern, na=False)].tolist(),\n",
    "                'email_like': values[values.str.match(email_pattern, na=False)].tolist()\n",
    "            }\n",
    "            \n",
    "            # Remove empty lists\n",
    "            mixed_types = {k: v for k, v in mixed_types.items() if v}\n",
    "            if mixed_types:\n",
    "                col_errors['mixed_data_types'] = mixed_types\n",
    "            \n",
    "            # Check for unusual characters or encoding issues\n",
    "            unusual_chars = []\n",
    "            for val in values.unique()[:100]:  # Check first 100 unique values\n",
    "                if any(ord(char) > 127 for char in str(val)):  # Non-ASCII characters\n",
    "                    unusual_chars.append(val)\n",
    "            \n",
    "            if unusual_chars:\n",
    "                col_errors['unusual_characters'] = unusual_chars[:10]  # Show first 10\n",
    "        \n",
    "        # Check numeric columns stored as strings\n",
    "        elif col in numeric_columns and df[col].dtype == 'object':\n",
    "            non_numeric = df[~df[col].str.match(r'^-?\\d+\\.?\\d*$', na=False)][col].dropna()\n",
    "            if len(non_numeric) > 0:\n",
    "                col_errors['non_numeric_in_numeric_column'] = non_numeric.tolist()[:10]\n",
    "        \n",
    "        if col_errors:\n",
    "            formatting_errors[col] = col_errors\n",
    "    \n",
    "    report['formatting_errors'] = formatting_errors\n",
    "    \n",
    "    # 5. OUTLIERS\n",
    "    print(\"üîç Checking for outliers...\")\n",
    "    \n",
    "    outlier_report = {}\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns and df[col].dtype in ['int64', 'float64']:\n",
    "            col_data = df[col].dropna()\n",
    "            \n",
    "            if len(col_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            outliers = {}\n",
    "            \n",
    "            if outlier_method == 'iqr':\n",
    "                Q1 = col_data.quantile(0.25)\n",
    "                Q3 = col_data.quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - outlier_threshold * IQR\n",
    "                upper_bound = Q3 + outlier_threshold * IQR\n",
    "                \n",
    "                outlier_mask = (col_data < lower_bound) | (col_data > upper_bound)\n",
    "                outlier_values = col_data[outlier_mask]\n",
    "                \n",
    "                outliers['method'] = 'IQR'\n",
    "                outliers['bounds'] = {'lower': lower_bound, 'upper': upper_bound}\n",
    "                \n",
    "            elif outlier_method == 'zscore':\n",
    "                z_scores = np.abs((col_data - col_data.mean()) / col_data.std())\n",
    "                outlier_mask = z_scores > outlier_threshold\n",
    "                outlier_values = col_data[outlier_mask]\n",
    "                \n",
    "                outliers['method'] = 'Z-Score'\n",
    "                outliers['threshold'] = outlier_threshold\n",
    "                \n",
    "            elif outlier_method == 'modified_zscore':\n",
    "                median = col_data.median()\n",
    "                mad = np.median(np.abs(col_data - median))\n",
    "                modified_z_scores = 0.6745 * (col_data - median) / mad\n",
    "                outlier_mask = np.abs(modified_z_scores) > outlier_threshold\n",
    "                outlier_values = col_data[outlier_mask]\n",
    "                \n",
    "                outliers['method'] = 'Modified Z-Score'\n",
    "                outliers['threshold'] = outlier_threshold\n",
    "            \n",
    "            if len(outlier_values) > 0:\n",
    "                outliers.update({\n",
    "                    'count': len(outlier_values),\n",
    "                    'percentage': (len(outlier_values) / len(col_data)) * 100,\n",
    "                    'values': outlier_values.tolist(),\n",
    "                    'indices': outlier_values.index.tolist(),\n",
    "                    'statistics': {\n",
    "                        'min_outlier': outlier_values.min(),\n",
    "                        'max_outlier': outlier_values.max(),\n",
    "                        'mean_outlier': outlier_values.mean()\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "                outlier_report[col] = outliers\n",
    "    \n",
    "    report['outliers'] = outlier_report\n",
    "    \n",
    "    # 6. SUMMARY\n",
    "    print(\"üìä Generating summary...\")\n",
    "    \n",
    "    total_issues = 0\n",
    "    issue_categories = []\n",
    "    \n",
    "    if report['duplicates']['full_row_duplicates']['count'] > 0:\n",
    "        total_issues += report['duplicates']['full_row_duplicates']['count']\n",
    "        issue_categories.append('duplicates')\n",
    "    \n",
    "    missing_issues = sum([stats['count'] for stats in report['missing_values'].values()])\n",
    "    if missing_issues > 0:\n",
    "        total_issues += missing_issues\n",
    "        issue_categories.append('missing_values')\n",
    "    \n",
    "    if report['inconsistent_entries']:\n",
    "        total_issues += len(report['inconsistent_entries'])\n",
    "        issue_categories.append('inconsistent_entries')\n",
    "    \n",
    "    if report['formatting_errors']:\n",
    "        total_issues += len(report['formatting_errors'])\n",
    "        issue_categories.append('formatting_errors')\n",
    "    \n",
    "    outlier_issues = sum([stats['count'] for stats in report['outliers'].values()])\n",
    "    if outlier_issues > 0:\n",
    "        total_issues += outlier_issues\n",
    "        issue_categories.append('outliers')\n",
    "    \n",
    "    report['summary'] = {\n",
    "        'total_issues_found': total_issues,\n",
    "        'issue_categories': issue_categories,\n",
    "        'data_quality_score': max(0, 100 - (total_issues / len(df)) * 100),\n",
    "        'recommendations': []\n",
    "    }\n",
    "    \n",
    "    # Add recommendations\n",
    "    recommendations = []\n",
    "    if report['duplicates']['full_row_duplicates']['count'] > 0:\n",
    "        recommendations.append(\"Remove duplicate rows to improve data integrity\")\n",
    "    if missing_issues > 0:\n",
    "        recommendations.append(\"Handle missing values through imputation or removal\")\n",
    "    if report['inconsistent_entries']:\n",
    "        recommendations.append(\"Standardize categorical values and fix case/whitespace issues\")\n",
    "    if report['formatting_errors']:\n",
    "        recommendations.append(\"Clean formatting errors and ensure consistent data types\")\n",
    "    if outlier_issues > 0:\n",
    "        recommendations.append(\"Investigate outliers - they may indicate data errors or genuine extreme values\")\n",
    "    \n",
    "    report['summary']['recommendations'] = recommendations\n",
    "    \n",
    "    print(\"‚úÖ Data quality inspection completed!\")\n",
    "    return report\n",
    "\n",
    "def print_quality_report(report: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Print a formatted version of the data quality report\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìã DATA QUALITY INSPECTION REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Dataset Overview\n",
    "    print(\"\\nüìä DATASET OVERVIEW\")\n",
    "    print(\"-\" * 40)\n",
    "    overview = report['dataset_overview']\n",
    "    print(f\"Total Rows: {overview['total_rows']:,}\")\n",
    "    print(f\"Total Columns: {overview['total_columns']}\")\n",
    "    print(f\"Columns: {', '.join(overview['columns'])}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nüéØ SUMMARY\")\n",
    "    print(\"-\" * 40)\n",
    "    summary = report['summary']\n",
    "    print(f\"Data Quality Score: {summary['data_quality_score']:.1f}/100\")\n",
    "    print(f\"Total Issues Found: {summary['total_issues_found']:,}\")\n",
    "    print(f\"Issue Categories: {', '.join(summary['issue_categories']) if summary['issue_categories'] else 'None'}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    if summary['recommendations']:\n",
    "        print(\"\\nüí° RECOMMENDATIONS\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, rec in enumerate(summary['recommendations'], 1):\n",
    "            print(f\"{i}. {rec}\")\n",
    "    \n",
    "    # Detailed findings\n",
    "    print(\"\\nüîç DETAILED FINDINGS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Duplicates\n",
    "    dup_count = report['duplicates']['full_row_duplicates']['count']\n",
    "    print(f\"Duplicate Rows: {dup_count:,} ({report['duplicates']['full_row_duplicates']['percentage']:.2f}%)\")\n",
    "    \n",
    "    # Missing Values\n",
    "    missing_cols = [col for col, stats in report['missing_values'].items() if stats['count'] > 0]\n",
    "    print(f\"Columns with Missing Values: {len(missing_cols)}\")\n",
    "    if missing_cols:\n",
    "        for col in missing_cols[:5]:  # Show top 5\n",
    "            stats = report['missing_values'][col]\n",
    "            print(f\"  ‚Ä¢ {col}: {stats['count']:,} missing ({stats['percentage']:.2f}%)\")\n",
    "    \n",
    "    # Inconsistencies\n",
    "    inconsistent_cols = len(report['inconsistent_entries'])\n",
    "    print(f\"Columns with Inconsistencies: {inconsistent_cols}\")\n",
    "    \n",
    "    # Formatting Errors\n",
    "    format_error_cols = len(report['formatting_errors'])\n",
    "    print(f\"Columns with Formatting Errors: {format_error_cols}\")\n",
    "    \n",
    "    # Outliers\n",
    "    outlier_cols = len(report['outliers'])\n",
    "    print(f\"Columns with Outliers: {outlier_cols}\")\n",
    "    if outlier_cols > 0:\n",
    "        for col, stats in list(report['outliers'].items())[:3]:  # Show top 3\n",
    "            print(f\"  ‚Ä¢ {col}: {stats['count']:,} outliers ({stats['percentage']:.2f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset\n",
    "    df = pd.read_csv('Employee Turnover Dataset.csv')\n",
    "    \n",
    "    # Define column types (adjust based on your data)\n",
    "    numeric_cols = ['EmployeeNumber', 'Age', 'Tenure', 'HoursWeekly', \n",
    "                   'AnnualSalary', 'DrivingCommuterDistance', \n",
    "                   'NumCompaniesPreviouslyWorked', 'AnnualProfessionalDevHrs']\n",
    "    \n",
    "    categorical_cols = ['Turnover', 'HourlyRate ', 'CompensationType', \n",
    "                       'JobRoleArea', 'Gender', 'MaritalStatus', \n",
    "                       'PaycheckMethod', 'TextMessageOptIn']\n",
    "    \n",
    "    # Run inspection\n",
    "    quality_report = inspect_data_quality(\n",
    "        df, \n",
    "        numeric_columns=numeric_cols,\n",
    "        categorical_columns=categorical_cols,\n",
    "        outlier_method='iqr',\n",
    "        outlier_threshold=1.5\n",
    "    )\n",
    "    \n",
    "    # Print formatted report\n",
    "    print_quality_report(quality_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04205964-d067-469f-909c-b2e720c87143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1 - Formatting issues\n",
    "df['Gender'].value_counts()  # or compare .str.lower() vs .str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1981b1-ef64-411a-9a46-b3ac9326854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1 - Outliers\n",
    "# Annual Salary - Look for outliers in an inv\n",
    "sns.boxplot(x=df['AnnualSalary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6edb2f-6908-4902-9526-b4313463b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1 - Outliers \n",
    "# Age\n",
    "sns.boxplot(x=df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d622fd79-19c6-45fc-9595-1b655ad584f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1 - Outliers\n",
    "# Driving Communter Distance\n",
    "sns.boxplot(x=df['DrivingCommuterDistance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86237b3a-0399-4029-b69c-e96b249b6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1 - Outliers\n",
    "# Annual Professional DevHrs\n",
    "sns.boxplot(x=df['AnnualProfessionalDevHrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ea8a5-751b-4f40-b3aa-5a92e43b8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = zscore(df['AnnualSalary'].dropna())\n",
    "outliers = df[(abs(z_scores) > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2286b-479d-44cd-9dbf-fff87630ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# C - Clean the data\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 0: Strip column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Step 1: Remove Duplicates\n",
    "df_cleaned = df.drop_duplicates().copy()\n",
    "\n",
    "# Step 2: Handle Missing Values\n",
    "if 'AnnualProfessionalDevHrs' in df_cleaned.columns:\n",
    "    median_dev_hours = df_cleaned['AnnualProfessionalDevHrs'].median()\n",
    "    df_cleaned.loc[:, 'AnnualProfessionalDevHrs'] = df_cleaned['AnnualProfessionalDevHrs'].fillna(median_dev_hours)\n",
    "\n",
    "# Step 3: Fix Inconsistent Entries\n",
    "if 'PaycheckMethod' in df_cleaned.columns:\n",
    "    df_cleaned.loc[:, 'PaycheckMethod'] = (\n",
    "        df_cleaned['PaycheckMethod']\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .replace({\n",
    "            'Mailed Check': 'Mail Check',\n",
    "            'Mail_Check': 'Mail Check',\n",
    "            'Mailedcheck': 'Mail Check',\n",
    "            'DirectDeposit': 'Direct Deposit',\n",
    "            'Direct_Deposit': 'Direct Deposit'\n",
    "        })\n",
    "    )\n",
    "\n",
    "if 'JobRoleArea' in df_cleaned.columns:\n",
    "    df_cleaned.loc[:, 'JobRoleArea'] = df_cleaned['JobRoleArea'].replace({\n",
    "        'InformationTechnology': 'Information Technology',\n",
    "        'Information_Technology': 'Information Technology',\n",
    "        'HumanResources': 'Human Resources',\n",
    "        'Human_Resources': 'Human Resources'\n",
    "    })\n",
    "\n",
    "text_columns = ['Gender', 'MaritalStatus', 'CompensationType', 'JobRoleArea', 'TextMessageOptIn', 'PaycheckMethod']\n",
    "for col in text_columns:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned.loc[:, col] = df_cleaned[col].astype(str).str.strip().str.title()\n",
    "\n",
    "# Step 4: Fix Formatting\n",
    "if 'HourlyRate' in df_cleaned.columns and df_cleaned['HourlyRate'].dtype == 'object':\n",
    "    df_cleaned.loc[:, 'HourlyRate'] = (\n",
    "        df_cleaned['HourlyRate']\n",
    "        .astype(str)\n",
    "        .str.replace('$', '', regex=False)\n",
    "        .str.strip()\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# Safely strip whitespace from all object-type string fields\n",
    "for col in df_cleaned.select_dtypes(include='object').columns:\n",
    "    df_cleaned.loc[:, col] = df_cleaned[col].astype(str).str.strip()\n",
    "\n",
    "# Step 5: Handle Outliers\n",
    "if 'AnnualSalary' in df_cleaned.columns:\n",
    "    Q1 = df_cleaned['AnnualSalary'].quantile(0.25)\n",
    "    Q3 = df_cleaned['AnnualSalary'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_cleaned.loc[:, 'AnnualSalary'] = df_cleaned['AnnualSalary'].apply(lambda x: min(x, upper_bound))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588d09e-74bb-4145-96fe-5c5391ad6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values post cleaning\n",
    "for col in df_cleaned.select_dtypes(include='object'):\n",
    "    print(f\"{col}:\", df_cleaned[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c5c5d-6816-48b3-a0e2-0ea1f1fe56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned file\n",
    "df_cleaned.to_csv('Employee_Turnover_Cleaned.csv', index=False)\n",
    "print('Cleaned File exported')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shap_env_new)",
   "language": "python",
   "name": "shap_env_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
