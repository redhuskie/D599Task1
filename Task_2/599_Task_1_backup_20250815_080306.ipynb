{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe19916-2d90-4dfe-ac7b-dff0975f9872",
   "metadata": {},
   "source": [
    "## WGU D599: Data Preparation and Exploration\n",
    "#### John D. Pickering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819136ef-1e47-4f30-b569-c2ba7710608b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac34f2-cf2c-4c0c-933d-42a91f591665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import plotly\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e10da3-c10e-449a-918c-649532b4bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset into pandas as df\n",
    "df = pd.read_csv('Employee Turnover Dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9761676e-13e6-4cd7-b095-24ba60bc9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1 - Identify the number of records and variables (columns)\n",
    "# Rows: 10199\n",
    "# Columns: 16\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4b713-cec1-466c-8008-f037acc3cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2 - List each variable and indicate the variable’s data type \n",
    "# (quantitative/numerical or qualitative/categorical) and data subtype (i.e., continuous/discrete or nominal/ordinal).\n",
    "def variable_type_summary(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Pandas_Dtype': df.dtypes.astype(str),\n",
    "        'Non_Null_Count': df.notnull().sum()\n",
    "    })\n",
    "\n",
    "    summary['Variable_Type'] = summary['Pandas_Dtype'].apply(lambda x:\n",
    "        'Quantitative' if 'int' in x or 'float' in x else\n",
    "        'Qualitative'\n",
    "    )\n",
    "\n",
    "    def guess_subtype(col):\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            unique_vals = df[col].dropna().unique()\n",
    "            if df[col].dtype == 'int64' and len(unique_vals) < 20:\n",
    "                return 'Discrete'\n",
    "            else:\n",
    "                return 'Continuous'\n",
    "        elif df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "            n_unique = df[col].nunique()\n",
    "            if n_unique < 10:\n",
    "                unique_vals = df[col].dropna().unique()\n",
    "                return 'Ordinal' if sorted(unique_vals) == list(unique_vals) else 'Nominal'\n",
    "            else:\n",
    "                return 'Nominal'\n",
    "        return 'Unknown'\n",
    "\n",
    "    summary['Subtype'] = summary['Column'].apply(guess_subtype)\n",
    "\n",
    "    return summary[['Column', 'Pandas_Dtype', 'Variable_Type', 'Subtype']]\n",
    "\n",
    "summary_table = variable_type_summary(df)\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd99ed-e648-46b6-ad52-58d664f723e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3 - Identify a sample of observable values for each variable.\n",
    "df.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f37be-c20f-462f-a84c-9915f65a1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total rows of duplicated data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0728f-729b-4c23-b926-4365d3c21ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1 - Show duplicated data\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c50d68-d030-430e-970d-d588217569a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# B2 - Inspection\n",
    "# Start Inspection\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style for Jupyter\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "def inspect_data_quality(df: pd.DataFrame, \n",
    "                        numeric_columns: List[str] = None,\n",
    "                        categorical_columns: List[str] = None,\n",
    "                        outlier_method: str = 'iqr',\n",
    "                        outlier_threshold: float = 1.5,\n",
    "                        show_plots: bool = True) -> Dict[str, Any]:\n",
    "  \n",
    "    \n",
    "    print(\" STARTING DATA QUALITY INSPECTION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    report = {\n",
    "        'dataset_overview': {},\n",
    "        'duplicates': {},\n",
    "        'missing_values': {},\n",
    "        'inconsistent_entries': {},\n",
    "        'formatting_errors': {},\n",
    "        'outliers': {},\n",
    "        'summary': {}\n",
    "    }\n",
    "    \n",
    "    # Dataset Overview\n",
    "    report['dataset_overview'] = {\n",
    "        'total_rows': len(df),\n",
    "        'total_columns': len(df.columns),\n",
    "        'columns': list(df.columns),\n",
    "        'data_types': df.dtypes.to_dict(),\n",
    "        'memory_usage': df.memory_usage(deep=True).sum()\n",
    "    }\n",
    "    \n",
    "    # Detect column types\n",
    "    if numeric_columns is None:\n",
    "        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\" Dataset: {len(df):,} rows × {len(df.columns)} columns\")\n",
    "    print(f\" Numeric columns: {len(numeric_columns)}\")\n",
    "    print(f\" Categorical columns: {len(categorical_columns)}\")\n",
    "    print()\n",
    "    \n",
    "    # 1. DUPLICATE ENTRIES\n",
    "    print(\"1. CHECKING DUPLICATE ENTRIES...\")\n",
    "    \n",
    "    # Full row duplicates\n",
    "    full_duplicates = df.duplicated()\n",
    "    duplicate_rows = df[full_duplicates]\n",
    "    \n",
    "    report['duplicates']['full_row_duplicates'] = {\n",
    "        'count': full_duplicates.sum(),\n",
    "        'percentage': (full_duplicates.sum() / len(df)) * 100,\n",
    "        'duplicate_indices': duplicate_rows.index.tolist()\n",
    "    }\n",
    "    \n",
    "    # Column-wise duplicate analysis\n",
    "    column_duplicates = {}\n",
    "    for col in df.columns:\n",
    "        col_dups = df[col].duplicated()\n",
    "        column_duplicates[col] = {\n",
    "            'count': col_dups.sum(),\n",
    "            'percentage': (col_dups.sum() / len(df)) * 100,\n",
    "            'unique_values': df[col].nunique(),\n",
    "            'unique_percentage': (df[col].nunique() / len(df)) * 100\n",
    "        }\n",
    "    \n",
    "    report['duplicates']['column_wise'] = column_duplicates\n",
    "    \n",
    "    print(f\"Full row duplicates: {full_duplicates.sum():,} ({(full_duplicates.sum() / len(df)) * 100:.2f}%)\")\n",
    "    \n",
    "    if show_plots and len(df.columns) <= 20:  \n",
    "        # Visualization: Uniqueness by column\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "        unique_percentages = [column_duplicates[col]['unique_percentage'] for col in df.columns]\n",
    "        \n",
    "        bars = ax.bar(range(len(df.columns)), unique_percentages, color='skyblue', alpha=0.7)\n",
    "        ax.set_xlabel('Columns')\n",
    "        ax.set_ylabel('Unique Values (%)')\n",
    "        ax.set_title('Uniqueness Percentage by Column')\n",
    "        ax.set_xticks(range(len(df.columns)))\n",
    "        ax.set_xticklabels(df.columns, rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, val in zip(bars, unique_percentages):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                   f'{val:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # 2. MISSING VALUES\n",
    "    print(\"\\n2. CHECKING MISSING VALUES...\")\n",
    "    \n",
    "    missing_stats = {}\n",
    "    total_missing = 0\n",
    "    \n",
    "    for col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        missing_stats[col] = {\n",
    "            'count': int(missing_count),\n",
    "            'percentage': (missing_count / len(df)) * 100,\n",
    "            'missing_indices': df[df[col].isnull()].index.tolist()\n",
    "        }\n",
    "        total_missing += missing_count\n",
    "        \n",
    "        # Check for different representations of missing values\n",
    "        if df[col].dtype == 'object':\n",
    "            potential_missing = df[col].isin(['', ' ', 'NULL', 'null', 'NaN', 'nan', 'N/A', 'n/a', 'None', 'none'])\n",
    "            if potential_missing.sum() > 0:\n",
    "                missing_stats[col]['potential_missing_representations'] = {\n",
    "                    'count': int(potential_missing.sum()),\n",
    "                    'values': df[potential_missing][col].value_counts().to_dict()\n",
    "                }\n",
    "    \n",
    "    report['missing_values'] = missing_stats\n",
    "    print(f\"Total missing values: {total_missing:,} ({(total_missing / (len(df) * len(df.columns))) * 100:.2f}% of all data)\")\n",
    "    \n",
    "    # Show columns with missing values\n",
    "    missing_cols = [(col, stats['count'], stats['percentage']) \n",
    "                   for col, stats in missing_stats.items() if stats['count'] > 0]\n",
    "    if missing_cols:\n",
    "        print(\"  Columns with missing values:\")\n",
    "        for col, count, pct in sorted(missing_cols, key=lambda x: x[2], reverse=True)[:10]:\n",
    "            print(f\"      • {col}: {count:,} ({pct:.2f}%)\")\n",
    "    \n",
    "    if show_plots and missing_cols:\n",
    "        # Visualization: Missing values heatmap\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Missing values by column (bar chart)\n",
    "        cols, counts, pcts = zip(*missing_cols) if missing_cols else ([], [], [])\n",
    "        ax1.barh(range(len(cols)), pcts, color='coral', alpha=0.7)\n",
    "        ax1.set_yticks(range(len(cols)))\n",
    "        ax1.set_yticklabels(cols)\n",
    "        ax1.set_xlabel('Missing Values (%)')\n",
    "        ax1.set_title('Missing Values by Column')\n",
    "        \n",
    "        # Missing values heatmap\n",
    "        if len(df) <= 1000:  # Only for smaller datasets\n",
    "            missing_matrix = df.isnull()\n",
    "            sns.heatmap(missing_matrix.T, cbar=True, ax=ax2, cmap='RdYlBu_r')\n",
    "            ax2.set_title('Missing Values Pattern (Sample)')\n",
    "            ax2.set_xlabel('Row Index')\n",
    "        else:\n",
    "            # Sample for large datasets\n",
    "            sample_df = df.sample(min(1000, len(df)), random_state=42)\n",
    "            missing_matrix = sample_df.isnull()\n",
    "            sns.heatmap(missing_matrix.T, cbar=True, ax=ax2, cmap='RdYlBu_r')\n",
    "            ax2.set_title('Missing Values Pattern (Random Sample)')\n",
    "            ax2.set_xlabel('Sample Row Index')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. INCONSISTENT ENTRIES\n",
    "    print(\"\\n 3. CHECKING INCONSISTENT ENTRIES...\")\n",
    "    \n",
    "    inconsistency_report = {}\n",
    "    total_inconsistencies = 0\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in df.columns:\n",
    "            inconsistencies = {}\n",
    "            \n",
    "            # Case variations\n",
    "            if df[col].dtype == 'object':\n",
    "                values = df[col].dropna().astype(str)\n",
    "                case_variations = {}\n",
    "                \n",
    "                # Group by lowercase to find case variations\n",
    "                lowercase_groups = values.str.lower().value_counts()\n",
    "                for lower_val in lowercase_groups.index:\n",
    "                    original_variations = values[values.str.lower() == lower_val].unique()\n",
    "                    if len(original_variations) > 1:\n",
    "                        case_variations[lower_val] = original_variations.tolist()\n",
    "                \n",
    "                if case_variations:\n",
    "                    inconsistencies['case_variations'] = case_variations\n",
    "                    total_inconsistencies += len(case_variations)\n",
    "                \n",
    "                # Whitespace issues\n",
    "                whitespace_issues = {}\n",
    "                for val in values.unique():\n",
    "                    if val != val.strip():\n",
    "                        whitespace_issues[val] = val.strip()\n",
    "                \n",
    "                if whitespace_issues:\n",
    "                    inconsistencies['whitespace_issues'] = whitespace_issues\n",
    "                    total_inconsistencies += len(whitespace_issues)\n",
    "                \n",
    "                # Similar values and standardization issues\n",
    "                from difflib import SequenceMatcher\n",
    "                unique_vals = values.unique()\n",
    "                similar_pairs = []\n",
    "                \n",
    "                # Enhanced standardization issue detection\n",
    "                standardization_groups = {}\n",
    "                \n",
    "                # Limit comparison for performance\n",
    "                if len(unique_vals) <= 100:\n",
    "                    for i, val1 in enumerate(unique_vals):\n",
    "                        for val2 in unique_vals[i+1:]:\n",
    "                            if len(str(val1)) > 2 and len(str(val2)) > 2:  # Skip very short strings\n",
    "                                \n",
    "                                # Create normalized versions for comparison\n",
    "                                norm_val1 = str(val1).lower().replace('_', ' ').replace('-', ' ').strip()\n",
    "                                norm_val2 = str(val2).lower().replace('_', ' ').replace('-', ' ').strip()\n",
    "                                \n",
    "                                # Check for exact matches after normalization\n",
    "                                if norm_val1 == norm_val2 and str(val1) != str(val2):\n",
    "                                    # This is a standardization issue (same meaning, different format)\n",
    "                                    group_key = norm_val1\n",
    "                                    if group_key not in standardization_groups:\n",
    "                                        standardization_groups[group_key] = []\n",
    "                                    \n",
    "                                    # Add both values to the group if not already there\n",
    "                                    if val1 not in [item['value'] for item in standardization_groups[group_key]]:\n",
    "                                        standardization_groups[group_key].append({\n",
    "                                            'value': val1,\n",
    "                                            'count': int((values == val1).sum())\n",
    "                                        })\n",
    "                                    if val2 not in [item['value'] for item in standardization_groups[group_key]]:\n",
    "                                        standardization_groups[group_key].append({\n",
    "                                            'value': val2,\n",
    "                                            'count': int((values == val2).sum())\n",
    "                                        })\n",
    "                                \n",
    "                                else:\n",
    "                                    # Check for high similarity (potential typos)\n",
    "                                    similarity = SequenceMatcher(None, norm_val1, norm_val2).ratio()\n",
    "                                    if 0.8 <= similarity < 1.0:  # High similarity but not identical\n",
    "                                        similar_pairs.append({\n",
    "                                            'value1': val1,\n",
    "                                            'value2': val2,\n",
    "                                            'similarity': similarity,\n",
    "                                            'count1': int((values == val1).sum()),\n",
    "                                            'count2': int((values == val2).sum()),\n",
    "                                            'normalized1': norm_val1,\n",
    "                                            'normalized2': norm_val2\n",
    "                                        })\n",
    "                \n",
    "                # Store standardization issues\n",
    "                if standardization_groups:\n",
    "                    inconsistencies['standardization_issues'] = standardization_groups\n",
    "                    total_inconsistencies += len(standardization_groups)\n",
    "                    \n",
    "                    # Print detailed standardization issues\n",
    "                    print(f\"        Found {len(standardization_groups)} standardization groups in '{col}':\")\n",
    "                    for group_name, variants in list(standardization_groups.items())[:3]:  # Show first 3\n",
    "                        total_count = sum([item['count'] for item in variants])\n",
    "                        variant_strs = [f\"'{item['value']}' ({item['count']})\" for item in variants]\n",
    "                        print(f\"         • {group_name}: {', '.join(variant_strs)} | Total: {total_count}\")\n",
    "                \n",
    "                if similar_pairs:\n",
    "                    inconsistencies['similar_values'] = similar_pairs\n",
    "                    total_inconsistencies += len(similar_pairs)\n",
    "            \n",
    "            if inconsistencies:\n",
    "                inconsistency_report[col] = inconsistencies\n",
    "    \n",
    "    report['inconsistent_entries'] = inconsistency_report\n",
    "    print(f\"     Inconsistency issues found: {total_inconsistencies}\")\n",
    "    \n",
    "    if inconsistency_report:\n",
    "        print(\"    Columns with inconsistencies:\")\n",
    "        for col, issues in list(inconsistency_report.items())[:5]:\n",
    "            issue_types = list(issues.keys())\n",
    "            print(f\"      • {col}: {', '.join(issue_types)}\")\n",
    "            \n",
    "            # Show standardization issues summary\n",
    "            if 'standardization_issues' in issues:\n",
    "                std_issues = issues['standardization_issues']\n",
    "                affected_values = sum([len(variants) for variants in std_issues.values()])\n",
    "                print(f\"        → {len(std_issues)} standardization groups affecting {affected_values} unique values\")\n",
    "    \n",
    "    # 4. FORMATTING ERRORS\n",
    "    print(\"\\n 4. CHECKING FORMATTING ERRORS...\")\n",
    "    \n",
    "    formatting_errors = {}\n",
    "    total_format_errors = 0\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_errors = {}\n",
    "        \n",
    "        if df[col].dtype == 'object':\n",
    "            values = df[col].dropna().astype(str)\n",
    "            \n",
    "            # 1. Check for mixed data types in string columns\n",
    "            numeric_pattern = re.compile(r'^-?\\d+\\.?\\d*$')\n",
    "            date_pattern = re.compile(r'\\d{1,4}[-/]\\d{1,2}[-/]\\d{1,4}')\n",
    "            email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n",
    "            \n",
    "            mixed_types = {}\n",
    "            \n",
    "            numeric_matches = values[values.str.match(numeric_pattern, na=False)]\n",
    "            if len(numeric_matches) > 0 and len(numeric_matches) < len(values):\n",
    "                mixed_types['numeric_like'] = numeric_matches.tolist()[:10]\n",
    "            \n",
    "            date_matches = values[values.str.match(date_pattern, na=False)]\n",
    "            if len(date_matches) > 0:\n",
    "                mixed_types['date_like'] = date_matches.tolist()[:10]\n",
    "            \n",
    "            email_matches = values[values.str.match(email_pattern, na=False)]\n",
    "            if len(email_matches) > 0:\n",
    "                mixed_types['email_like'] = email_matches.tolist()[:10]\n",
    "            \n",
    "            if mixed_types:\n",
    "                col_errors['mixed_data_types'] = mixed_types\n",
    "                total_format_errors += len(mixed_types)\n",
    "            \n",
    "            # 2. Check for inconsistent formatting within the same column\n",
    "            format_inconsistencies = {}\n",
    "            \n",
    "            # Currency formatting inconsistencies\n",
    "            if any(keyword in col.lower() for keyword in ['salary', 'rate', 'pay', 'wage', 'cost', 'price']):\n",
    "                currency_patterns = {\n",
    "                    'dollar_sign_prefix': values.str.match(r'^\\$[\\d,]+\\.?\\d*$', na=False).sum(),\n",
    "                    'dollar_sign_suffix': values.str.match(r'^[\\d,]+\\.?\\d*\\$$', na=False).sum(),\n",
    "                    'no_dollar_sign': values.str.match(r'^[\\d,]+\\.?\\d*$', na=False).sum(),\n",
    "                    'with_commas': values.str.contains(',', na=False).sum(),\n",
    "                    'without_commas': (~values.str.contains(',', na=False)).sum()\n",
    "                }\n",
    "                # If multiple formats exist, it's inconsistent\n",
    "                non_zero_formats = sum(1 for count in currency_patterns.values() if count > 0)\n",
    "                if non_zero_formats > 1:\n",
    "                    format_inconsistencies['currency_formatting'] = currency_patterns\n",
    "            \n",
    "            \n",
    "            # 3. Check for unusual characters or encoding issues\n",
    "            unusual_chars = []\n",
    "            control_chars = []\n",
    "            for val in values.unique()[:100]:  # Check first 100 unique values\n",
    "                # Non-ASCII characters\n",
    "                if any(ord(char) > 127 for char in str(val)):\n",
    "                    unusual_chars.append(val)\n",
    "                # Control characters (except common whitespace)\n",
    "                if any(ord(char) < 32 and char not in ['\\t', '\\n', '\\r'] for char in str(val)):\n",
    "                    control_chars.append(val)\n",
    "            \n",
    "            if unusual_chars:\n",
    "                col_errors['non_ascii_characters'] = unusual_chars[:10]\n",
    "                total_format_errors += 1\n",
    "            \n",
    "            if control_chars:\n",
    "                col_errors['control_characters'] = control_chars[:10]\n",
    "                total_format_errors += 1\n",
    "            \n",
    "            # 4. Check for inconsistent text casing in what should be standardized fields\n",
    "            if any(keyword in col.lower() for keyword in ['state', 'country', 'status', 'type', 'category']):\n",
    "                unique_values = values.unique()\n",
    "                casing_issues = {\n",
    "                    'all_upper': sum(1 for val in unique_values if val.isupper()),\n",
    "                    'all_lower': sum(1 for val in unique_values if val.islower()),\n",
    "                    'title_case': sum(1 for val in unique_values if val.istitle()),\n",
    "                    'mixed_case': sum(1 for val in unique_values if not val.isupper() and not val.islower() and not val.istitle())\n",
    "                }\n",
    "                non_zero_cases = sum(1 for count in casing_issues.values() if count > 0)\n",
    "                if non_zero_cases > 1:\n",
    "                    col_errors['inconsistent_casing'] = casing_issues\n",
    "                    total_format_errors += 1\n",
    "            \n",
    "            # 5. Data Type Mismatch Detection - Enhanced\n",
    "            data_type_mismatches = {}\n",
    "            \n",
    "            # Check for numeric data stored as strings\n",
    "            potential_numeric_indicators = ['rate', 'salary', 'wage', 'amount', 'price', 'cost', 'value', 'number', 'count', 'total', 'sum', 'age', 'distance', 'hour']\n",
    "            is_likely_numeric = any(indicator in col.lower() for indicator in potential_numeric_indicators)\n",
    "            \n",
    "            if is_likely_numeric and len(values) > 0:\n",
    "                mismatch_details = {}\n",
    "                \n",
    "                # Check what's preventing numeric conversion\n",
    "                # Remove common formatting and see if it becomes numeric\n",
    "                cleaned_values = (values\n",
    "                                .str.replace(r'[\\$£€¥,\\s%]', '', regex=True)  # Remove currency, commas, spaces, %\n",
    "                                .str.replace(r'^[\\+\\-]?', '', regex=True))    # Remove leading +/-\n",
    "                \n",
    "                # Test if cleaned values are numeric\n",
    "                try:\n",
    "                    numeric_test = pd.to_numeric(cleaned_values, errors='coerce')\n",
    "                    convertible_count = numeric_test.notna().sum()\n",
    "                    convertible_percentage = (convertible_count / len(values)) * 100\n",
    "                    \n",
    "                    # If high percentage is convertible, it's likely a mismatch\n",
    "                    if convertible_percentage >= 80:  # 80% or more could be numeric\n",
    "                        mismatch_details['expected_type'] = 'numeric'\n",
    "                        mismatch_details['current_type'] = 'object'\n",
    "                        mismatch_details['convertible_percentage'] = convertible_percentage\n",
    "                        mismatch_details['sample_values'] = values.head(5).tolist()\n",
    "                        \n",
    "                        # Identify specific formatting issues\n",
    "                        formatting_issues = []\n",
    "                        if values.str.contains(r'[\\$£€¥]', na=False).any():\n",
    "                            formatting_issues.append('currency_symbols')\n",
    "                        if values.str.contains(',', na=False).any():\n",
    "                            formatting_issues.append('thousands_separators')\n",
    "                        if values.str.contains('%', na=False).any():\n",
    "                            formatting_issues.append('percentage_signs')\n",
    "                        if values.str.contains(r'\\s', na=False).any():\n",
    "                            formatting_issues.append('embedded_spaces')\n",
    "                        \n",
    "                        mismatch_details['formatting_issues'] = formatting_issues\n",
    "                        mismatch_details['recommended_fix'] = f\"Convert to numeric after removing formatting characters\"\n",
    "                        \n",
    "                        data_type_mismatches[col] = mismatch_details\n",
    "                        print(f\"         Data Type Mismatch detected in '{col}': {convertible_percentage:.1f}% convertible to numeric\")\n",
    "                        print(f\"         Issues: {', '.join(formatting_issues)}\")\n",
    "                        print(f\"         Sample values: {mismatch_details['sample_values']}\")\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            \n",
    "        \n",
    "        # 6. Check numeric columns stored as strings with formatting characters\n",
    "        elif col in numeric_columns and df[col].dtype == 'object':\n",
    "            try:\n",
    "                # Try to identify what's preventing numeric conversion\n",
    "                non_numeric_reasons = {}\n",
    "                string_values = df[col].dropna().astype(str)\n",
    "                \n",
    "                # Check for currency symbols\n",
    "                has_currency = string_values.str.contains(r'[\\$£€¥]', na=False).sum()\n",
    "                if has_currency > 0:\n",
    "                    non_numeric_reasons['currency_symbols'] = has_currency\n",
    "                \n",
    "                # Check for commas\n",
    "                has_commas = string_values.str.contains(',', na=False).sum()\n",
    "                if has_commas > 0:\n",
    "                    non_numeric_reasons['thousands_separators'] = has_commas\n",
    "                \n",
    "                # Check for percentage signs\n",
    "                has_percent = string_values.str.contains('%', na=False).sum()\n",
    "                if has_percent > 0:\n",
    "                    non_numeric_reasons['percentage_signs'] = has_percent\n",
    "                \n",
    "                # Check for spaces\n",
    "                has_spaces = string_values.str.contains(' ', na=False).sum()\n",
    "                if has_spaces > 0:\n",
    "                    non_numeric_reasons['embedded_spaces'] = has_spaces\n",
    "                \n",
    "                if non_numeric_reasons:\n",
    "                    col_errors['numeric_formatting_issues'] = non_numeric_reasons\n",
    "                    total_format_errors += 1\n",
    "                    print(f\"   Numeric column '{col}' has formatting issues: {', '.join(non_numeric_reasons.keys())}\")\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if col_errors:\n",
    "            formatting_errors[col] = col_errors\n",
    "    \n",
    "    report['formatting_errors'] = formatting_errors\n",
    "    print(f\"  Formatting error types found: {total_format_errors}\")\n",
    "    \n",
    "    if formatting_errors:\n",
    "        print(\" Columns with formatting errors:\")\n",
    "        for col, errors in list(formatting_errors.items())[:5]:\n",
    "            error_types = list(errors.keys())\n",
    "            print(f\"      • {col}: {', '.join(error_types)}\")\n",
    "    \n",
    "    # 5. OUTLIERS\n",
    "    print(\"\\n 5. CHECKING FOR OUTLIERS...\")\n",
    "    \n",
    "    outlier_report = {}\n",
    "    total_outliers = 0\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "            col_data = df[col].dropna()\n",
    "            \n",
    "            if len(col_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            outliers = {}\n",
    "            \n",
    "            if outlier_method == 'iqr':\n",
    "                Q1 = col_data.quantile(0.25)\n",
    "                Q3 = col_data.quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - outlier_threshold * IQR\n",
    "                upper_bound = Q3 + outlier_threshold * IQR\n",
    "                \n",
    "                outlier_mask = (col_data < lower_bound) | (col_data > upper_bound)\n",
    "                outlier_values = col_data[outlier_mask]\n",
    "                \n",
    "                outliers['method'] = 'IQR'\n",
    "                outliers['bounds'] = {'lower': float(lower_bound), 'upper': float(upper_bound)}\n",
    "                \n",
    "            elif outlier_method == 'zscore':\n",
    "                z_scores = np.abs((col_data - col_data.mean()) / col_data.std())\n",
    "                outlier_mask = z_scores > outlier_threshold\n",
    "                outlier_values = col_data[outlier_mask]\n",
    "                \n",
    "                outliers['method'] = 'Z-Score'\n",
    "                outliers['threshold'] = outlier_threshold\n",
    "                \n",
    "            elif outlier_method == 'modified_zscore':\n",
    "                median = col_data.median()\n",
    "                mad = np.median(np.abs(col_data - median))\n",
    "                if mad != 0:\n",
    "                    modified_z_scores = 0.6745 * (col_data - median) / mad\n",
    "                    outlier_mask = np.abs(modified_z_scores) > outlier_threshold\n",
    "                    outlier_values = col_data[outlier_mask]\n",
    "                else:\n",
    "                    outlier_values = pd.Series([], dtype=col_data.dtype)\n",
    "                \n",
    "                outliers['method'] = 'Modified Z-Score'\n",
    "                outliers['threshold'] = outlier_threshold\n",
    "            \n",
    "            if len(outlier_values) > 0:\n",
    "                outliers.update({\n",
    "                    'count': len(outlier_values),\n",
    "                    'percentage': (len(outlier_values) / len(col_data)) * 100,\n",
    "                    'values': outlier_values.tolist()[:50],  # Limit to first 50\n",
    "                    'indices': outlier_values.index.tolist()[:50],\n",
    "                    'statistics': {\n",
    "                        'min_outlier': float(outlier_values.min()),\n",
    "                        'max_outlier': float(outlier_values.max()),\n",
    "                        'mean_outlier': float(outlier_values.mean())\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "                outlier_report[col] = outliers\n",
    "                total_outliers += len(outlier_values)\n",
    "    \n",
    "    report['outliers'] = outlier_report\n",
    "    print(f\"   Total outliers found: {total_outliers:,}\")\n",
    "    \n",
    "    if outlier_report and show_plots:\n",
    "        # Visualization: Outliers\n",
    "        n_outlier_cols = len(outlier_report)\n",
    "        if n_outlier_cols > 0:\n",
    "            fig, axes = plt.subplots(min(2, n_outlier_cols), 2, figsize=(15, min(8, n_outlier_cols * 4)))\n",
    "            if n_outlier_cols == 1:\n",
    "                axes = axes.reshape(1, -1)\n",
    "            \n",
    "            for i, (col, stats) in enumerate(list(outlier_report.items())[:2]):\n",
    "                row = i\n",
    "                \n",
    "                # Box plot\n",
    "                ax1 = axes[row, 0] if n_outlier_cols > 1 else axes[0]\n",
    "                df[col].plot.box(ax=ax1)\n",
    "                ax1.set_title(f'{col} - Box Plot')\n",
    "                ax1.set_ylabel('Values')\n",
    "                \n",
    "                # Histogram\n",
    "                ax2 = axes[row, 1] if n_outlier_cols > 1 else axes[1]\n",
    "                df[col].hist(bins=50, alpha=0.7, ax=ax2)\n",
    "                ax2.axvline(stats['bounds']['lower'] if 'bounds' in stats else df[col].mean() - 2*df[col].std(), \n",
    "                           color='red', linestyle='--', alpha=0.7, label='Lower bound')\n",
    "                ax2.axvline(stats['bounds']['upper'] if 'bounds' in stats else df[col].mean() + 2*df[col].std(), \n",
    "                           color='red', linestyle='--', alpha=0.7, label='Upper bound')\n",
    "                ax2.set_title(f'{col} - Distribution')\n",
    "                ax2.set_xlabel('Values')\n",
    "                ax2.set_ylabel('Frequency')\n",
    "                ax2.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    if outlier_report:\n",
    "        print(\"    Columns with outliers:\")\n",
    "        for col, stats in list(outlier_report.items())[:5]:\n",
    "            print(f\"      • {col}: {stats['count']:,} outliers ({stats['percentage']:.2f}%)\")\n",
    "    \n",
    "    # 6. SUMMARY\n",
    "    print(\"\\n GENERATING SUMMARY...\")\n",
    "    \n",
    "    total_issues = 0\n",
    "    issue_categories = []\n",
    "    \n",
    "    if report['duplicates']['full_row_duplicates']['count'] > 0:\n",
    "        total_issues += report['duplicates']['full_row_duplicates']['count']\n",
    "        issue_categories.append('duplicates')\n",
    "    \n",
    "    missing_issues = sum([stats['count'] for stats in report['missing_values'].values()])\n",
    "    if missing_issues > 0:\n",
    "        total_issues += missing_issues\n",
    "        issue_categories.append('missing_values')\n",
    "    \n",
    "    if report['inconsistent_entries']:\n",
    "        total_issues += total_inconsistencies\n",
    "        issue_categories.append('inconsistent_entries')\n",
    "    \n",
    "    if report['formatting_errors']:\n",
    "        total_issues += total_format_errors\n",
    "        issue_categories.append('formatting_errors')\n",
    "    \n",
    "    if total_outliers > 0:\n",
    "        total_issues += total_outliers\n",
    "        issue_categories.append('outliers')\n",
    "    \n",
    "    # Calculate data quality score\n",
    "    max_possible_issues = len(df) * len(df.columns)\n",
    "    quality_score = max(0, 100 - (total_issues / max_possible_issues) * 100)\n",
    "    \n",
    "    report['summary'] = {\n",
    "        'total_issues_found': total_issues,\n",
    "        'issue_categories': issue_categories,\n",
    "        'data_quality_score': quality_score,\n",
    "        'recommendations': []\n",
    "    }\n",
    "    \n",
    "    # Add recommendations\n",
    "    recommendations = []\n",
    "    if report['duplicates']['full_row_duplicates']['count'] > 0:\n",
    "        recommendations.append(\"Remove duplicate rows to improve data integrity\")\n",
    "    if missing_issues > 0:\n",
    "        recommendations.append(\"Handle missing values through imputation or removal\")\n",
    "    if report['inconsistent_entries']:\n",
    "        recommendations.append(\"Standardize categorical values and fix case/whitespace issues\")\n",
    "    if report['formatting_errors']:\n",
    "        recommendations.append(\"Clean formatting errors and ensure consistent data types\")\n",
    "    if total_outliers > 0:\n",
    "        recommendations.append(\"Investigate outliers - validate if they're errors or legitimate extreme values\")\n",
    "    \n",
    "    report['summary']['recommendations'] = recommendations\n",
    "    \n",
    "    # Final Summary Display\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA QUALITY INSPECTION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Data Quality Score: {quality_score:.1f}/100\")\n",
    "    print(f\"Total Issues Found: {total_issues:,}\")\n",
    "    print(f\"Dataset Size: {len(df):,} rows × {len(df.columns)} columns\")\n",
    "    print(f\"Memory Usage: {report['dataset_overview']['memory_usage'] / 1024**2:.2f} MB\")\n",
    "    \n",
    "    if issue_categories:\n",
    "        print(f\"\\nIssue Categories Found:\")\n",
    "        for category in issue_categories:\n",
    "            print(f\"   • {category.replace('_', ' ').title()}\")\n",
    "    \n",
    "    if recommendations:\n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for rec in recommendations:\n",
    "            print(f\"   {rec}\")\n",
    "    \n",
    "    print(\"\\nData quality inspection completed!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def get_column_summary_table(df: pd.DataFrame, report: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get a clean summary table of all columns with the requested metrics\n",
    "    \n",
    "    Returns a pandas DataFrame that can be easily displayed or exported\n",
    "    \"\"\"\n",
    "    column_summary = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_data = df[col]\n",
    "        \n",
    "        # Data Type\n",
    "        data_type = str(col_data.dtype)\n",
    "        \n",
    "        # Missing Data\n",
    "        missing_count = col_data.isnull().sum()\n",
    "        missing_percentage = (missing_count / len(col_data)) * 100\n",
    "        \n",
    "        # Whitespace Issues\n",
    "        whitespace_count = 0\n",
    "        if col_data.dtype == 'object':\n",
    "            non_null_values = col_data.dropna().astype(str)\n",
    "            whitespace_mask = non_null_values != non_null_values.str.strip()\n",
    "            whitespace_count = whitespace_mask.sum()\n",
    "        \n",
    "        # Case Inconsistencies\n",
    "        case_inconsistencies = 0\n",
    "        if col in report['inconsistent_entries']:\n",
    "            if 'case_variations' in report['inconsistent_entries'][col]:\n",
    "                case_variations = report['inconsistent_entries'][col]['case_variations']\n",
    "                case_inconsistencies = len(case_variations)\n",
    "        \n",
    "        # Outlier Count\n",
    "        outlier_count = 0\n",
    "        if col in report['outliers']:\n",
    "            outlier_count = report['outliers'][col]['count']\n",
    "        \n",
    "        # Absurd Values\n",
    "        absurd_info = detect_absurd_values(df, col)\n",
    "        absurd_count = absurd_info['count']\n",
    "        \n",
    "        column_summary.append({\n",
    "            'Column': col,\n",
    "            'Data_Type': data_type,\n",
    "            'Missing_Data_Count': missing_count,\n",
    "            'Missing_Data_Percentage': round(missing_percentage, 2),\n",
    "            'Absurd_Values': absurd_count,\n",
    "            'Outlier_Count': outlier_count,\n",
    "            'Whitespace_Issues': whitespace_count,\n",
    "            'Case_Inconsistencies': case_inconsistencies\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(column_summary)\n",
    "    return summary_df\n",
    "\n",
    "def detect_absurd_values(df: pd.DataFrame, column: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Detect absurd values based on business logic and common sense rules\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    column : str\n",
    "        Column name to check\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict[str, Any] : Report of absurd values found\n",
    "    \"\"\"\n",
    "    \n",
    "    absurd_report = {\n",
    "        'count': 0,\n",
    "        'percentage': 0.0,\n",
    "        'values': [],\n",
    "        'indices': [],\n",
    "        'rules_violated': []\n",
    "    }\n",
    "    \n",
    "    if column not in df.columns:\n",
    "        return absurd_report\n",
    "    \n",
    "    col_data = df[column].dropna()\n",
    "    if len(col_data) == 0:\n",
    "        return absurd_report\n",
    "    \n",
    "    # Only check numeric columns for absurd values\n",
    "    if not pd.api.types.is_numeric_dtype(col_data):\n",
    "        return absurd_report\n",
    "    \n",
    "    absurd_mask = pd.Series([False] * len(col_data), index=col_data.index)\n",
    "    rules_violated = []\n",
    "    \n",
    "    # Define business logic rules based on column names and typical HR data\n",
    "    column_lower = column.lower()\n",
    "    \n",
    "    # Age-related rules\n",
    "    if 'age' in column_lower:\n",
    "        age_absurd = (col_data < 16) | (col_data > 100)\n",
    "        absurd_mask |= age_absurd\n",
    "        if age_absurd.any():\n",
    "            rules_violated.append(f\"Age values outside reasonable range (16-100): found {age_absurd.sum()} values\")\n",
    "    \n",
    "    # Tenure-related rules\n",
    "    elif 'tenure' in column_lower or 'experience' in column_lower:\n",
    "        tenure_absurd = (col_data < 0) | (col_data > 50)\n",
    "        absurd_mask |= tenure_absurd\n",
    "        if tenure_absurd.any():\n",
    "            rules_violated.append(f\"Tenure/Experience values outside reasonable range (0-50 years): found {tenure_absurd.sum()} values\")\n",
    "    \n",
    "    # Distance-related rules (like DrivingCommuterDistance)\n",
    "    elif 'distance' in column_lower or 'commut' in column_lower or 'DrivingCommuterDistance' in column_lower:\n",
    "        distance_absurd = (col_data < 0) | (col_data > 500)  # Negative or > 500 miles is absurd\n",
    "        absurd_mask |= distance_absurd\n",
    "        if distance_absurd.any():\n",
    "            rules_violated.append(f\"Distance values outside reasonable range (0-500): found {distance_absurd.sum()} values\")\n",
    "    \n",
    "    # Hours-related rules\n",
    "    elif 'hour' in column_lower and 'weekly' in column_lower:\n",
    "        hours_absurd = (col_data < 0) | (col_data > 80)  # Negative or >80 hours/week is absurd\n",
    "        absurd_mask |= hours_absurd\n",
    "        if hours_absurd.any():\n",
    "            rules_violated.append(f\"Weekly hours outside reasonable range (0-80): found {hours_absurd.sum()} values\")\n",
    "    \n",
    "    elif 'hour' in column_lower and ('annual' in column_lower or 'professional' in column_lower or 'dev' in column_lower):\n",
    "        hours_absurd = (col_data < 0) | (col_data > 2000)  # Annual professional dev hours\n",
    "        absurd_mask |= hours_absurd\n",
    "        if hours_absurd.any():\n",
    "            rules_violated.append(f\"Annual hours outside reasonable range (0-2000): found {hours_absurd.sum()} values\")\n",
    "    \n",
    "    # Salary-related rules\n",
    "    elif 'annualsalary' in column_lower: # or 'rate' in column_lower:\n",
    "        # Check for negative salaries first (always absurd)\n",
    "        negative_salary = col_data < 0\n",
    "        if negative_salary.any():\n",
    "            absurd_mask |= negative_salary\n",
    "            rules_violated.append(f\"Negative salary values found (impossible): {negative_salary.sum()} values\")\n",
    "        \n",
    "        # Tcheck reasonable ranges for positive values\n",
    "        positive_data = col_data[col_data >= 0]\n",
    "        if len(positive_data) > 0:\n",
    "            if len(positive_data) > 0:\n",
    "        # Check above 250,000\n",
    "                extremely_high = positive_data > 250000\n",
    "                if extremely_high.any():\n",
    "                    absurd_mask |= extremely_high\n",
    "                    rules_violated.append(f\"Extremely high salary values (> $1M): found {extremely_high.sum()} values\")\n",
    "            else:  # Likely hourly rate\n",
    "                rate_absurd = (positive_data < 7.25) | (positive_data > 200)\n",
    "                absurd_mask |= rate_absurd\n",
    "                if rate_absurd.any():\n",
    "                    rules_violated.append(f\"Hourly rate outside reasonable range ($7.25-$200): found {rate_absurd.sum()} values\")\n",
    "    \n",
    "    # Employee number rules\n",
    "    elif 'employee' in column_lower and 'number' in column_lower:\n",
    "        emp_absurd = col_data <= 0\n",
    "        absurd_mask |= emp_absurd\n",
    "        if emp_absurd.any():\n",
    "            rules_violated.append(f\"Employee numbers <= 0: found {emp_absurd.sum()} values\")\n",
    "    \n",
    "    # Number of companies worked\n",
    "    elif 'compan' in column_lower and ('previous' in column_lower or 'worked' in column_lower):\n",
    "        companies_absurd = (col_data < 0) | (col_data > 20)  # Negative or more than 20 previous companies\n",
    "        absurd_mask |= companies_absurd\n",
    "        if companies_absurd.any():\n",
    "            rules_violated.append(f\"Number of previous companies outside reasonable range (0-20): found {companies_absurd.sum()} values\")\n",
    "    \n",
    "    # General negative value check for columns that should always be positive\n",
    "    positive_keywords = ['count', 'number', 'total', 'amount']\n",
    "    if any(keyword in column_lower for keyword in positive_keywords):\n",
    "        negative_absurd = col_data < 0\n",
    "        absurd_mask |= negative_absurd\n",
    "        if negative_absurd.any():\n",
    "            rules_violated.append(f\"Negative values in column that should be positive: found {negative_absurd.sum()} values\")\n",
    "    \n",
    "    # Extract results\n",
    "    if absurd_mask.any():\n",
    "        absurd_values = col_data[absurd_mask]\n",
    "        absurd_report = {\n",
    "            'count': len(absurd_values),\n",
    "            'percentage': (len(absurd_values) / len(col_data)) * 100,\n",
    "            'values': absurd_values.tolist()[:20],  # Limit to first 20\n",
    "            'indices': absurd_values.index.tolist()[:20],\n",
    "            'rules_violated': rules_violated\n",
    "        }\n",
    "    \n",
    "    return absurd_report\n",
    "\n",
    "def print_detailed_column_report(df: pd.DataFrame, report: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Print a detailed, formatted column-by-column report\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\" DETAILED COLUMN-BY-COLUMN DATA QUALITY REPORT\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        print(f\"\\n COLUMN: '{col}'\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        col_data = df[col]\n",
    "        \n",
    "        # 1. Data Type\n",
    "        print(f\" Data Type: {col_data.dtype}\")\n",
    "        \n",
    "        # 2. Missing Data\n",
    "        missing_count = col_data.isnull().sum()\n",
    "        missing_percentage = (missing_count / len(col_data)) * 100\n",
    "        print(f\" Missing Data: {missing_count:,} ({missing_percentage:.2f}%)\")\n",
    "        \n",
    "        # Check for alternative missing representations\n",
    "        if col in report['missing_values'] and 'potential_missing_representations' in report['missing_values'][col]:\n",
    "            alt_missing = report['missing_values'][col]['potential_missing_representations']\n",
    "            print(f\"   • Alternative missing representations: {alt_missing['count']} values\")\n",
    "            print(f\"     → {list(alt_missing['values'].keys())}\")\n",
    "        \n",
    "        # 3. Absurd Values\n",
    "        absurd_info = detect_absurd_values(df, col)\n",
    "        absurd_count = absurd_info['count']\n",
    "        print(f\"  Absurd Values: {absurd_count} ({absurd_info['percentage']:.2f}%)\")\n",
    "        \n",
    "        if absurd_count > 0:\n",
    "            print(f\"   • Rules violated:\")\n",
    "            for rule in absurd_info['rules_violated']:\n",
    "                print(f\"     → {rule}\")\n",
    "            if absurd_info['values']:\n",
    "                print(f\"   • Sample absurd values: {absurd_info['values'][:5]}\")\n",
    "        \n",
    "        # 4. Outlier Count\n",
    "        outlier_count = 0\n",
    "        if col in report['outliers']:\n",
    "            outlier_info = report['outliers'][col]\n",
    "            outlier_count = outlier_info['count']\n",
    "            print(f\" Outlier Count: {outlier_count} ({outlier_info['percentage']:.2f}%)\")\n",
    "            print(f\"   • Method: {outlier_info['method']}\")\n",
    "            if 'bounds' in outlier_info:\n",
    "                print(f\"    Bounds: [{outlier_info['bounds']['lower']:.2f}, {outlier_info['bounds']['upper']:.2f}]\")\n",
    "            if outlier_info['values']:\n",
    "                sample_outliers = outlier_info['values'][:5]\n",
    "                print(f\"   Sample outliers: {sample_outliers}\")\n",
    "        else:\n",
    "            print(f\" Outlier Count: {outlier_count}\")\n",
    "        \n",
    "        # 5. Whitespace Issues\n",
    "        whitespace_count = 0\n",
    "        whitespace_examples = []\n",
    "        if col_data.dtype == 'object':\n",
    "            non_null_values = col_data.dropna().astype(str)\n",
    "            whitespace_mask = non_null_values != non_null_values.str.strip()\n",
    "            whitespace_count = whitespace_mask.sum()\n",
    "            if whitespace_count > 0:\n",
    "                whitespace_examples = non_null_values[whitespace_mask].unique()[:3].tolist()\n",
    "        \n",
    "        print(f\" Whitespace Issues: {whitespace_count}\")\n",
    "        if whitespace_examples:\n",
    "            print(f\"   • Examples: {whitespace_examples}\")\n",
    "        \n",
    "        # 6. Case Inconsistencies\n",
    "        case_inconsistencies = 0\n",
    "        if col in report['inconsistent_entries']:\n",
    "            if 'case_variations' in report['inconsistent_entries'][col]:\n",
    "                case_variations = report['inconsistent_entries'][col]['case_variations']\n",
    "                case_inconsistencies = len(case_variations)\n",
    "                print(f\" Case Inconsistencies: {case_inconsistencies} groups\")\n",
    "                \n",
    "                # Show examples\n",
    "                for group_name, variations in list(case_variations.items())[:2]:\n",
    "                    print(f\"   • '{group_name}' group: {variations}\")\n",
    "            else:\n",
    "                print(f\" Case Inconsistencies: {case_inconsistencies}\")\n",
    "        else:\n",
    "            print(f\" Case Inconsistencies: {case_inconsistencies}\")\n",
    "        \n",
    "        # Additional standardization issues\n",
    "        if col in report['inconsistent_entries']:\n",
    "            if 'standardization_issues' in report['inconsistent_entries'][col]:\n",
    "                std_issues = report['inconsistent_entries'][col]['standardization_issues']\n",
    "                print(f\" Standardization Groups: {len(std_issues)}\")\n",
    "                for group_name, variants in list(std_issues.items())[:2]:\n",
    "                    variant_names = [v['value'] for v in variants]\n",
    "                    print(f\"   • '{group_name}': {variant_names}\")\n",
    "        \n",
    "        # Summary for this column\n",
    "        total_issues = missing_count + absurd_count + outlier_count + whitespace_count + case_inconsistencies\n",
    "        issue_density = (total_issues / len(col_data)) * 100\n",
    "        \n",
    "        if issue_density == 0:\n",
    "            print(f\" Column Quality: EXCELLENT (no issues found)\")\n",
    "        elif issue_density < 1:\n",
    "            print(f\" Column Quality: GOOD ({issue_density:.2f}% issues)\")\n",
    "        elif issue_density < 5:\n",
    "            print(f\" Column Quality: FAIR ({issue_density:.2f}% issues)\")\n",
    "        else:\n",
    "            print(f\" Column Quality: POOR ({issue_density:.2f}% issues)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "\n",
    "def generate_standardization_recommendations(report: Dict[str, Any], df: pd.DataFrame) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Generate specific recommendations for standardizing categorical values\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    report : Dict[str, Any]\n",
    "        The quality report from inspect_data_quality()\n",
    "    df : pd.DataFrame\n",
    "        The original dataframe\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict[str, Dict] : Standardization recommendations by column\n",
    "    \"\"\"\n",
    "    \n",
    "    recommendations = {}\n",
    "    \n",
    "    for col, issues in report['inconsistent_entries'].items():\n",
    "        if 'standardization_issues' in issues:\n",
    "            col_recommendations = {}\n",
    "            standardization_groups = issues['standardization_issues']\n",
    "            \n",
    "            for group_name, variants in standardization_groups.items():\n",
    "                # Determine the best standard format\n",
    "                variant_counts = [(item['value'], item['count']) for item in variants]\n",
    "                \n",
    "                # Strategy 1: Use the most common variant\n",
    "                most_common = max(variant_counts, key=lambda x: x[1])\n",
    "                \n",
    "                # Strategy 2: Use the cleanest format (prefer spaces over underscores, proper case)\n",
    "                def format_score(value):\n",
    "                    score = 0\n",
    "                    # Prefer spaces over underscores\n",
    "                    if ' ' in value and '_' not in value:\n",
    "                        score += 3\n",
    "                    # Prefer proper case\n",
    "                    if value.replace('_', ' ').title() == value.replace('_', ' '):\n",
    "                        score += 2\n",
    "                    # Prefer shorter, cleaner formats\n",
    "                    score -= len(value) * 0.1\n",
    "                    return score\n",
    "                \n",
    "                cleanest = max(variant_counts, key=lambda x: format_score(x[0]))\n",
    "                \n",
    "                # Create mapping recommendations\n",
    "                mapping = {}\n",
    "                total_affected = sum([count for _, count in variant_counts])\n",
    "                \n",
    "                # Use the most common as standard unless cleanest format is significantly better\n",
    "                if cleanest[1] >= most_common[1] * 0.5:  # Cleanest has at least 50% of most common's frequency\n",
    "                    standard_value = cleanest[0]\n",
    "                else:\n",
    "                    standard_value = most_common[0]\n",
    "                \n",
    "                for value, count in variant_counts:\n",
    "                    if value != standard_value:\n",
    "                        mapping[value] = standard_value\n",
    "                \n",
    "                if mapping:\n",
    "                    col_recommendations[group_name] = {\n",
    "                        'standard_value': standard_value,\n",
    "                        'mappings': mapping,\n",
    "                        'total_affected_rows': total_affected,\n",
    "                        'variants': variant_counts\n",
    "                    }\n",
    "            \n",
    "            if col_recommendations:\n",
    "                recommendations[col] = col_recommendations\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def print_standardization_recommendations(recommendations: Dict[str, Dict], df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Print formatted standardization recommendations\n",
    "    \"\"\"\n",
    "    if not recommendations:\n",
    "        print(\" No standardization issues found!\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" STANDARDIZATION RECOMMENDATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for col, col_recommendations in recommendations.items():\n",
    "        print(f\"\\n COLUMN: '{col}'\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        total_rows_affected = sum([rec['total_affected_rows'] for rec in col_recommendations.values()])\n",
    "        print(f\"Total rows that need standardization: {total_rows_affected:,} ({total_rows_affected/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        for group_name, rec in col_recommendations.items():\n",
    "            print(f\"\\n Group: '{group_name}' → Standardize to: '{rec['standard_value']}'\")\n",
    "            print(f\"   Affected rows: {rec['total_affected_rows']:,}\")\n",
    "            print(f\"   Variants to change:\")\n",
    "            \n",
    "            for old_value, new_value in rec['mappings'].items():\n",
    "                old_count = next(count for val, count in rec['variants'] if val == old_value)\n",
    "                print(f\"      • '{old_value}' ({old_count:,} rows) → '{new_value}'\")\n",
    "        \n",
    "        # Generate pandas code\n",
    "        print(f\"\\n Pandas code to fix '{col}':\")\n",
    "        print(\"```python\")\n",
    "        mapping_dict = {}\n",
    "        for rec in col_recommendations.values():\n",
    "            mapping_dict.update(rec['mappings'])\n",
    "        \n",
    "        print(f\"# Standardize {col}\")\n",
    "        print(f\"mapping_{col.lower().replace(' ', '_')} = {mapping_dict}\")\n",
    "        print(f\"df['{col}'] = df['{col}'].replace(mapping_{col.lower().replace(' ', '_')})\")\n",
    "        print(\"```\")\n",
    "\n",
    "def detect_delimiter_inconsistencies(df: pd.DataFrame, columns: List[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Detect inconsistent use of delimiters (underscores, spaces, hyphens) in categorical columns\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "        columns : List[str], optional\n",
    "        Specific columns to check. If None, checks all object columns\n",
    "    Returns:\n",
    "    --------\n",
    "    Dict[str, Any] : Report of delimiter inconsistencies\n",
    "    \"\"\"\n",
    "    \n",
    "    if columns is None:\n",
    "        columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    delimiter_report = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        values = df[col].dropna().astype(str).unique()\n",
    "        \n",
    "        # Check for mixed delimiter usage\n",
    "        has_underscores = any('_' in str(val) for val in values)\n",
    "        has_spaces = any(' ' in str(val) for val in values)\n",
    "        has_hyphens = any('-' in str(val) for val in values)\n",
    "        \n",
    "        delimiter_count = sum([has_underscores, has_spaces, has_hyphens])\n",
    "        \n",
    "        if delimiter_count > 1:  # Mixed delimiters found\n",
    "            delimiter_analysis = {\n",
    "                'mixed_delimiters': True,\n",
    "                'delimiters_found': [],\n",
    "                'examples': {}\n",
    "            }\n",
    "            \n",
    "            if has_underscores:\n",
    "                delimiter_analysis['delimiters_found'].append('underscore')\n",
    "                underscore_examples = [val for val in values if '_' in str(val)][:3]\n",
    "                delimiter_analysis['examples']['underscore'] = underscore_examples\n",
    "            \n",
    "            if has_spaces:\n",
    "                delimiter_analysis['delimiters_found'].append('space')\n",
    "                space_examples = [val for val in values if ' ' in str(val)][:3]\n",
    "                delimiter_analysis['examples']['space'] = space_examples\n",
    "            \n",
    "            if has_hyphens:\n",
    "                delimiter_analysis['delimiters_found'].append('hyphen')\n",
    "                hyphen_examples = [val for val in values if '-' in str(val)][:3]\n",
    "                delimiter_analysis['examples']['hyphen'] = hyphen_examples\n",
    "            \n",
    "            delimiter_report[col] = delimiter_analysis\n",
    "    \n",
    "    return delimiter_report\n",
    "\n",
    "def get_detailed_column_report(df: pd.DataFrame, column: str, report: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Display detailed information about a specific column\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        print(f\"Column '{column}' not found in dataset\")\n",
    "        return\n",
    "    \n",
    "    print(f\"DETAILED REPORT FOR COLUMN: '{column}'\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    col_data = df[column]\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Data Type: {col_data.dtype}\")\n",
    "    print(f\"Non-null Count: {col_data.count():,} / {len(col_data):,}\")\n",
    "    print(f\"Missing Values: {col_data.isnull().sum():,} ({(col_data.isnull().sum()/len(col_data)*100):.2f}%)\")\n",
    "    print(f\"Unique Values: {col_data.nunique():,}\")\n",
    "    \n",
    "    # Type-specific analysis\n",
    "    if pd.api.types.is_numeric_dtype(col_data):\n",
    "        print(f\"\\nNUMERIC STATISTICS:\")\n",
    "        print(f\"Mean: {col_data.mean():.2f}\")\n",
    "        print(f\"Median: {col_data.median():.2f}\")\n",
    "        print(f\"Std Dev: {col_data.std():.2f}\")\n",
    "        print(f\"Min: {col_data.min()}\")\n",
    "        print(f\"Max: {col_data.max()}\")\n",
    "        \n",
    "        # Show outliers if any\n",
    "        if column in report['outliers']:\n",
    "            outlier_info = report['outliers'][column]\n",
    "            print(f\"\\nOUTLIERS ({outlier_info['method']}):\")\n",
    "            print(f\"Count: {outlier_info['count']:,} ({outlier_info['percentage']:.2f}%)\")\n",
    "            if 'bounds' in outlier_info:\n",
    "                print(f\"Bounds: [{outlier_info['bounds']['lower']:.2f}, {outlier_info['bounds']['upper']:.2f}]\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\nCATEGORICAL STATISTICS:\")\n",
    "        value_counts = col_data.value_counts().head(10)\n",
    "        print(\"Top 10 values:\")\n",
    "        for val, count in value_counts.items():\n",
    "            print(f\"   '{val}': {count:,} ({count/len(col_data)*100:.1f}%)\")\n",
    "        \n",
    "        # Show inconsistencies if any\n",
    "        if column in report['inconsistent_entries']:\n",
    "            inconsistencies = report['inconsistent_entries'][column]\n",
    "            print(f\"\\n INCONSISTENCIES FOUND:\")\n",
    "            for issue_type, details in inconsistencies.items():\n",
    "                print(f\"   {issue_type.replace('_', ' ').title()}: {len(details)} issues\")\n",
    "    \n",
    "    # Show formatting errors if any\n",
    "    if column in report['formatting_errors']:\n",
    "        format_errors = report['formatting_errors'][column]\n",
    "        print(f\"\\n FORMATTING ERRORS:\")\n",
    "        for error_type, details in format_errors.items():\n",
    "            print(f\"   {error_type.replace('_', ' ').title()}: {len(details)} issues\")\n",
    "\n",
    "# Example usage for Jupyter Notebook:\n",
    "def quick_quality_check(csv_file_path: str, \n",
    "                       sample_size: int = None,\n",
    "                       show_plots: bool = True) -> Dict[str, Any]:\n",
    "  \n",
    "    \n",
    "    # Load data\n",
    "    print(f\"Loading data from: {csv_file_path}\")\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Sample if requested\n",
    "    if sample_size and len(df) > sample_size:\n",
    "        print(f\" Sampling {sample_size:,} rows from {len(df):,} total rows\")\n",
    "        df = df.sample(sample_size, random_state=42)\n",
    "    \n",
    "    # Auto-detect columns for Employee Turnover Dataset\n",
    "    numeric_cols = ['EmployeeNumber', 'Age', 'Tenure', 'HoursWeekly', \n",
    "                   'AnnualSalary', 'DrivingCommuterDistance', \n",
    "                   'NumCompaniesPreviouslyWorked', 'AnnualProfessionalDevHrs']\n",
    "    \n",
    "    categorical_cols = ['Turnover', 'HourlyRate ', 'CompensationType', \n",
    "                       'JobRoleArea', 'Gender', 'MaritalStatus', \n",
    "                       'PaycheckMethod', 'TextMessageOptIn']\n",
    "    \n",
    "    # Filter to only existing columns\n",
    "    numeric_cols = [col for col in numeric_cols if col in df.columns]\n",
    "    categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "    \n",
    "    # Run inspection\n",
    "    report = inspect_data_quality(\n",
    "        df, \n",
    "        numeric_columns=numeric_cols,\n",
    "        categorical_columns=categorical_cols,\n",
    "        outlier_method='iqr',\n",
    "        outlier_threshold=1.5,\n",
    "        show_plots=show_plots\n",
    "    )\n",
    "    \n",
    "    return report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d4812-9f22-4b9a-8729-ee9e0932a333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# C2 - Clean Data\n",
    "def clean_employee_data(df: pd.DataFrame, \n",
    "                       report: Dict[str, Any] = None,\n",
    "                       backup: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Data cleaning function for Employee Turnover dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"STARTING DATA CLEANING PROCESS\")\n",
    "    print(\"==\" * 25)\n",
    "    \n",
    "    # Create backup if requested\n",
    "    if backup:\n",
    "        df_original = df.copy()\n",
    "        print(\" Original data backed up\")\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    cleaning_log = []\n",
    "    \n",
    "    # 1. REMOVE DUPLICATE ROWS\n",
    "    print(\"\\n 1. REMOVING DUPLICATE ROWS...\")\n",
    "    initial_rows = len(df_cleaned)\n",
    "    df_cleaned = df_cleaned.drop_duplicates()\n",
    "    duplicates_removed = initial_rows - len(df_cleaned)\n",
    "    \n",
    "    if duplicates_removed > 0:\n",
    "        cleaning_log.append(f\"Removed {duplicates_removed} duplicate rows\")\n",
    "        print(f\"Removed {duplicates_removed} duplicate rows\")\n",
    "    else:\n",
    "        print(\"No duplicate rows found\")\n",
    "    \n",
    "    # 2. FIX DATA TYPE MISMATCHES\n",
    "    print(\"\\n 2. FIXING DATA TYPE MISMATCHES...\")\n",
    "    \n",
    "    # Fix HourlyRate column (remove $ and convert to numeric)\n",
    "    if 'HourlyRate ' in df_cleaned.columns:  \n",
    "        print(\"   Cleaning HourlyRate column...\")\n",
    "        original_col = df_cleaned['HourlyRate '].copy()\n",
    "        \n",
    "        # Remove currency symbols and extra spaces, convert to numeric\n",
    "        cleaned_values = (df_cleaned['HourlyRate ']\n",
    "                         .astype(str)\n",
    "                         .str.replace(r'[\\$£€¥,\\s]', '', regex=True)\n",
    "                         .replace('', np.nan))\n",
    "        \n",
    "        df_cleaned['HourlyRate '] = pd.to_numeric(cleaned_values, errors='coerce')\n",
    "        \n",
    "        converted_count = (~df_cleaned['HourlyRate '].isna()).sum()\n",
    "        cleaning_log.append(f\"Converted HourlyRate to numeric: {converted_count} values\")\n",
    "        print(f\"   Converted {converted_count} HourlyRate values to numeric\")\n",
    "    \n",
    "    # Fix any other currency/numeric columns\n",
    "    currency_columns = ['AnnualSalary']\n",
    "    for col in currency_columns:\n",
    "        if col in df_cleaned.columns and df_cleaned[col].dtype == 'object':\n",
    "            print(f\"   Cleaning {col} column...\")\n",
    "            cleaned_values = (df_cleaned[col]\n",
    "                             .astype(str)\n",
    "                             .str.replace(r'[\\$£€¥,\\s]', '', regex=True)\n",
    "                             .replace('', np.nan))\n",
    "            \n",
    "            df_cleaned[col] = pd.to_numeric(cleaned_values, errors='coerce')\n",
    "            converted_count = (~df_cleaned[col].isna()).sum()\n",
    "            cleaning_log.append(f\"Converted {col} to numeric: {converted_count} values\")\n",
    "            print(f\"   ✓ Converted {converted_count} {col} values to numeric\")\n",
    "    \n",
    "    # 3. STANDARDIZE CATEGORICAL VALUES\n",
    "    print(\"\\n 3. STANDARDIZING CATEGORICAL VALUES...\")\n",
    "    \n",
    "    # PaycheckMethod standardization\n",
    "    if 'PaycheckMethod' in df_cleaned.columns:\n",
    "        print(\"   Standardizing PaycheckMethod...\")\n",
    "        paycheck_mapping = {\n",
    "            'Mailed Check': 'Mail Check',\n",
    "            'Mail_Check': 'Mail Check', \n",
    "            'MailedCheck': 'Mail Check',\n",
    "            'DirectDeposit': 'Direct Deposit',\n",
    "            'Direct_Deposit': 'Direct Deposit'\n",
    "        }\n",
    "        \n",
    "        original_unique = df_cleaned['PaycheckMethod'].nunique()\n",
    "        df_cleaned['PaycheckMethod'] = df_cleaned['PaycheckMethod'].replace(paycheck_mapping)\n",
    "        new_unique = df_cleaned['PaycheckMethod'].nunique()\n",
    "        \n",
    "        cleaning_log.append(f\"Standardized PaycheckMethod: {original_unique} to {new_unique} unique values\")\n",
    "        print(f\"     Standardized PaycheckMethod: {original_unique} to {new_unique} unique values\")\n",
    "    \n",
    "    # JobRoleArea standardization\n",
    "    if 'JobRoleArea' in df_cleaned.columns:\n",
    "        print(\"   Standardizing JobRoleArea...\")\n",
    "        jobrole_mapping = {\n",
    "            'Information_Technology': 'Information Technology',\n",
    "            'InformationTechnology': 'Information Technology',\n",
    "            'Human_Resources': 'Human Resources',\n",
    "            'HumanResources': 'Human Resources'\n",
    "        }\n",
    "        \n",
    "        original_unique = df_cleaned['JobRoleArea'].nunique()\n",
    "        df_cleaned['JobRoleArea'] = df_cleaned['JobRoleArea'].replace(jobrole_mapping)\n",
    "        new_unique = df_cleaned['JobRoleArea'].nunique()\n",
    "        \n",
    "        cleaning_log.append(f\"Standardized JobRoleArea: {original_unique} → {new_unique} unique values\")\n",
    "        print(f\"   Standardized JobRoleArea: {original_unique} → {new_unique} unique values\")\n",
    "    \n",
    "    # 4. CLEAN WHITESPACE ISSUES\n",
    "    print(\"\\n 4. CLEANING WHITESPACE ISSUES...\")\n",
    "    \n",
    "    text_columns = df_cleaned.select_dtypes(include=['object']).columns\n",
    "    total_whitespace_cleaned = 0\n",
    "    \n",
    "    for col in text_columns:\n",
    "        if df_cleaned[col].dtype == 'object':\n",
    "            # Clean leading/trailing whitespace\n",
    "            before_clean = df_cleaned[col].astype(str)\n",
    "            after_clean = before_clean.str.strip()\n",
    "            \n",
    "            # Count changes\n",
    "            changes = (before_clean != after_clean).sum()\n",
    "            if changes > 0:\n",
    "                df_cleaned[col] = after_clean\n",
    "                total_whitespace_cleaned += changes\n",
    "                print(f\"   Cleaned whitespace in {col}: {changes} values\")\n",
    "    \n",
    "    if total_whitespace_cleaned > 0:\n",
    "        cleaning_log.append(f\"Cleaned whitespace issues: {total_whitespace_cleaned} values\")\n",
    "    else:\n",
    "        print(\"   No whitespace issues found\")\n",
    "    \n",
    "    # 5. HANDLE ABSURD VALUES\n",
    "    print(\"\\n 5. HANDLING ABSURD VALUES\")\n",
    "    \n",
    "    # Remove negative salaries (impossible values)\n",
    "    if 'AnnualSalary' in df_cleaned.columns:\n",
    "        negative_salaries = (df_cleaned['AnnualSalary'] < 0).sum()\n",
    "        if negative_salaries > 0:\n",
    "            print(f\"Removing {negative_salaries} negative salary values...\")\n",
    "            df_cleaned = df_cleaned[df_cleaned['AnnualSalary'] >= 0]\n",
    "            cleaning_log.append(f\"Removed {negative_salaries} negative salary values\")\n",
    "            print(f\"    Removed {negative_salaries} impossible negative salaries\")\n",
    "    \n",
    "    # Handle other absurd values based on business rules\n",
    "    # Age values outside reasonable range\n",
    "    if 'Age' in df_cleaned.columns:\n",
    "        absurd_ages = ((df_cleaned['Age'] < 16) | (df_cleaned['Age'] > 100)).sum()\n",
    "        if absurd_ages > 0:\n",
    "            print(f\"Flagging {absurd_ages} absurd age values...\")\n",
    "            df_cleaned.loc[(df_cleaned['Age'] < 16) | (df_cleaned['Age'] > 100), 'Age'] = np.nan\n",
    "            cleaning_log.append(f\"Set {absurd_ages} absurd age values to NaN for review\")\n",
    "            print(f\"   Set {absurd_ages} absurd age values to NaN for manual review\")\n",
    "    \n",
    "    # Negative commute distances\n",
    "    if 'DrivingCommuterDistance' in df_cleaned.columns:\n",
    "    # Define threshold for absurd commute distances\n",
    "        max_reasonable_distance = 400  # miles\n",
    "\n",
    "        absurd_mask = (df_cleaned['DrivingCommuterDistance'] < 0) | \\\n",
    "                  (df_cleaned['DrivingCommuterDistance'] > max_reasonable_distance)\n",
    "\n",
    "        absurd_count = absurd_mask.sum()\n",
    "\n",
    "    if absurd_count > 0:\n",
    "        print(f\"   Handling {absurd_count} absurd commute distances...\")\n",
    "        # Set absurd distances to NaN (likely data entry errors)\n",
    "        df_cleaned.loc[absurd_mask, 'DrivingCommuterDistance'] = np.nan\n",
    "        cleaning_log.append(\n",
    "            f\"Set {absurd_count} absurd commute distances (<0 or >{max_reasonable_distance} miles) to NaN\"\n",
    "        )\n",
    "        print(f\"    Set {absurd_count} absurd commute distances to NaN for review\")\n",
    "    #-------------------------------------------------------------------------New Section--------------------------\n",
    "    print(\"\\n 5.5. CONVERTING HIDDEN MISSING VALUES...\")\n",
    "    \n",
    "    # Convert \"N/A\" strings to proper NaN values in NumCompaniesPreviouslyWorked\n",
    "    if 'NumCompaniesPreviouslyWorked' in df_cleaned.columns:\n",
    "        na_count = (df_cleaned['NumCompaniesPreviouslyWorked'] == 'N/A').sum()\n",
    "        if na_count > 0:\n",
    "            print(f\"  Converting {na_count} 'N/A' strings to NaN in NumCompaniesPreviouslyWorked...\")\n",
    "            \n",
    "            # Replace \"N/A\" strings with NaN\n",
    "            df_cleaned['NumCompaniesPreviouslyWorked'] = df_cleaned['NumCompaniesPreviouslyWorked'].replace('N/A', np.nan)\n",
    "            \n",
    "            # Convert to numeric to ensure proper data type\n",
    "            df_cleaned['NumCompaniesPreviouslyWorked'] = pd.to_numeric(\n",
    "                df_cleaned['NumCompaniesPreviouslyWorked'], \n",
    "                errors='coerce'\n",
    "            )\n",
    "            \n",
    "            cleaning_log.append(f\"Converted {na_count} 'N/A' strings to NaN and converted to numeric\")\n",
    "            print(f\"   Converted {na_count} hidden missing values to NaN\")\n",
    "            print(f\"   Converted column to numeric data type\")\n",
    "            print(f\"   Data type is now: {df_cleaned['NumCompaniesPreviouslyWorked'].dtype}\")\n",
    "        else:\n",
    "            print(\"    No 'N/A' strings found\")\n",
    "            # Still convert to numeric in case there are string numbers\n",
    "            original_dtype = df_cleaned['NumCompaniesPreviouslyWorked'].dtype\n",
    "            df_cleaned['NumCompaniesPreviouslyWorked'] = pd.to_numeric(\n",
    "                df_cleaned['NumCompaniesPreviouslyWorked'], \n",
    "                errors='coerce'\n",
    "            )\n",
    "            if original_dtype != df_cleaned['NumCompaniesPreviouslyWorked'].dtype:\n",
    "                cleaning_log.append(\"Converted NumCompaniesPreviouslyWorked to numeric data type\")\n",
    "                print(f\"   Converted column to numeric data type: {df_cleaned['NumCompaniesPreviouslyWorked'].dtype}\")\n",
    "    \n",
    "    # Check for other columns that might have similar issues\n",
    "    # (You can extend this for other columns if needed)\n",
    "    text_missing_patterns = ['N/A', 'n/a', 'NA', 'na', 'NULL', 'null', 'None', 'none', '-', '?']\n",
    "    \n",
    "    # Check other potential columns for hidden missing values\n",
    "    columns_to_check = ['AnnualProfessionalDevHrs']  # Add other columns as needed\n",
    "    \n",
    "    for col in columns_to_check:\n",
    "        if col in df_cleaned.columns and df_cleaned[col].dtype == 'object':\n",
    "            hidden_missing_count = df_cleaned[col].isin(text_missing_patterns).sum()\n",
    "            if hidden_missing_count > 0:\n",
    "                print(f\"   🎯 Found {hidden_missing_count} hidden missing values in {col}\")\n",
    "                df_cleaned[col] = df_cleaned[col].replace(text_missing_patterns, np.nan)\n",
    "                df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "                cleaning_log.append(f\"Converted {hidden_missing_count} hidden missing values in {col}\")\n",
    "                print(f\"   ✓ Converted {hidden_missing_count} hidden missing values in {col}\")\n",
    "    \n",
    "    print(\"   Hidden missing value conversion completed\")\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------------------------End of New Section----------------------------------------------\n",
    "    \n",
    "    # 6. HANDLE MISSING VALUES (THIS CODE SHOULD BE INSIDE THE FUNCTION!)\n",
    "    print(\"\\n 6. HANDLING MISSING VALUES...\")\n",
    "    \n",
    "    # Strategy depends on column and business context\n",
    "    missing_strategies = {\n",
    "        'Age': 'median',  # Use median age\n",
    "        'DrivingCommuterDistance': 'median',  # Use median distance\n",
    "        'NumCompaniesPreviouslyWorked': 'mode',  # Use most common value\n",
    "        'AnnualProfessionalDevHrs': 'median',  # Use median hours\n",
    "        'TextMessageOptIn': 'No'  # Default to No\n",
    "    }\n",
    "    \n",
    "    for col, strategy in missing_strategies.items():\n",
    "        if col in df_cleaned.columns:\n",
    "            missing_count = df_cleaned[col].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                print(f\"   Imputing {missing_count} missing values in {col} using {strategy}...\")\n",
    "                \n",
    "                if strategy == 'median':\n",
    "                    fill_value = df_cleaned[col].median()\n",
    "                elif strategy == 'mode':\n",
    "                    fill_value = df_cleaned[col].mode().iloc[0] if not df_cleaned[col].mode().empty else 0\n",
    "                else:\n",
    "                    # Handle custom string values like 'No'\n",
    "                    fill_value = strategy\n",
    "                \n",
    "                df_cleaned[col] = df_cleaned[col].fillna(fill_value)\n",
    "                cleaning_log.append(f\"Imputed {missing_count} missing {col} values with {strategy}\")\n",
    "                print(f\"   ✓ Imputed {missing_count} missing {col} values\")\n",
    "    \n",
    "    # 7. FINAL VALIDATION\n",
    "    print(\"\\n 7. FINAL VALIDATION...\")\n",
    "    \n",
    "    # Check data types\n",
    "    numeric_cols = ['EmployeeNumber', 'Age', 'Tenure', 'HoursWeekly', \n",
    "                   'AnnualSalary', 'DrivingCommuterDistance', \n",
    "                   'NumCompaniesPreviouslyWorked', 'AnnualProfessionalDevHrs']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in df_cleaned.columns and not pd.api.types.is_numeric_dtype(df_cleaned[col]):\n",
    "            print(f\"Warning: {col} is still not numeric after cleaning\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"CLEANING SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Original rows: {len(df):,}\")\n",
    "    print(f\"Cleaned rows: {len(df_cleaned):,}\")\n",
    "    print(f\"Rows removed: {len(df) - len(df_cleaned):,}\")\n",
    "    \n",
    "    print(f\"\\nActions taken:\")\n",
    "    for action in cleaning_log:\n",
    "        print(f\"   • {action}\")\n",
    "    \n",
    "    print(\"\\n Data cleaning completed!\")\n",
    "    \n",
    "    # Store cleaning log in dataframe attributes for reference\n",
    "    df_cleaned.cleaning_log = cleaning_log\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0374327-1536-4d18-bc4f-1d973900ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_salary_fixes(df_original: pd.DataFrame, df_fixed: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Validate that salary fixes resolved the inconsistencies\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_original : pd.DataFrame\n",
    "        Original dataframe before fixes\n",
    "    df_fixed : pd.DataFrame\n",
    "        Dataframe after fixes applied\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"VALIDATING SALARY FIXES\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Check inconsistencies before and after\n",
    "    inconsistencies_before = detect_salary_inconsistencies(df_original)\n",
    "    inconsistencies_after = detect_salary_inconsistencies(df_fixed)\n",
    "    \n",
    "    print(f\"Inconsistencies before: {len(inconsistencies_before):,}\")\n",
    "    print(f\"Inconsistencies after: {len(inconsistencies_after):,}\")\n",
    "    print(f\"Improvement: {len(inconsistencies_before) - len(inconsistencies_after):,} records fixed\")\n",
    "    \n",
    "    if len(inconsistencies_after) == 0:\n",
    "        print(\"All salary inconsistencies resolved!\")\n",
    "    else:\n",
    "        print(f\"{len(inconsistencies_after)} inconsistencies remain\")\n",
    "\n",
    "def inspect_salary_math_consistency(df: pd. DataFrame, \n",
    "                                   tolerance_percentage: float = 10.0,\n",
    "                                   weeks_per_year: float = 52.0) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Salary math validation to ensure HourlyRate × HoursWeekly × 52 = AnnualSalary\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe with salary columns\n",
    "    tolerance_percentage : float, default 10.0\n",
    "        Acceptable percentage difference between calculated and actual annual salary\n",
    "    weeks_per_year : float, default 52.0\n",
    "        Number of work weeks per year (adjust for vacation/holidays if needed)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict[str, Any] : Comprehensive salary consistency report\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"SALARY MATH CONSISTENCY INSPECTION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Handle column name variations\n",
    "    hourly_col = None\n",
    "    for col in ['HourlyRate', 'HourlyRate ', 'Hourly Rate', 'hourly_rate']:\n",
    "        if col in df.columns:\n",
    "            hourly_col = col\n",
    "            break\n",
    "    \n",
    "    if hourly_col is None:\n",
    "        print(\"No hourly rate column found\")\n",
    "        return {'error': 'No hourly rate column found'}\n",
    "    \n",
    "    # Check required columns\n",
    "    required_cols = [hourly_col, 'HoursWeekly', 'AnnualSalary']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"Missing required columns: {missing_cols}\")\n",
    "        return {'error': f'Missing columns: {missing_cols}'}\n",
    "    \n",
    "    print(f\"Using columns: {hourly_col}, HoursWeekly, AnnualSalary\")\n",
    "    print(f\"Tolerance: ±{tolerance_percentage}%\")\n",
    "    print(f\"Work weeks per year: {weeks_per_year}\")\n",
    "    \n",
    "    # Create a working copy and clean the data for analysis\n",
    "    df_work = df.copy()\n",
    "    \n",
    "    # Clean the hourly rate column if it contains text/currency symbols\n",
    "    if df_work[hourly_col].dtype == 'object':\n",
    "        print(f\"Cleaning {hourly_col} column (removing currency symbols)...\")\n",
    "        \n",
    "        # Remove currency symbols and convert to numeric\n",
    "        cleaned_hourly = (df_work[hourly_col]\n",
    "                         .astype(str)\n",
    "                         .str.replace(r'[\\$£€¥,\\s]', '', regex=True)\n",
    "                         .replace('', np.nan))\n",
    "        \n",
    "        df_work[hourly_col] = pd.to_numeric(cleaned_hourly, errors='coerce')\n",
    "        converted_count = df_work[hourly_col].notna().sum()\n",
    "        print(f\"Converted {converted_count} hourly rate values to numeric\")\n",
    "    \n",
    "    # Ensure other salary columns are numeric\n",
    "    for col in ['HoursWeekly', 'AnnualSalary']:\n",
    "        if df_work[col].dtype == 'object':\n",
    "            print(f\"Cleaning {col} column...\")\n",
    "            cleaned_values = (df_work[col]\n",
    "                             .astype(str)\n",
    "                             .str.replace(r'[\\$£€¥,\\s]', '', regex=True)\n",
    "                             .replace('', np.nan))\n",
    "            df_work[col] = pd.to_numeric(cleaned_values, errors='coerce')\n",
    "    \n",
    "    # Create report structure\n",
    "    report = {\n",
    "        'dataset_info': {\n",
    "            'total_rows': len(df_work),\n",
    "            'complete_salary_records': 0,\n",
    "            'incomplete_records': 0\n",
    "        },\n",
    "        'math_consistency': {\n",
    "            'consistent_records': 0,\n",
    "            'inconsistent_records': 0,\n",
    "            'consistency_percentage': 0.0\n",
    "        },\n",
    "        'inconsistency_details': {\n",
    "            'by_severity': {},\n",
    "            'by_pattern': {},\n",
    "            'worst_cases': [],\n",
    "            'statistical_summary': {}\n",
    "        },\n",
    "        'flagged_records': [],\n",
    "        'recommendations': []\n",
    "    }\n",
    "    \n",
    "    # Filter to records with complete salary data (now that data is cleaned)\n",
    "    salary_mask = (\n",
    "        df_work[hourly_col].notna() & \n",
    "        df_work['HoursWeekly'].notna() & \n",
    "        df_work['AnnualSalary'].notna() &\n",
    "        (df_work[hourly_col] > 0) &\n",
    "        (df_work['HoursWeekly'] > 0) &\n",
    "        (df_work['AnnualSalary'] > 0)\n",
    "    )\n",
    "    \n",
    "    complete_records = df_work[salary_mask].copy()\n",
    "    incomplete_count = len(df_work) - len(complete_records)\n",
    "    \n",
    "    report['dataset_info']['complete_salary_records'] = len(complete_records)\n",
    "    report['dataset_info']['incomplete_records'] = incomplete_count\n",
    "    \n",
    "    print(f\"\\n DATA OVERVIEW:\")\n",
    "    print(f\"   Total records: {len(df_work):,}\")\n",
    "    print(f\"   Complete salary data: {len(complete_records):,}\")\n",
    "    print(f\"   Incomplete/invalid: {incomplete_count:,}\")\n",
    "    \n",
    "    if len(complete_records) == 0:\n",
    "        print(\"No complete salary records to analyze\")\n",
    "        return report\n",
    "    \n",
    "    # Calculate expected annual salary\n",
    "    expected_annual = (complete_records[hourly_col] * \n",
    "                      complete_records['HoursWeekly'] * \n",
    "                      weeks_per_year)\n",
    "    \n",
    "    actual_annual = complete_records['AnnualSalary']\n",
    "    \n",
    "    # Calculate absolute percentage difference\n",
    "    percentage_diff = abs((expected_annual - actual_annual) / expected_annual) * 100\n",
    "    \n",
    "    # Identify inconsistent records\n",
    "    inconsistent_mask = percentage_diff > tolerance_percentage\n",
    "    consistent_mask = ~inconsistent_mask\n",
    "    \n",
    "    consistent_count = consistent_mask.sum()\n",
    "    inconsistent_count = inconsistent_mask.sum()\n",
    "    \n",
    "    report['math_consistency']['consistent_records'] = int(consistent_count)\n",
    "    report['math_consistency']['inconsistent_records'] = int(inconsistent_count)\n",
    "    report['math_consistency']['consistency_percentage'] = (consistent_count / len(complete_records)) * 100\n",
    "    \n",
    "    print(f\"\\nMATH CONSISTENCY RESULTS:\")\n",
    "    print(f\"  Consistent records: {consistent_count:,} ({(consistent_count/len(complete_records)*100):.1f}%)\")\n",
    "    print(f\"  Inconsistent records: {inconsistent_count:,} ({(inconsistent_count/len(complete_records)*100):.1f}%)\")\n",
    "    \n",
    "    if inconsistent_count > 0:\n",
    "        # Analyze inconsistency patterns\n",
    "        inconsistent_records = complete_records[inconsistent_mask].copy()\n",
    "        inconsistent_records['Expected_Annual'] = expected_annual[inconsistent_mask]\n",
    "        inconsistent_records['Actual_Annual'] = actual_annual[inconsistent_mask]\n",
    "        inconsistent_records['Dollar_Difference'] = expected_annual[inconsistent_mask] - actual_annual[inconsistent_mask]\n",
    "        inconsistent_records['Percentage_Difference'] = percentage_diff[inconsistent_mask]\n",
    "        \n",
    "        # Severity classification\n",
    "        severity_ranges = {\n",
    "            'Minor (10-25%)': (10, 25),\n",
    "            'Moderate (25-50%)': (25, 50),\n",
    "            'Major (50-100%)': (50, 100),\n",
    "            'Severe (>100%)': (100, float('inf'))\n",
    "        }\n",
    "        \n",
    "        severity_counts = {}\n",
    "        for severity, (min_pct, max_pct) in severity_ranges.items():\n",
    "            count = ((percentage_diff >= min_pct) & (percentage_diff < max_pct)).sum()\n",
    "            severity_counts[severity] = int(count)\n",
    "        \n",
    "        report['inconsistency_details']['by_severity'] = severity_counts\n",
    "        \n",
    "        print(f\"\\n INCONSISTENCY SEVERITY:\")\n",
    "        for severity, count in severity_counts.items():\n",
    "            if count > 0:\n",
    "                print(f\"   {severity}: {count:,} records\")\n",
    "        \n",
    "        # Pattern analysis\n",
    "        patterns = {}\n",
    "        \n",
    "        # Pattern 1: Low annual, reasonable hourly (your case)\n",
    "        low_annual_reasonable_hourly = (\n",
    "            (inconsistent_records['Actual_Annual'] < 20000) & \n",
    "            (inconsistent_records[hourly_col] > 15) &\n",
    "            (inconsistent_records['HoursWeekly'] >= 35)\n",
    "        ).sum()\n",
    "        patterns['Low Annual + High Hourly + Full Time'] = int(low_annual_reasonable_hourly)\n",
    "        \n",
    "        # Pattern 2: High annual, low hourly\n",
    "        high_annual_low_hourly = (\n",
    "            (inconsistent_records['Actual_Annual'] > 80000) & \n",
    "            (inconsistent_records[hourly_col] < 25)\n",
    "        ).sum()\n",
    "        patterns['High Annual + Low Hourly'] = int(high_annual_low_hourly)\n",
    "        \n",
    "        # Pattern 3: Unrealistic hours\n",
    "        unrealistic_hours = (\n",
    "            (inconsistent_records['HoursWeekly'] < 10) | \n",
    "            (inconsistent_records['HoursWeekly'] > 70)\n",
    "        ).sum()\n",
    "        patterns['Unrealistic Weekly Hours'] = int(unrealistic_hours)\n",
    "        \n",
    "        # Pattern 4: Possible monthly vs annual confusion\n",
    "        monthly_confusion = (\n",
    "            abs(inconsistent_records['Actual_Annual'] * 12 - inconsistent_records['Expected_Annual']) / \n",
    "            inconsistent_records['Expected_Annual'] * 100 < tolerance_percentage\n",
    "        ).sum()\n",
    "        patterns['Possible Monthly Salary Error'] = int(monthly_confusion)\n",
    "        \n",
    "        report['inconsistency_details']['by_pattern'] = patterns\n",
    "        \n",
    "        print(f\"\\n INCONSISTENCY PATTERNS:\")\n",
    "        for pattern, count in patterns.items():\n",
    "            if count > 0:\n",
    "                print(f\"   {pattern}: {count:,} records\")\n",
    "        \n",
    "        # Statistical summary of inconsistencies\n",
    "        stats = {\n",
    "            'avg_percentage_diff': float(percentage_diff[inconsistent_mask].mean()),\n",
    "            'median_percentage_diff': float(percentage_diff[inconsistent_mask].median()),\n",
    "            'max_percentage_diff': float(percentage_diff[inconsistent_mask].max()),\n",
    "            'avg_dollar_diff': float(inconsistent_records['Dollar_Difference'].mean()),\n",
    "            'median_dollar_diff': float(inconsistent_records['Dollar_Difference'].median())\n",
    "        }\n",
    "        \n",
    "        report['inconsistency_details']['statistical_summary'] = stats\n",
    "        \n",
    "        print(f\"\\nINCONSISTENCY STATISTICS:\")\n",
    "        print(f\"Average difference: {stats['avg_percentage_diff']:.1f}% (${stats['avg_dollar_diff']:,.0f})\")\n",
    "        print(f\"Median difference: {stats['median_percentage_diff']:.1f}% (${stats['median_dollar_diff']:,.0f})\")\n",
    "        print(f\"Maximum difference: {stats['max_percentage_diff']:.1f}%\")\n",
    "        \n",
    "        # Top 10 worst cases\n",
    "        worst_cases = inconsistent_records.nlargest(10, 'Percentage_Difference')\n",
    "        worst_cases_list = []\n",
    "        \n",
    "        print(f\"\\nTOP 10 WORST INCONSISTENCIES:\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, (idx, row) in enumerate(worst_cases.iterrows(), 1):\n",
    "            case_info = {\n",
    "                'rank': i,\n",
    "                'row_index': int(idx),\n",
    "                'hourly_rate': float(row[hourly_col]),\n",
    "                'hours_weekly': float(row['HoursWeekly']),\n",
    "                'expected_annual': float(row['Expected_Annual']),\n",
    "                'actual_annual': float(row['Actual_Annual']),\n",
    "                'difference_pct': float(row['Percentage_Difference']),\n",
    "                'difference_dollars': float(row['Dollar_Difference'])\n",
    "            }\n",
    "            worst_cases_list.append(case_info)\n",
    "            \n",
    "            print(f\"{i:2d}. Row {idx}: ${row[hourly_col]:.2f}/hr × {row['HoursWeekly']}hr/wk = \"\n",
    "                  f\"${row['Expected_Annual']:,.0f}/yr BUT shows ${row['Actual_Annual']:,.0f}/yr \"\n",
    "                  f\"({row['Percentage_Difference']:.1f}% off)\")\n",
    "        \n",
    "        report['inconsistency_details']['worst_cases'] = worst_cases_list\n",
    "        \n",
    "        # Create flagged records list for cleaning process\n",
    "        flagged_records = []\n",
    "        for idx, row in inconsistent_records.iterrows():\n",
    "            flagged_records.append({\n",
    "                'row_index': int(idx),\n",
    "                'issue_type': 'SALARY_MATH_INCONSISTENCY',\n",
    "                'severity': get_severity_level(row['Percentage_Difference']),\n",
    "                'details': f\"Expected ${row['Expected_Annual']:,.0f} but shows ${row['Actual_Annual']:,.0f} ({row['Percentage_Difference']:.1f}% difference)\",\n",
    "                'hourly_rate': float(row[hourly_col]),\n",
    "                'hours_weekly': float(row['HoursWeekly']),\n",
    "                'annual_salary': float(row['Actual_Annual']),\n",
    "                'expected_annual': float(row['Expected_Annual']),\n",
    "                'needs_review': True\n",
    "            })\n",
    "        \n",
    "        report['flagged_records'] = flagged_records\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = []\n",
    "        \n",
    "        if patterns['Low Annual + High Hourly + Full Time'] > 0:\n",
    "            recommendations.append(f\"CRITICAL: {patterns['Low Annual + High Hourly + Full Time']} records have suspiciously low annual salaries despite reasonable hourly rates - likely data entry errors\")\n",
    "        \n",
    "        if patterns['Possible Monthly Salary Error'] > 0:\n",
    "            recommendations.append(f\"INVESTIGATE: {patterns['Possible Monthly Salary Error']} records might have monthly salary entered instead of annual\")\n",
    "        \n",
    "        if patterns['Unrealistic Weekly Hours'] > 0:\n",
    "            recommendations.append(f\"REVIEW: {patterns['Unrealistic Weekly Hours']} records have unusual weekly hours that may affect calculations\")\n",
    "        \n",
    "        if inconsistent_count > len(complete_records) * 0.1:  # More than 10% inconsistent\n",
    "            recommendations.append(\"HIGH PRIORITY: Large percentage of salary records are mathematically inconsistent - review data collection process\")\n",
    "        \n",
    "        recommendations.append(f\"RECOMMENDED ACTION: Flag all {inconsistent_count:,} inconsistent records for manual review before analysis\")\n",
    "        \n",
    "        report['recommendations'] = recommendations\n",
    "        \n",
    "        print(f\"\\n RECOMMENDATIONS:\")\n",
    "        for rec in recommendations:\n",
    "            print(f\"   {rec}\")\n",
    "    \n",
    "    print(f\"\\n Salary math inspection completed!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def get_severity_level(percentage_diff: float) -> str:\n",
    "    \"\"\"Helper function to classify inconsistency severity\"\"\"\n",
    "    if percentage_diff < 25:\n",
    "        return 'MINOR'\n",
    "    elif percentage_diff < 50:\n",
    "        return 'MODERATE'\n",
    "    elif percentage_diff < 100:\n",
    "        return 'MAJOR'\n",
    "    else:\n",
    "        return 'SEVERE'\n",
    "\n",
    "def add_salary_consistency_flags(df: pd.DataFrame, \n",
    "                                salary_report: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add salary consistency flags to the dataframe based on inspection results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    salary_report : Dict[str, Any]\n",
    "        Report from inspect_salary_math_consistency()\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Dataframe with added flag columns\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\" ADDING SALARY CONSISTENCY FLAGS TO DATASET\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    df_flagged = df.copy()\n",
    "    \n",
    "    # Initialize flag columns\n",
    "    df_flagged['Salary_Math_Consistent'] = True\n",
    "    df_flagged['Salary_Inconsistency_Severity'] = 'NONE'\n",
    "    df_flagged['Salary_Needs_Review'] = False\n",
    "    df_flagged['Salary_Issue_Details'] = ''\n",
    "    \n",
    "    # Apply flags based on report\n",
    "    if 'flagged_records' in salary_report:\n",
    "        flagged_count = 0\n",
    "        \n",
    "        for record in salary_report['flagged_records']:\n",
    "            idx = record['row_index']\n",
    "            \n",
    "            df_flagged.loc[idx, 'Salary_Math_Consistent'] = False\n",
    "            df_flagged.loc[idx, 'Salary_Inconsistency_Severity'] = record['severity']\n",
    "            df_flagged.loc[idx, 'Salary_Needs_Review'] = True\n",
    "            df_flagged.loc[idx, 'Salary_Issue_Details'] = record['details']\n",
    "            \n",
    "            flagged_count += 1\n",
    "        \n",
    "        print(f\"   Flagged {flagged_count:,} records with salary inconsistencies\")\n",
    "        \n",
    "        # Summary by severity\n",
    "        severity_summary = df_flagged['Salary_Inconsistency_Severity'].value_counts()\n",
    "        print(f\"\\n FLAGS BY SEVERITY:\")\n",
    "        for severity, count in severity_summary.items():\n",
    "            if severity != 'NONE':\n",
    "                print(f\"      {severity}: {count:,}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"No salary inconsistencies found - no flags added\")\n",
    "    \n",
    "    return df_flagged\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def handle_outliers_and_absurd_values(df: pd.DataFrame, \n",
    "                                    method: str = 'investigate',\n",
    "                                    outlier_method: str = 'iqr',\n",
    "                                    outlier_threshold: float = 1.5,\n",
    "                                    fix_salary_inconsistencies: bool = True) -> pd.DataFrame:\n",
    "   \n",
    "    \"\"\"\n",
    "    Outlier and absurd value handling with multiple strategies\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe to process\n",
    "    method : str, default 'investigate'\n",
    "        Strategy: 'investigate', 'remove', 'cap', 'transform', 'flag'\n",
    "    outlier_method : str, default 'iqr'\n",
    "        Outlier detection method: 'iqr', 'zscore', 'modified_zscore'\n",
    "    outlier_threshold : float, default 1.5\n",
    "        Threshold for outlier detection\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Processed dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"HANDLING OUTLIERS AND ABSURD VALUES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    processing_log = []\n",
    "    \n",
    "    # Define numeric columns to check\n",
    "    numeric_columns = ['Age', 'Tenure', 'HoursWeekly', 'AnnualSalary', \n",
    "                      'DrivingCommuterDistance', 'NumCompaniesPreviouslyWorked', \n",
    "                      'AnnualProfessionalDevHrs']\n",
    "    \n",
    "    # 1. HANDLE ABSURD VALUES FIRST (Logically impossible)\n",
    "    print(\"\\n1. HANDLING ABSURD VALUES (Logically Impossible)...\")\n",
    "    \n",
    "    absurd_rules = {\n",
    "        'Age': {'min': 18, 'max': 80, 'reason': 'Working age limits'},\n",
    "        'Tenure': {'min': 0, 'max': 50, 'reason': 'Career length limits'},\n",
    "        'HoursWeekly': {'min': 0, 'max': 80, 'reason': 'Legal working hours'},\n",
    "        'AnnualSalary': {'min': 0, 'max': None, 'reason': 'Cannot be negative or higher than 250,000'},\n",
    "        'DrivingCommuterDistance': {'min': 0, 'max': 500, 'reason': 'Reasonable commute limits'},\n",
    "        'NumCompaniesPreviouslyWorked': {'min': 0, 'max': 20, 'reason': 'Career history limits'},\n",
    "        'AnnualProfessionalDevHrs': {'min': 0, 'max': 1000, 'reason': 'Annual time limits'}\n",
    "    }\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df_processed.columns and col in absurd_rules:\n",
    "            rules = absurd_rules[col]\n",
    "            \n",
    "            # Count absurd values\n",
    "            absurd_mask = pd.Series([False] * len(df_processed), index=df_processed.index)\n",
    "            \n",
    "            if rules['min'] is not None:\n",
    "                absurd_mask |= (df_processed[col] < rules['min'])\n",
    "            if rules['max'] is not None:\n",
    "                absurd_mask |= (df_processed[col] > rules['max'])\n",
    "                \n",
    "            absurd_count = absurd_mask.sum()\n",
    "            \n",
    "            if absurd_count > 0:\n",
    "                print(f\" {col}: {absurd_count} absurd values ({rules['reason']})\")\n",
    "                \n",
    "                if method == 'remove':\n",
    "                    df_processed = df_processed[~absurd_mask]\n",
    "                    processing_log.append(f\"Removed {absurd_count} absurd {col} values\")\n",
    "                \n",
    "                elif method == 'cap':\n",
    "                    if rules['min'] is not None:\n",
    "                        df_processed.loc[df_processed[col] < rules['min'], col] = rules['min']\n",
    "                    if rules['max'] is not None:\n",
    "                        df_processed.loc[df_processed[col] > rules['max'], col] = rules['max']\n",
    "                    processing_log.append(f\"Capped {absurd_count} absurd {col} values to valid range\")\n",
    "                \n",
    "                elif method == 'flag':\n",
    "                    df_processed[f'{col}_absurd_flag'] = absurd_mask\n",
    "                    processing_log.append(f\"Flagged {absurd_count} absurd {col} values\")\n",
    "                \n",
    "                else:  # investigate (default)\n",
    "                    df_processed.loc[absurd_mask, col] = np.nan\n",
    "                    processing_log.append(f\"Set {absurd_count} absurd {col} values to NaN for investigation\")\n",
    "                \n",
    "                print(f\"      → Action taken: {method}\")\n",
    "    \n",
    "    # 2. HANDLE STATISTICAL OUTLIERS\n",
    "    print(f\"\\n 2. HANDLING STATISTICAL OUTLIERS (Method: {outlier_method})...\")\n",
    "    \n",
    "    outlier_summary = {}\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df_processed.columns and pd.api.types.is_numeric_dtype(df_processed[col]):\n",
    "            col_data = df_processed[col].dropna()\n",
    "            \n",
    "            if len(col_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Detect outliers using specified method\n",
    "            outlier_mask = detect_outliers(col_data, method=outlier_method, threshold=outlier_threshold)\n",
    "            outlier_count = outlier_mask.sum()\n",
    "            \n",
    "            if outlier_count > 0:\n",
    "                outlier_values = col_data[outlier_mask]\n",
    "                outlier_percentage = (outlier_count / len(col_data)) * 100\n",
    "                \n",
    "                print(f\" {col}: {outlier_count} outliers ({outlier_percentage:.1f}%)\")\n",
    "                print(f\"      Range: {outlier_values.min():.2f} to {outlier_values.max():.2f}\")\n",
    "                \n",
    "                outlier_summary[col] = {\n",
    "                    'count': outlier_count,\n",
    "                    'percentage': outlier_percentage,\n",
    "                    'values': outlier_values.tolist()[:10],  # First 10 for inspection\n",
    "                    'min': outlier_values.min(),\n",
    "                    'max': outlier_values.max()\n",
    "                }\n",
    "                \n",
    "                # Apply outlier handling strategy\n",
    "                if method == 'remove':\n",
    "                    # Remove outlier rows\n",
    "                    df_processed = df_processed.loc[~col_data.index.isin(outlier_values.index)]\n",
    "                    processing_log.append(f\"Removed {outlier_count} outlier rows for {col}\")\n",
    "                \n",
    "                elif method == 'cap':\n",
    "                    # Cap to 5th and 95th percentiles\n",
    "                    lower_cap = col_data.quantile(0.05)\n",
    "                    upper_cap = col_data.quantile(0.95)\n",
    "                    \n",
    "                    df_processed.loc[df_processed[col] < lower_cap, col] = lower_cap\n",
    "                    df_processed.loc[df_processed[col] > upper_cap, col] = upper_cap\n",
    "                    processing_log.append(f\"Capped {outlier_count} {col} outliers to 5th-95th percentile range\")\n",
    "                \n",
    "                elif method == 'transform':\n",
    "                    # Log transformation for right-skewed data\n",
    "                    if col_data.min() > 0:  # Only if all values are positive\n",
    "                        df_processed[f'{col}_log'] = np.log1p(df_processed[col])\n",
    "                        processing_log.append(f\"Created log-transformed {col}_log for {col}\")\n",
    "                    else:\n",
    "                        print(f\"      → Cannot log-transform {col} (contains non-positive values)\")\n",
    "                \n",
    "                elif method == 'flag':\n",
    "                    # Create outlier flag column\n",
    "                    df_processed[f'{col}_outlier_flag'] = False\n",
    "                    df_processed.loc[col_data.index[outlier_mask], f'{col}_outlier_flag'] = True\n",
    "                    processing_log.append(f\"Flagged {outlier_count} {col} outliers\")\n",
    "                \n",
    "                else:  # investigate (default)\n",
    "                    print(f\"      → Outliers preserved for investigation\")\n",
    "                    processing_log.append(f\"Identified {outlier_count} {col} outliers for investigation\")\n",
    "    \n",
    "    # 3. BUSINESS CONTEXT RECOMMENDATIONS\n",
    "    print(f\"\\n3. BUSINESS CONTEXT RECOMMENDATIONS...\")\n",
    "    \n",
    "    business_recommendations = {\n",
    "        'Age': \"Low ages (16-20) might be student workers - verify legitimacy\",\n",
    "        'AnnualSalary': \"Very low salaries might be part-time or intern positions\",\n",
    "        'DrivingCommuterDistance': \"High distances (>100 miles) might indicate remote workers\",\n",
    "        'HoursWeekly': \"Low hours might indicate part-time or contractor status\",\n",
    "        'AnnualProfessionalDevHrs': \"Zero dev hours might indicate entry-level positions\"\n",
    "    }\n",
    "    \n",
    "    for col, rec in business_recommendations.items():\n",
    "        if col in outlier_summary:\n",
    "            print(f\"    {col}: {rec}\")\n",
    "    \n",
    "    # 4. SUMMARY REPORT\n",
    "    print(f\"\\n 4. PROCESSING SUMMARY...\")\n",
    "    print(f\"Strategy used: {method}\")\n",
    "    print(f\"Original rows: {len(df):,}\")\n",
    "    print(f\"Processed rows: {len(df_processed):,}\")\n",
    "    \n",
    "    if processing_log:\n",
    "        print(f\"\\n Actions taken:\")\n",
    "        for action in processing_log:\n",
    "            print(f\"   • {action}\")\n",
    "    \n",
    "    # Store processing info\n",
    "    df_processed.outlier_processing_log = processing_log\n",
    "    df_processed.outlier_summary = outlier_summary\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "def detect_outliers(data: pd.Series, \n",
    "                   method: str = 'iqr', \n",
    "                   threshold: float = 1.5) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Detect outliers using various statistical methods\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.Series\n",
    "        Numeric data to analyze\n",
    "    method : str, default 'iqr'\n",
    "        Detection method: 'iqr', 'zscore', 'modified_zscore'\n",
    "    threshold : float, default 1.5\n",
    "        Threshold for outlier detection\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series : Boolean mask indicating outliers\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        return (data < lower_bound) | (data > upper_bound)\n",
    "    \n",
    "    elif method == 'zscore':\n",
    "        z_scores = np.abs((data - data.mean()) / data.std())\n",
    "        return z_scores > threshold\n",
    "    \n",
    "    elif method == 'modified_zscore':\n",
    "        median = data.median()\n",
    "        mad = np.median(np.abs(data - median))\n",
    "        if mad == 0:\n",
    "            return pd.Series([False] * len(data), index=data.index)\n",
    "        modified_z_scores = 0.6745 * (data - median) / mad\n",
    "        return np.abs(modified_z_scores) > threshold\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "def create_outlier_investigation_report(df: pd.DataFrame, \n",
    "                                       output_file: str = 'outlier_investigation.csv') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a detailed report of outliers for manual investigation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    output_file : str, default 'outlier_investigation.csv'\n",
    "        Output filename for investigation report\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Investigation report\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"CREATING OUTLIER INVESTIGATION REPORT...\")\n",
    "    \n",
    "    investigation_data = []\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            col_data = df[col].dropna()\n",
    "            \n",
    "            # Detect outliers using IQR method\n",
    "            outlier_mask = detect_outliers(col_data, method='iqr', threshold=1.5)\n",
    "            outlier_indices = col_data[outlier_mask].index\n",
    "            \n",
    "            for idx in outlier_indices:\n",
    "                investigation_data.append({\n",
    "                    'Row_Index': idx,\n",
    "                    'Column': col,\n",
    "                    'Value': df.loc[idx, col],\n",
    "                    'Column_Mean': col_data.mean(),\n",
    "                    'Column_Median': col_data.median(),\n",
    "                    'Column_Std': col_data.std(),\n",
    "                    'Z_Score': abs((df.loc[idx, col] - col_data.mean()) / col_data.std()),\n",
    "                    'Percentile': (col_data < df.loc[idx, col]).mean() * 100,\n",
    "                    'Action_Needed': 'INVESTIGATE',\n",
    "                    'Notes': ''\n",
    "                })\n",
    "    \n",
    "    investigation_df = pd.DataFrame(investigation_data)\n",
    "    \n",
    "    if len(investigation_df) > 0:\n",
    "        investigation_df.to_csv(output_file, index=False)\n",
    "        print(f\"Investigation report saved: {output_file}\")\n",
    "        print(f\"    {len(investigation_df)} outliers require investigation\")\n",
    "        \n",
    "        # Show summary by column\n",
    "        summary = investigation_df.groupby('Column').size().sort_values(ascending=False)\n",
    "        print(f\"\\nOutliers by column:\")\n",
    "        for col, count in summary.items():\n",
    "            print(f\"      • {col}: {count}\")\n",
    "    else:\n",
    "        print(\"No outliers detected\")\n",
    "    \n",
    "    return investigation_df\n",
    "\n",
    "\n",
    "def export_cleaning_report(df_cleaned: pd.DataFrame, \n",
    "                          filename: str = 'cleaning_report.txt') -> None:\n",
    "    \"\"\"\n",
    "    Export cleaning actions to a text file for documentation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_cleaned : pd.DataFrame\n",
    "        Cleaned dataframe with cleaning_log attribute\n",
    "    filename : str, default 'cleaning_report.txt'\n",
    "        Output filename for the report\n",
    "    \"\"\"\n",
    "    \n",
    "    if hasattr(df_cleaned, 'cleaning_log'):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"DATA CLEANING REPORT\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\")\n",
    "            f.write(f\"Generated on: {pd.Timestamp.now()}\\n\\n\")\n",
    "            \n",
    "            f.write(\"ACTIONS TAKEN:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            for action in df_cleaned.cleaning_log:\n",
    "                f.write(f\"• {action}\\n\")\n",
    "            \n",
    "            f.write(f\"\\n FINAL DATASET:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(f\"Rows: {len(df_cleaned):,}\\n\")\n",
    "            f.write(f\"Columns: {len(df_cleaned.columns)}\\n\")\n",
    "            \n",
    "        print(f\"Cleaning report exported to: {filename}\")\n",
    "    else:\n",
    "        print(\"No cleaning log found in dataframe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093fafb-db51-4267-be77-7c14e219efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Run main quality check\n",
    "main_report = quick_quality_check('Employee Turnover Dataset.csv')\n",
    "\n",
    "# Step 1.5: Generate summary table of ORIGINAL data quality issues\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING ORIGINAL DATA QUALITY SUMMARY\")\n",
    "\n",
    "summary_table = get_column_summary_table(df, main_report)\n",
    "summary_table.to_csv('original_data_quality_summary.csv', index=False)\n",
    "print(\"Original data quality summary exported to 'original_data_quality_summary.csv'\")\n",
    "\n",
    "# Step 2: Run salary math validation  \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "salary_report = inspect_salary_math_consistency(df, tolerance_percentage=10.0)\n",
    "# Step 3: Add flags to dataset\n",
    "df_flagged = add_salary_consistency_flags(df, salary_report)\n",
    "\n",
    "\n",
    "# Step 3.5: DATA CLEANING PROCESS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING DATA CLEANING PROCESS\")\n",
    "\n",
    "df_cleaned = clean_employee_data(df_flagged, report=main_report, backup=True)\n",
    "df_processed = handle_outliers_and_absurd_values(df_cleaned, method='flag')\n",
    "\n",
    "# Export additional Cleaning Report\n",
    "cleaned_report = inspect_data_quality(df_processed, show_plots=False)\n",
    "summary_table_after = get_column_summary_table(df_processed, cleaned_report)\n",
    "summary_table_after.to_csv('data_quality_AFTER_cleaning.csv', index=False)\n",
    "\n",
    "# Step 4: Export final files\n",
    "flagged_records = df_processed[df_processed['Salary_Needs_Review'] == True]\n",
    "flagged_records.to_csv('salary_math_inconsistencies_for_review.csv', index=False)\n",
    "df_processed.to_csv('Employee_Turnover_Dataset_CLEANED.csv', index=False)\n",
    "outlier_investigation_df = create_outlier_investigation_report(df_processed, 'outlier_investigation_report.csv')\n",
    "\n",
    "print(f\"\\nExported {len(flagged_records)} problematic salary records for evaluation\")\n",
    "print(f\"Exported cleaned dataset with {len(df_processed)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f60f9-a4d5-466e-8ce3-3da32fac2197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shap_env_new)",
   "language": "python",
   "name": "shap_env_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
